{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks
.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5156a76c-7af7-465d-aff4-41a2e54e3595",
"showTitle":false,"title":""}},"source":["# Welcome to the Profiling Tool for the RAPIDS Accelerator for Apache Spark\n","To run the tool, you need to enter a log path that represents the DBFS location for your Spark GPU event logs.  Then you can select \"Run all\" to execute the notebook.  After the notebook completes, you will see various output tables show up below.  More options for running the profiling tool can be found here: https://docs.nvidia.com/spark-rapids/user-guide/latest/spark-profiling-tool.html#profiling-tool-options.\n","\n","## GPU Job Tuning Recommendations\n","This has general suggestions for tuning your applications to run optimally on GPUs.\n","\n","## Per-Job Profile\n","The profiler output includes information about the application, data sources, executors, SQL stages, Spark properties, and key application metrics at the job and stage levels."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"53b4d770-9db6-4bd7-9b93-d036d375eac5","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">Out[59]: 2011685</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">Out[59]: 2011685</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["import json\n","import requests\n","import base64\n","import shlex\n","import subprocess\n","import pandas as pd\n","\n","TOOL_JAR_URL = 'https://repo1.maven.org/maven2/com/nvidia/rapids-4-spark-tools_2.12/24.06.0/rapids-4-spark-tools_2.12-24.06.0.jar'\n","TOOL_JAR_LOCAL_PATH = '/tmp/rapids-4-spark-tools.jar'\n","\n","# Profiling tool output directory.\n","OUTPUT_DIR = '/tmp' \n","\n","response = requests.get(TOOL_JAR_URL)\n","open(TOOL_JAR_LOCAL_PATH, \"wb\").write(response.content)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f0e4371a-d2d9-4449-81ed-8f6c61ae8f80","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["dbutils.widgets.text(\"log_path\", \"\")\n","eventlog_string=dbutils.widgets.get(\"log_path\") \n","\n","dbutils.widgets.text(\"output_path\", \"\")\n","outputpath_string=dbutils.widgets.get(\"output_path\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"6c35e478-abe6-49b7-97f9-a8aba71f11d3","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["worker_info_path = \"/tmp/worker_info.yaml\"\n","\n","worker_info = \"\"\"\n","  system:\n","    numCores: 32\n","    memory: 212992MiB\n","    numWorkers: 5\n","  gpu:\n","    memory: 15109MiB\n","    count: 4\n","    name: T4\n","  softwareProperties:\n","    spark.driver.maxResultSize: 7680m\n","    spark.driver.memory: 15360m\n","    spark.executor.cores: '8'\n","    spark.executor.instances: '2'\n","    spark.executor.memory: 47222m\n","    spark.executorEnv.OPENBLAS_NUM_THREADS: '1'\n","    spark.scheduler.mode: FAIR\n","    spark.sql.cbo.enabled: 'true'\n","    spark.ui.port: '0'\n","    spark.yarn.am.memory: 640m\n","\"\"\"\n","\n","with open(worker_info_path, 'w') as f:\n","    f.write(worker_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e9e7cecf-c2dc-4a0f-aea1-61a323e4ccc4","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["!java -Xmx10g -cp /tmp/rapids-4-spark-tools.jar:/databricks/jars/* com.nvidia.spark.rapids.tool.profiling.ProfileMain --csv --worker-info $worker_info_path --auto-tuner -o $outputpath_string $eventlog_string &> /tmp/prof_debug.log"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"be0a2da7-1ee3-475e-96f9-303779edfd85","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["import os\n","\n","app_df = pd.DataFrame(columns = ['appId', 'appName'])\n","\n","for x in os.scandir(outputpath_string + \"/rapids_4_spark_profile/\"):\n","  tmp_df = pd.read_csv(x.path + \"/application_information.csv\")\n","  app_df = app_df.append(tmp_df[['appId', 'appName']])"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a1e326ec-5701-4b08-ae0f-7df0c8440038","showTitle":false,"title":""}},"source":["## GPU Job Tuning Recommendations"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4979f78c-44a0-4e54-b803-e5e194b71104","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>app</th><th>recommendations</th></tr></thead><tbody><tr><td>app-20220210005817-0212</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=1197m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004538-0189</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210000414-0117</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=2353m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005713-0210</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210000744-0123</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002521-0154</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004801-0193</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=3158m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002620-0156</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210001501-0135</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=1365m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001417-0134</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=1365m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001930-0143</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005502-0206</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002316-0150</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004324-0185</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005039-0198</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210004834-0194</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=2099m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004011-0180</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004656-0191</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210001324-0133</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=2225m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210000856-0125</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210000241-0114</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002105-0146</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210000312-0115</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210003325-0169</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002654-0157</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005425-0205</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=1509m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210000700-0122</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001109-0129</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002138-0147</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001717-0139</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210000018-0110</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002725-0158</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210000933-0126</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210004617-0190</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005846-0213</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=1197m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210002757-0159</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001038-0128</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210000628-0121</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=3404m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210001959-0144</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210000556-0120</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004727-0192</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=3354m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005222-0201</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210000825-0124</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005536-0207</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001139-0130</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210000343-0116</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210003705-0176</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=2337m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210003359-0170</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005611-0208</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=2974m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210000119-0112</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=3061m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005322-0203</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003900-0179</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004355-0186</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001648-0138</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002938-0162</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005354-0204</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210001821-0141</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=2530m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210005252-0202</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210002452-0153</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001617-0137</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003254-0168</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004507-0188</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210001751-0140</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005642-0209</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210004905-0195</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003751-0177</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002030-0145</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210001854-0142</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210002549-0155</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210001239-0132</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=2225m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004428-0187</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=3796m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002240-0149</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005147-0200</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=2974m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220523230623-0000</td><td>\n","Spark Properties:\n","--conf spark.executor.instances=20\n","--conf spark.executor.memory=16384m\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.shuffle.partitions=6\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' should be increased since spilling occurred.\n","</td></tr><tr><td>app-20220210000207-0113</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220209235945-0109</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210002349-0151</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002421-0152</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210000448-0118</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001005-0127</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210003149-0166</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003635-0175</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210003223-0167</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004041-0181</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003532-0173</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003607-0174</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003048-0164</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210004145-0183</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210003825-0178</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210003118-0165</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210000049-0111</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210000519-0119</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=3061m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210003015-0163</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210005744-0211</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210005111-0199</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004217-0184</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210002904-0161</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=3796m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001546-0136</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003503-0172</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210001209-0131</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","</td></tr><tr><td>app-20220210004114-0182</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210002208-0148</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210002833-0160</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr><tr><td>app-20220210003431-0171</td><td>\n","Spark Properties:\n","--conf spark.executor.cores=8\n","--conf spark.executor.instances=20\n","--conf spark.executor.memoryOverhead=5734m\n","--conf spark.rapids.memory.pinnedPool.size=4096m\n","--conf spark.rapids.sql.concurrentGpuTasks=2\n","--conf spark.sql.files.maxPartitionBytes=4096m\n","--conf spark.sql.shuffle.partitions=200\n","--conf spark.task.resource.gpu.amount=0.125\n","\n","Comments:\n","- 'spark.executor.memoryOverhead' was not set.\n","- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n","- 'spark.sql.shuffle.partitions' was not set.\n","- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n","</td></tr></tbody></table></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"aggData":[],"aggError":"","aggOverflow":false,"aggSchema":[],"aggSeriesLimitReached":false,"aggType":"","arguments":{},"columnCustomDisplayInfos":{},"data":[["app-20220210005817-0212","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=1197m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004538-0189","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210000414-0117","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=2353m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005713-0210","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210000744-0123","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002521-0154","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004801-0193","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=3158m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002620-0156","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210001501-0135","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=1365m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001417-0134","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=1365m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001930-0143","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005502-0206","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002316-0150","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004324-0185","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005039-0198","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210004834-0194","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=2099m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004011-0180","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004656-0191","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210001324-0133","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=2225m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210000856-0125","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210000241-0114","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002105-0146","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210000312-0115","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210003325-0169","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002654-0157","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005425-0205","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=1509m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210000700-0122","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001109-0129","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002138-0147","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001717-0139","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210000018-0110","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002725-0158","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210000933-0126","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210004617-0190","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005846-0213","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=1197m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210002757-0159","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001038-0128","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210000628-0121","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=3404m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210001959-0144","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210000556-0120","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004727-0192","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=3354m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005222-0201","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210000825-0124","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005536-0207","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001139-0130","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210000343-0116","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210003705-0176","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=2337m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210003359-0170","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005611-0208","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=2974m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210000119-0112","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=3061m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005322-0203","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003900-0179","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004355-0186","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001648-0138","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002938-0162","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005354-0204","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210001821-0141","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=2530m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210005252-0202","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210002452-0153","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001617-0137","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003254-0168","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004507-0188","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210001751-0140","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005642-0209","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210004905-0195","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003751-0177","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002030-0145","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210001854-0142","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210002549-0155","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210001239-0132","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=2225m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004428-0187","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=3796m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002240-0149","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005147-0200","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=2974m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220523230623-0000","\nSpark Properties:\n--conf spark.executor.instances=20\n--conf spark.executor.memory=16384m\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.shuffle.partitions=6\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' should be increased since spilling occurred.\n"],["app-20220210000207-0113","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220209235945-0109","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210002349-0151","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002421-0152","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210000448-0118","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001005-0127","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210003149-0166","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003635-0175","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210003223-0167","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004041-0181","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003532-0173","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003607-0174","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003048-0164","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210004145-0183","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210003825-0178","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210003118-0165","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210000049-0111","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210000519-0119","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=3061m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210003015-0163","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210005744-0211","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210005111-0199","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004217-0184","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210002904-0161","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=3796m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001546-0136","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003503-0172","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210001209-0131","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n"],["app-20220210004114-0182","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210002208-0148","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210002833-0160","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"],["app-20220210003431-0171","\nSpark Properties:\n--conf spark.executor.cores=8\n--conf spark.executor.instances=20\n--conf spark.executor.memoryOverhead=5734m\n--conf spark.rapids.memory.pinnedPool.size=4096m\n--conf spark.rapids.sql.concurrentGpuTasks=2\n--conf spark.sql.files.maxPartitionBytes=4096m\n--conf spark.sql.shuffle.partitions=200\n--conf spark.task.resource.gpu.amount=0.125\n\nComments:\n- 'spark.executor.memoryOverhead' was not set.\n- 'spark.executor.memoryOverhead' must be set if using 'spark.rapids.memory.pinnedPool.size\n- 'spark.sql.shuffle.partitions' was not set.\n- Average JVM GC time is very high. Other Garbage Collectors can be used for better performance.\n"]],"datasetInfos":[],"dbfsResultPath":null,"isJsonSchema":true,"metadata":{},"overflow":false,"plotOptions":{"customPlotOptions":{},"displayType":"table","pivotAggregation":null,"pivotColumns":null,"xColumns":null,"yColumns":null},"removedWidgets":[],"schema":[{"metadata":"{}","name":"app","type":"\"string\""},{"metadata":"{}","name":"recommendations","type":"\"string\""}],"type":"table"}},"output_type":"display_data"}],"source":["app_list = app_df[\"appId\"].tolist()\n","app_recommendations = pd.DataFrame(columns=['app', 'recommendations'])\n","\n","for app in app_list:\n","  app_file = open(outputpath_string + \"/rapids_4_spark_profile/\" + app + \"/profile.log\")\n","  recommendations_start = 0\n","  recommendations_str = \"\"\n","  for line in app_file:\n","    if recommendations_start == 1:\n","      recommendations_str = recommendations_str + line\n","    if \"### D. Recommended Configuration ###\" in line:\n","      recommendations_start = 1\n","  app_recommendations = app_recommendations.append({'app': app, 'recommendations': recommendations_str}, ignore_index=True)\n","    \n","display(app_recommendations)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[{"elements":[{"dashboardResultIndex":0,"elementNUID":"be0a2da7-1ee3-475e-96f9-303779edfd85","elementType":"command","guid":"05eef9d3-7c55-4e26-8d1f-fa80338359e6","options":null,"position":{"height":6,"width":24,"x":0,"y":0,"z":null},"resultIndex":null}],"globalVars":{},"guid":"a9ea7799-040a-484e-a59d-c3cdf5072953","layoutOption":{"grid":true,"stack":true},"nuid":"91c1bfb2-695a-4e5c-8a25-848a433108dc","origId":2690941040041430,"title":"Executive View","version":"DashboardViewV1","width":1600},{"elements":[],"globalVars":{},"guid":"0896a45f-af1b-4849-b6c2-2b6abcb8b97b","layoutOption":{"grid":true,"stack":true},"nuid":"62243296-4562-4f06-90ac-d7a609f19c16","origId":2690941040041431,"title":"App View","version":"DashboardViewV1","width":1920}],"language":"python","notebookMetadata":{"pythonIndentUnit":2,"widgetLayout":[{"breakBefore":false,"name":"log_path","width":562},{"breakBefore":false,"name":"output_path","width":511}]},"notebookName":"[RAPIDS Accelerator for Apache Spark] Profiling Tool Notebook Template","notebookOrigID":2690941040041407,"widgets":{"log_path":{"currentValue":"/dbfs/user1/profiler_logs","nuid":"c7ce3870-db19-4813-b1cb-cead3f4c36f1","widgetInfo":{"defaultValue":"","label":null,"name":"log_path","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}},"output_path":{"currentValue":"/tmp","nuid":"a7d1d293-d8c3-452b-9ffb-786ea7a28843","widgetInfo":{"defaultValue":"","label":null,"name":"output_path","options":{"validationRegex":null,"widgetType":"text"},"widgetType":"text"}}}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
