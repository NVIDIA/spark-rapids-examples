{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to XGBoost Spark with GPU\n",
    "\n",
    "Mortgage is an example of xgboost classifier to do binary classification. This notebook will show you how to load data, train the xgboost model and use this model to predict if a mushroom is \"poisonous\". Camparing to original XGBoost Spark code, there're only one API difference.\n",
    "\n",
    "## Load libraries\n",
    "First load some common libraries will be used by both GPU version and CPU version xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml.dmlc.xgboost4j.scala.spark.{XGBoostClassifier, XGBoostClassificationModel}\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.sql.types.{DoubleType, IntegerType, StructField, StructType}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides CPU version requires some extra libraries, such as:\n",
    "\n",
    "```scala\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.FloatType\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainPath = /data/mortgage/csv/train/\n",
       "evalPath = /data/mortgage/csv/test/\n",
       "transPath = /data/mortgage/csv/test/\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/data/mortgage/csv/test/"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// You need to update them to your real paths!\n",
    "val trainPath = \"/data/mortgage/csv/train/\"\n",
    "val evalPath  = \"/data/mortgage/csv/test/\"\n",
    "val transPath = \"/data/mortgage/csv/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the schema and parameters\n",
    "The mortgage data has 27 columns: 26 features and 1 label. \"deinquency_12\" is the label column. The schema will be used to load data in the future.\n",
    "\n",
    "The next block also defines some key parameters used in xgboost training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelColName = delinquency_12\n",
       "schema = StructType(StructField(orig_channel,DoubleType,true), StructField(first_home_buyer,DoubleType,true), StructField(loan_purpose,DoubleType,true), StructField(property_type,DoubleType,true), StructField(occupancy_status,DoubleType,true), StructField(property_state,DoubleType,true), StructField(product_type,DoubleType,true), StructField(relocation_mortgage_indicator,DoubleType,true), StructField(seller_name,DoubleType,true), StructField(mod_flag,DoubleType,true), StructField(orig_interest_rate,DoubleType,true), StructField(orig_upb,IntegerType,true), StructField(orig_loan_term,IntegerType,true), StructField(orig_ltv,DoubleType,true), StructField(orig_cltv,DoubleType,true), StructField(num_borrowers,DoubleT...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(orig_channel,DoubleType,true), StructField(first_home_buyer,DoubleType,true), StructField(loan_purpose,DoubleType,true), StructField(property_type,DoubleType,true), StructField(occupancy_status,DoubleType,true), StructField(property_state,DoubleType,true), StructField(product_type,DoubleType,true), StructField(relocation_mortgage_indicator,DoubleType,true), StructField(seller_name,DoubleType,true), StructField(mod_flag,DoubleType,true), StructField(orig_interest_rate,DoubleType,true), StructField(orig_upb,IntegerType,true), StructField(orig_loan_term,IntegerType,true), StructField(orig_ltv,DoubleType,true), StructField(orig_cltv,DoubleType,true), StructField(num_borrowers,DoubleT..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelColName = \"delinquency_12\"\n",
    "val schema = StructType(List(\n",
    "  StructField(\"orig_channel\", DoubleType),\n",
    "  StructField(\"first_home_buyer\", DoubleType),\n",
    "  StructField(\"loan_purpose\", DoubleType),\n",
    "  StructField(\"property_type\", DoubleType),\n",
    "  StructField(\"occupancy_status\", DoubleType),\n",
    "  StructField(\"property_state\", DoubleType),\n",
    "  StructField(\"product_type\", DoubleType),\n",
    "  StructField(\"relocation_mortgage_indicator\", DoubleType),\n",
    "  StructField(\"seller_name\", DoubleType),\n",
    "  StructField(\"mod_flag\", DoubleType),\n",
    "  StructField(\"orig_interest_rate\", DoubleType),\n",
    "  StructField(\"orig_upb\", IntegerType),\n",
    "  StructField(\"orig_loan_term\", IntegerType),\n",
    "  StructField(\"orig_ltv\", DoubleType),\n",
    "  StructField(\"orig_cltv\", DoubleType),\n",
    "  StructField(\"num_borrowers\", DoubleType),\n",
    "  StructField(\"dti\", DoubleType),\n",
    "  StructField(\"borrower_credit_score\", DoubleType),\n",
    "  StructField(\"num_units\", IntegerType),\n",
    "  StructField(\"zip\", IntegerType),\n",
    "  StructField(\"mortgage_insurance_percent\", DoubleType),\n",
    "  StructField(\"current_loan_delinquency_status\", IntegerType),\n",
    "  StructField(\"current_actual_upb\", DoubleType),\n",
    "  StructField(\"interest_rate\", DoubleType),\n",
    "  StructField(\"loan_age\", DoubleType),\n",
    "  StructField(\"msa\", DoubleType),\n",
    "  StructField(\"non_interest_bearing_upb\", DoubleType),\n",
    "  StructField(labelColName, IntegerType)))\n",
    "\n",
    "val featureNames = schema.filter(_.name != labelColName).map(_.name)\n",
    "\n",
    "val commParamMap = Map(\n",
    "  \"eta\" -> 0.1,\n",
    "  \"gamma\" -> 0.1,\n",
    "  \"missing\" -> 0.0,\n",
    "  \"max_depth\" -> 10,\n",
    "  \"max_leaves\" -> 256,\n",
    "  \"objective\" -> \"binary:logistic\",\n",
    "  \"grow_policy\" -> \"depthwise\",\n",
    "  \"min_child_weight\" -> 30,\n",
    "  \"lambda\" -> 1,\n",
    "  \"scale_pos_weight\" -> 2,\n",
    "  \"subsample\" -> 1,\n",
    "  \"nthread\" -> 1,\n",
    "  \"num_round\" -> 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new spark session and load data\n",
    "\n",
    "A new spark session should be created to continue all the following spark operations.\n",
    "\n",
    "NOTE: in this notebook, the dependency jars have been loaded when installing toree kernel. Alternatively the jars can be loaded into notebook by [%AddJar magic](https://toree.incubator.apache.org/docs/current/user/faq/). However, there's one restriction for `%AddJar`: the jar uploaded can only be available when `AddJar` is called just after a new spark session is created. Do it as below:\n",
    "\n",
    "```scala\n",
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().appName(\"mortgage-GPU\").getOrCreate\n",
    "%AddJar file:/data/libs/cudf-XXX-cuda10.jar\n",
    "%AddJar file:/data/libs/rapids-4-spark-XXX.jar\n",
    "%AddJar file:/data/libs/xgboost4j_3.0-XXX.jar\n",
    "%AddJar file:/data/libs/xgboost4j-spark_3.0-XXX.jar\n",
    "// ...\n",
    "```\n",
    "\n",
    "##### Please note the new jar \"rapids-4-spark-XXX.jar\" is only needed for GPU version, you can not add it to dependence list for CPU version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparkSession = org.apache.spark.sql.SparkSession@56233666\n",
       "reader = org.apache.spark.sql.DataFrameReader@62964667\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.DataFrameReader@62964667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Build the spark session and data reader as usual\n",
    "val sparkSession = SparkSession.builder.appName(\"mortgage-gpu\").getOrCreate\n",
    "val reader = sparkSession.read.option(\"header\", true).schema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainSet = [orig_channel: double, first_home_buyer: double ... 26 more fields]\n",
       "evalSet = [orig_channel: double, first_home_buyer: double ... 26 more fields]\n",
       "transSet = [orig_channel: double, first_home_buyer: double ... 26 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[orig_channel: double, first_home_buyer: double ... 26 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainSet = reader.csv(trainPath)\n",
    "val evalSet  = reader.csv(evalPath)\n",
    "val transSet = reader.csv(transPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set xgboost parameters and build a XGBoostClassifier\n",
    "\n",
    "For CPU version, `num_workers` is recommended being equal to the number of CPU cores, while for GPU version, it should be set to the number of GPUs in Spark cluster.\n",
    "\n",
    "Besides the `tree_method` for CPU version is also different from that for GPU version. Now only \"gpu_hist\" is supported for training on GPU.\n",
    "\n",
    "```scala\n",
    "// difference in parameters\n",
    "  \"num_workers\" -> 12,\n",
    "  \"tree_method\" -> \"hist\",\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgbParamFinal = Map(min_child_weight -> 30, grow_policy -> depthwise, scale_pos_weight -> 2, num_workers -> 1, subsample -> 1, lambda -> 1, max_depth -> 10, objective -> binary:logistic, num_round -> 100, missing -> 0.0, tree_method -> gpu_hist, eta -> 0.1, max_leaves -> 256, gamma -> 0.1, nthread -> 1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(min_child_weight -> 30, grow_policy -> depthwise, scale_pos_weight -> 2, num_workers -> 1, subsample -> 1, lambda -> 1, max_depth -> 10, objective -> binary:logistic, num_round -> 100, missing -> 0.0, tree_method -> gpu_hist, eta -> 0.1, max_leaves -> 256, gamma -> 0.1, nthread -> 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xgbParamFinal = commParamMap ++ Map(\"tree_method\" -> \"gpu_hist\", \"num_workers\" -> 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the only API difference,`setFeaturesCol` in CPU version vs `setFeaturesCols` in GPU version.\n",
    "\n",
    "In previous block, it said that CPU version needs `VectorAssembler` to assemble multiple feature columns into one column, because `setFeaturesCol` only accepts one feature column with the type of `vector`.\n",
    "\n",
    "But `setFeaturesCols` supports multiple columns directly, so set the feautres column names directly to `XGBoostClassifier`. \n",
    "\n",
    "CPU version:\n",
    "\n",
    "```scala\n",
    "val xgbClassifier  = new XGBoostClassifier(paramMap)\n",
    "  .setLabelCol(labelName)\n",
    "  .setFeaturesCol(\"features\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgbClassifier = xgbc_51efa8a205b1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "xgbc_51efa8a205b1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xgbClassifier = new XGBoostClassifier(xgbParamFinal)\n",
    "      .setLabelCol(labelColName)\n",
    "      // === diff ===\n",
    "      .setFeaturesCols(featureNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark and train\n",
    "The object `benchmark` is used to compute the elapsed time of some operations.\n",
    "\n",
    "Training with evaluation sets is also supported in 2 ways, the same as CPU version's behavior:\n",
    "\n",
    "* Call API `setEvalSets` after initializing an XGBoostClassifier\n",
    "\n",
    "```scala\n",
    "xgbClassifier.setEvalSets(Map(\"eval\" -> evalSet))\n",
    "\n",
    "```\n",
    "\n",
    "* Use parameter `eval_sets` when initializing an XGBoostClassifier\n",
    "\n",
    "```scala\n",
    "val paramMapWithEval = paramMap + (\"eval_sets\" -> Map(\"eval\" -> evalSet))\n",
    "val xgbClassifierWithEval = new XGBoostClassifier(paramMapWithEval)\n",
    "```\n",
    "\n",
    "Here chooses the API way to set evaluation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgbc_51efa8a205b1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbClassifier.setEvalSets(Map(\"eval\" -> evalSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object Benchmark\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object Benchmark {\n",
    "  def time[R](phase: String)(block: => R): (R, Float) = {\n",
    "    val t0 = System.currentTimeMillis\n",
    "    val result = block // call-by-name\n",
    "    val t1 = System.currentTimeMillis\n",
    "    println(\"Elapsed time [\" + phase + \"]: \" + ((t1 - t0).toFloat / 1000) + \"s\")\n",
    "    (result, (t1 - t0).toFloat / 1000)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU version reqires an extra step before fitting data to classifier, using `VectorAssembler` to assemble all feature columns into one column. The following code snip shows how to do the vectorizing.\n",
    "\n",
    "```scala\n",
    "object Vectorize {\n",
    "  def apply(df: DataFrame, featureNames: Seq[String], labelName: String): DataFrame = {\n",
    "    val toFloat = df.schema.map(f => col(f.name).cast(FloatType))\n",
    "    new VectorAssembler()\n",
    "      .setInputCols(featureNames.toArray)\n",
    "      .setOutputCol(\"features\")\n",
    "      .transform(df.select(toFloat:_*))\n",
    "      .select(col(\"features\"), col(labelName))\n",
    "  }\n",
    "}\n",
    "\n",
    "trainSet = Vectorize(trainSet, featureCols, labelName)\n",
    "evalSet = Vectorize(evalSet, featureCols, labelName)\n",
    "transSet = Vectorize(transSet, featureCols, labelName)\n",
    "\n",
    "```\n",
    "\n",
    "Fortunately `VectorAssembler` is not needed for GPU version. Just fit the loaded data directly to XGBoostClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Training ------\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.78, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "xgbClassificationModel = xgbc_51efa8a205b1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time [train]: 35.409s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "xgbc_51efa8a205b1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Start training\n",
    "println(\"\\n------ Training ------\")\n",
    "val (xgbClassificationModel, _) = Benchmark.time(\"train\") {\n",
    "  xgbClassifier.fit(trainSet)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation and evaluation\n",
    "Here uses `transSet` to evaluate our model and prints some useful columns to show our prediction result. After that `MulticlassClassificationEvaluator` is used to calculate an overall accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Transforming ------\n",
      "Elapsed time [transform]: 10.922s\n",
      "+------------+--------------+--------------------+--------------------+----------+\n",
      "|orig_channel|delinquency_12|       rawPrediction|         probability|prediction|\n",
      "+------------+--------------+--------------------+--------------------+----------+\n",
      "|         0.0|             0|[7.94447755813598...|[0.99964551060111...|       0.0|\n",
      "|         0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0|[4.27546072006225...|[0.98628507554531...|       0.0|\n",
      "|         0.0|             0|[4.27546072006225...|[0.98628507554531...|       0.0|\n",
      "|         0.0|             0|[5.23280811309814...|[0.99468983523547...|       0.0|\n",
      "+------------+--------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------Accuracy of Evaluation------\n",
      "0.9876288410129955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "results = [orig_channel: double, first_home_buyer: double ... 29 more fields]\n",
       "evaluator = MulticlassClassificationEvaluator: uid=mcEval_cfa6376fa392, metricName=f1, metricLabel=0.0, beta=1.0, eps=1.0E-15\n",
       "accuracy = 0.9876288410129955\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9876288410129955"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"\\n------ Transforming ------\")\n",
    "val (results, _) = Benchmark.time(\"transform\") {\n",
    "  val ret = xgbClassificationModel.transform(transSet).cache()\n",
    "  ret.foreachPartition((_: Iterator[_]) => ())\n",
    "  ret\n",
    "}\n",
    "results.select(\"orig_channel\", labelColName,\"rawPrediction\",\"probability\",\"prediction\").show(10)\n",
    "\n",
    "println(\"\\n------Accuracy of Evaluation------\")\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(labelColName)\n",
    "val accuracy = evaluator.evaluate(results)\n",
    "println(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model to disk and load model\n",
    "Save the model to disk and then load it to memory. After that use the loaded model to do a new prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time [transform2]: 0.072s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modelFromDisk = xgbc_51efa8a205b1\n",
       "results2 = [orig_channel: double, first_home_buyer: double ... 29 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+------------+-------------+----------------+--------------+------------+-----------------------------+-----------+--------+------------------+--------+--------------+--------+---------+-------------+----+---------------------+---------+---+--------------------------+-------------------------------+------------------+-------------+--------+-------+------------------------+--------------+--------------------+--------------------+----------+\n",
      "|orig_channel|first_home_buyer|loan_purpose|property_type|occupancy_status|property_state|product_type|relocation_mortgage_indicator|seller_name|mod_flag|orig_interest_rate|orig_upb|orig_loan_term|orig_ltv|orig_cltv|num_borrowers| dti|borrower_credit_score|num_units|zip|mortgage_insurance_percent|current_loan_delinquency_status|current_actual_upb|interest_rate|loan_age|    msa|non_interest_bearing_upb|delinquency_12|       rawPrediction|         probability|prediction|\n",
      "+------------+----------------+------------+-------------+----------------+--------------+------------+-----------------------------+-----------+--------+------------------+--------+--------------+--------+---------+-------------+----+---------------------+---------+---+--------------------------+-------------------------------+------------------+-------------+--------+-------+------------------------+--------------+--------------------+--------------------+----------+\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|               0.0|         5.85|     8.0|19100.0|                     0.0|             0|[7.94447755813598...|[0.99964551060111...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|56173.950000000004|         5.85|   138.0|19100.0|                     0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|56858.729999999996|         5.85|   135.0|19100.0|                     0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|          60971.25|         5.85|   116.0|19100.0|                     0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|          61379.63|         5.85|   114.0|19100.0|                     0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|          63168.98|         5.85|   105.0|19100.0|                     0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|          63363.01|         5.85|   104.0|19100.0|                     0.0|             0|[4.54992532730102...|[0.98954252060502...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|          65305.57|         5.85|    92.0|19100.0|                     0.0|             0|[4.27546072006225...|[0.98628507554531...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|          65460.06|         5.85|    91.0|19100.0|                     0.0|             0|[4.27546072006225...|[0.98628507554531...|       0.0|\n",
      "|         0.0|             0.0|         0.0|          0.0|             0.0|           0.0|         0.0|                          0.0|        0.0|     0.0|              5.85|   77000|           360|    90.0|      0.0|          1.0|35.0|                773.0|        1|752|                      25.0|                              0|          65919.05|         5.85|    88.0|19100.0|                     0.0|             0|[5.23280811309814...|[0.99468983523547...|       0.0|\n",
      "+------------+----------------+------------+-------------+----------------+--------------+------------+-----------------------------+-----------+--------+------------------+--------+--------------+--------+---------+-------------+----+---------------------+---------+---+--------------------------+-------------------------------+------------------+-------------+--------+-------+------------------------+--------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[orig_channel: double, first_home_buyer: double ... 29 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbClassificationModel.write.overwrite.save(\"/data/model/mortgage\")\n",
    "\n",
    "val modelFromDisk = XGBoostClassificationModel.load(\"/data/model/mortgage\")\n",
    "\n",
    "val (results2, _) = Benchmark.time(\"transform2\") {\n",
    "  modelFromDisk.transform(transSet)\n",
    "}\n",
    "results2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgb3_gpu - Scala",
   "language": "scala",
   "name": "xgb3_gpu_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
