{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortgage CrossValidation with GPU accelerating on XGBoost\n",
    "\n",
    "In this notebook, we will show you how to levarage GPU to accelerate mortgage CrossValidation of XGBoost to find out the best model given a group of parameters.\n",
    "\n",
    "Note: CrossValidation can't be ran with the latest cudf v21.06.1 because of some API changes. We'll plan to release a new XGBoost jar with the fixing soon. We keep this notebook using cudf v0.19.2 & rapids-4-spark v0.5.0.\n",
    "\n",
    "## Import classes\n",
    "First we need load some common classes that both GPU version and CPU version will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml.dmlc.xgboost4j.scala.spark.{XGBoostClassificationModel, XGBoostClassifier}\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.tuning.ParamGridBuilder\n",
    "import org.apache.spark.sql.types.{FloatType, IntegerType, StructField, StructType}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is new to xgboost-spark users is **rapids.CrossValidator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml.dmlc.xgboost4j.scala.spark.rapids.CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainParquetPath = /data/mortgage/parquet/train\n",
       "evalParquetPath = /data/mortgage/parquet/eval\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/data/mortgage/parquet/eval"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainParquetPath=\"/data/mortgage/parquet/train\"\n",
    "val evalParquetPath=\"/data/mortgage/parquet/eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the schema of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelColName = delinquency_12\n",
       "schema = StructType(StructField(orig_channel,FloatType,true), StructField(first_home_buyer,FloatType,true), StructField(loan_purpose,FloatType,true), StructField(property_type,FloatType,true), StructField(occupancy_status,FloatType,true), StructField(property_state,FloatType,true), StructField(product_type,FloatType,true), StructField(relocation_mortgage_indicator,FloatType,true), StructField(seller_name,FloatType,true), StructField(mod_flag,FloatType,true), StructField(orig_interest_rate,FloatType,true), StructField(orig_upb,IntegerType,true), StructField(orig_loan_term,IntegerType,true), StructField(orig_ltv,FloatType,true), StructField(orig_cltv,FloatType,true), StructField(num_borrowers,FloatType,true), Str...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(orig_channel,FloatType,true), StructField(first_home_buyer,FloatType,true), StructField(loan_purpose,FloatType,true), StructField(property_type,FloatType,true), StructField(occupancy_status,FloatType,true), StructField(property_state,FloatType,true), StructField(product_type,FloatType,true), StructField(relocation_mortgage_indicator,FloatType,true), StructField(seller_name,FloatType,true), StructField(mod_flag,FloatType,true), StructField(orig_interest_rate,FloatType,true), StructField(orig_upb,IntegerType,true), StructField(orig_loan_term,IntegerType,true), StructField(orig_ltv,FloatType,true), StructField(orig_cltv,FloatType,true), StructField(num_borrowers,FloatType,true), Str..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelColName = \"delinquency_12\"\n",
    "val schema = StructType(List(\n",
    "    StructField(\"orig_channel\", FloatType),\n",
    "    StructField(\"first_home_buyer\", FloatType),\n",
    "    StructField(\"loan_purpose\", FloatType),\n",
    "    StructField(\"property_type\", FloatType),\n",
    "    StructField(\"occupancy_status\", FloatType),\n",
    "    StructField(\"property_state\", FloatType),\n",
    "    StructField(\"product_type\", FloatType),\n",
    "    StructField(\"relocation_mortgage_indicator\", FloatType),\n",
    "    StructField(\"seller_name\", FloatType),\n",
    "    StructField(\"mod_flag\", FloatType),\n",
    "    StructField(\"orig_interest_rate\", FloatType),\n",
    "    StructField(\"orig_upb\", IntegerType),\n",
    "    StructField(\"orig_loan_term\", IntegerType),\n",
    "    StructField(\"orig_ltv\", FloatType),\n",
    "    StructField(\"orig_cltv\", FloatType),\n",
    "    StructField(\"num_borrowers\", FloatType),\n",
    "    StructField(\"dti\", FloatType),\n",
    "    StructField(\"borrower_credit_score\", FloatType),\n",
    "    StructField(\"num_units\", IntegerType),\n",
    "    StructField(\"zip\", IntegerType),\n",
    "    StructField(\"mortgage_insurance_percent\", FloatType),\n",
    "    StructField(\"current_loan_delinquency_status\", IntegerType),\n",
    "    StructField(\"current_actual_upb\", FloatType),\n",
    "    StructField(\"interest_rate\", FloatType),\n",
    "    StructField(\"loan_age\", FloatType),\n",
    "    StructField(\"msa\", FloatType),\n",
    "    StructField(\"non_interest_bearing_upb\", FloatType),\n",
    "    StructField(labelColName, IntegerType)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new spark session and load data\n",
    "we must create a new spark session to continue all spark operations. It will also be used to initilize the `GpuDataReader` which is a data reader powered by GPU.\n",
    "\n",
    "NOTE: in this notebook, we have uploaded dependency jars when installing toree kernel. If we don't upload them at installation time, we can also upload in notebook by [%AddJar magic](https://toree.incubator.apache.org/docs/current/user/faq/). However, there's one restriction for `%AddJar`: the jar uploaded can only be available when `AddJar` is called after a new spark session is created. We must use it as below:\n",
    "\n",
    "```scala\n",
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().appName(\"Taxi-GPU\").getOrCreate\n",
    "%AddJar file:/data/libs/cudf-0.19.2-cuda10-1.jar\n",
    "%AddJar file:/data/libs/xgboost4j_3.0-1.3.0-0.1.0.jar\n",
    "%AddJar file:/data/libs/xgboost4j-spark_3.0-1.3.0-0.1.0.jar\n",
    "%AddJar file:/data/libs/rapids-4-spark_2.12-0.5.0.jar\n",
    "// ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@4ef2d54c\n",
       "trainDs = [orig_channel: double, first_home_buyer: double ... 26 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[orig_channel: double, first_home_buyer: double ... 26 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder().appName(\"mortgage-gpu-cv\").getOrCreate()\n",
    "val trainDs = spark.read.parquet(trainParquetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out features to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureNames = List(orig_channel, first_home_buyer, loan_purpose, property_type, occupancy_status, property_state, product_type, relocation_mortgage_indicator, seller_name, mod_flag, orig_interest_rate, orig_upb, orig_loan_term, orig_ltv, orig_cltv, num_borrowers, dti, borrower_credit_score, num_units, zip, mortgage_insurance_percent, current_loan_delinquency_status, current_actual_upb, interest_rate, loan_age, msa, non_interest_bearing_upb)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(orig_channel, first_home_buyer, loan_purpose, property_type, occupancy_status, property_state, product_type, relocation_mortgage_indicator, seller_name, mod_flag, orig_interest_rate, orig_upb, orig_loan_term, orig_ltv, orig_cltv, num_borrowers, dti, borrower_credit_score, num_units, zip, mortgage_insurance_percent, current_loan_delinquency_status, current_actual_upb, interest_rate, loan_age, msa, non_interest_bearing_upb)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureNames = schema.filter(_.name != labelColName).map(_.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifierParam = Map(min_child_weight -> 30, grow_policy -> depthwise, scale_pos_weight -> 2, subsample -> 1, lambda -> 1, max_depth -> 10, objective -> binary:logistic, num_round -> 100, missing -> 0.0, tree_method -> gpu_hist, eta -> 0.1, max_leaves -> 256, gamma -> 0.1, nthread -> 1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(min_child_weight -> 30, grow_policy -> depthwise, scale_pos_weight -> 2, subsample -> 1, lambda -> 1, max_depth -> 10, objective -> binary:logistic, num_round -> 100, missing -> 0.0, tree_method -> gpu_hist, eta -> 0.1, max_leaves -> 256, gamma -> 0.1, nthread -> 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val classifierParam = Map(\n",
    "    \"eta\" -> 0.1,\n",
    "    \"gamma\" -> 0.1,\n",
    "    \"missing\" -> 0.0,\n",
    "    \"max_depth\" -> 10,\n",
    "    \"max_leaves\" -> 256,\n",
    "    \"grow_policy\" -> \"depthwise\",\n",
    "    \"objective\" -> \"binary:logistic\",\n",
    "    \"min_child_weight\" -> 30,\n",
    "    \"lambda\" -> 1,\n",
    "    \"scale_pos_weight\" -> 2,\n",
    "    \"subsample\" -> 1,\n",
    "    \"nthread\" -> 1,\n",
    "    \"num_round\" -> 100,\n",
    "    \"tree_method\" -> \"gpu_hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier = xgbc_9b881658ae0b\n",
       "paramGrid = \n",
       "evaluator = MulticlassClassificationEvaluator: uid=mcEval_5057139582af, metricName=f1, metricLabel=0.0, beta=1.0, eps=1.0E-15\n",
       "cv = cv_510a3b5b16bc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array({\n",
       "\txgbc_9b881658ae0b-eta: 0.2,\n",
       "\txgbc_9b881658ae0b-maxDepth: 3\n",
       "}, {\n",
       "\txgbc_9b881658ae0b-eta: 0.2,\n",
       "\txgbc_9b881658ae0b-maxDepth: 10\n",
       "}, {\n",
       "\txgbc_9b881658ae0b-eta: 0.6,\n",
       "\txgbc_9b881658ae0b-maxDepth: 3\n",
       "}, {\n",
       "\txgbc_9b881658ae0b-eta: 0.6,\n",
       "\txgbc_9b881658ae0b-maxDepth: 10\n",
       "})\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "cv_510a3b5b16bc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val classifier = new XGBoostClassifier(classifierParam)\n",
    "    .setLabelCol(labelColName)\n",
    "    .setFeaturesCols(featureNames)\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "    .addGrid(classifier.maxDepth, Array(3, 10))\n",
    "    .addGrid(classifier.eta, Array(0.2, 0.6))\n",
    "    .build()\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(labelColName)\n",
    "val cv = new CrossValidator()\n",
    "    .setEstimator(classifier)\n",
    "    .setEvaluator(evaluator)\n",
    "    .setEstimatorParamMaps(paramGrid)\n",
    "    .setNumFolds(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.19.183.93, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model = xgbc_9b881658ae0b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "xgbc_9b881658ae0b"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = cv.fit(trainDs).bestModel.asInstanceOf[XGBoostClassificationModel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tranform with best model trained by CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformDs = [orig_channel: double, first_home_buyer: double ... 26 more fields]\n",
       "df = [orig_channel: double, first_home_buyer: double ... 29 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+----------+\n",
      "|delinquency_12|       rawPrediction|         probability|prediction|\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "|             0|[6.45624113082885...|[0.99843177443835...|       0.0|\n",
      "|             0|[8.55493927001953...|[0.99980744560889...|       0.0|\n",
      "|             0|[5.98186397552490...|[0.99748223810456...|       0.0|\n",
      "|             0|[9.41403198242187...|[0.99991843526368...|       0.0|\n",
      "|             0|[3.82117009162902...|[0.97856726497411...|       0.0|\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[orig_channel: double, first_home_buyer: double ... 29 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val transformDs = spark.read.parquet(evalParquetPath)\n",
    "val df = model.transform(transformDs).cache()\n",
    "df.drop(featureNames: _*).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator = MulticlassClassificationEvaluator: uid=mcEval_f16f1f7867dc, metricName=f1, metricLabel=0.0, beta=1.0, eps=1.0E-15\n",
       "accuracy = 0.9899912947173429\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9899912947173429"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(labelColName)\n",
    "val accuracy = evaluator.evaluate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost_spark_3.0 - Scala",
   "language": "scala",
   "name": "xgboost_spark_3.0_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
