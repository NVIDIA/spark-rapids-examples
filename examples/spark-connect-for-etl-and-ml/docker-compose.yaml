# Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


# YAML anchors for shared configurations
x-spark-common: &spark-common
  networks:
    - spark-network
  volumes:
    - ${WORK_DIR}:/opt/spark/work-dir
    - ${DATA_DIR}:/data/mortgage.input.csv
x-spark-common-env: &spark-common-env
  SPARK_NO_DAEMONIZE: "1"
  SPARK_WORKER_DIR: /opt/spark/work-dir

services:
  # Spark Master Node
  spark-master:
    <<: *spark-common
    image: apache/spark:4.0.0
    container_name: spark-master
    hostname: spark-master
    environment:
      <<: *spark-common-env
    ports:
      - "8080:8080"   # Spark Master Web UI
      - "7077:7077"   # Spark Master Port
    command: /opt/spark/sbin/start-master.sh

  # Spark Worker Node (GPU-enabled)
  spark-worker:
    <<: *spark-common
    image: dais25/spark-worker
    build:
      context: ./spark-worker
      dockerfile: Dockerfile
    container_name: spark-worker
    hostname: spark-worker
    environment:
      <<: *spark-common-env
    ports:
      - "8081:8081"   # Spark Worker WebUI
      - "8889:8889"   # Jupyter Lab Port for nvdashboard
    depends_on:
      - spark-master
    command: >
      bash -c '/opt/spark/sbin/start-worker.sh spark://spark-master:7077  &
      jupyter-lab --port 8889 --no-browser --IdentityProvider.token="" --ServerApp.password="" --ServerApp.ip='0.0.0.0' --ServerApp.allow_origin='*' /home/spark/work/README.ipynb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]

  # Spark Connect Server
  spark-connect-server:
    <<: *spark-common
    image: dais25/spark-connect-server
    build:
      context: ./spark-connect-server
      dockerfile: Dockerfile
    container_name: spark-connect-server
    hostname: spark-connect-server
    environment:
      <<: *spark-common-env
    ports:
      - "4040:4040"               # Spark Driver WebUI
      - "15002:15002"             # Spark Connect grpc
    depends_on:
      - spark-master
      - spark-worker
    command: /opt/spark/sbin/start-connect-server.sh --driver-memory 4G

  spark-connect-client:
    <<: *spark-common
    image: dais25/spark-connect-client
    # hack same uid as spark
    user: "185:185"
    group_add:
      - "users"
    build:
      context: ./spark-connect-client
      dockerfile: Dockerfile
    container_name: spark-connect-client
    hostname: spark-connect-client
    environment:
      - CHOWN_HOME=yes
      - PYDEVD_DISABLE_FILE_VALIDATION=1
      - MPLCONFIGDIR=/opt/spark/work-dir/mpl
    ports:
      - "8888:8888"   # Jupyter Lab Port
    depends_on:
      - spark-connect-server
    command: >
      start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''


networks:
  spark-network:
    driver: bridge
