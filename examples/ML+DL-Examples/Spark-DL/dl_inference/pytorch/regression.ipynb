{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04d288a-f4bf-4256-8ef8-fbc3ab92f24e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Based on: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-create-a-neural-network-for-regression-with-pytorch.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75930360-c5ce-49ef-a69a-da88fa69a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d5bc0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf02ba0a-8384-42b5-917c-53889b4a6471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1d81591db0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5c10ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bee64cf-a44a-4aff-82db-c64ee3a8b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8644e508-5e4c-4cdd-9ed1-9235887d9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, scale_data=True):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            # Apply scaling if necessary\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X.astype(np.float32))\n",
    "            self.y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6b55c3-dc7b-4831-9943-83efd48091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HousingDataset(X, y)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=10, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d868f39d-4695-4110-91d2-6f7a09d73b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.4159,  0.3465,  0.2294, -0.1113, -0.3130,  0.0527, -0.5955,  0.3193],\n",
       "         [-0.3706,  0.5849, -0.1514, -0.2040,  0.3943,  0.0550, -0.8155,  0.6687],\n",
       "         [-0.2024, -0.8454,  0.1928,  0.0087,  0.5435, -0.0279,  0.9449, -1.2679],\n",
       "         [ 0.1064, -1.9578,  0.2968,  0.0363,  2.7556, -0.0217, -0.4925,  0.7685],\n",
       "         [ 0.1057,  1.0616,  0.1675, -0.0081, -0.3651, -0.0372, -0.6751,  0.7186],\n",
       "         [ 0.3343, -1.4811, -0.7187,  0.2041,  0.0967,  0.0529, -0.8483,  0.8234],\n",
       "         [-0.2691,  1.3000, -0.6491, -0.0872,  1.7074, -0.1372, -0.7312,  0.6088],\n",
       "         [-0.0891, -0.3686,  0.0260, -0.1563,  0.3996,  0.0449,  1.1790, -1.3378],\n",
       "         [ 0.1397, -0.2097,  0.1816, -0.1881,  0.4049, -0.0229, -0.7547,  1.2676],\n",
       "         [-0.3399,  0.3465, -0.4621, -0.0519,  0.6115, -0.0284, -0.6704,  0.5189]]),\n",
       " tensor([1.8790, 1.1770, 3.3160, 1.5430, 2.3400, 1.5240, 2.8750, 1.2360, 1.2100,\n",
       "         2.0530])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a441b60-dca4-44d2-bc1c-aa7336d704bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15cff2b4-9d23-4d2b-808a-a5edb8eda135",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the MLP\n",
    "mlp = MLP().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e2db3f9-5db8-4b42-89ad-e77f23c4c1fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch   201: 0.733\n",
      "Loss after mini-batch   401: 0.534\n",
      "Loss after mini-batch   601: 0.403\n",
      "Loss after mini-batch   801: 0.330\n",
      "Loss after mini-batch  1001: 0.269\n",
      "Loss after mini-batch  1201: 0.232\n",
      "Loss after mini-batch  1401: 0.226\n",
      "Loss after mini-batch  1601: 0.223\n",
      "Loss after mini-batch  1801: 0.214\n",
      "Loss after mini-batch  2001: 0.214\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch   201: 0.211\n",
      "Loss after mini-batch   401: 0.205\n",
      "Loss after mini-batch   601: 0.199\n",
      "Loss after mini-batch   801: 0.192\n",
      "Loss after mini-batch  1001: 0.194\n",
      "Loss after mini-batch  1201: 0.196\n",
      "Loss after mini-batch  1401: 0.193\n",
      "Loss after mini-batch  1601: 0.194\n",
      "Loss after mini-batch  1801: 0.187\n",
      "Loss after mini-batch  2001: 0.197\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch   201: 0.190\n",
      "Loss after mini-batch   401: 0.183\n",
      "Loss after mini-batch   601: 0.181\n",
      "Loss after mini-batch   801: 0.190\n",
      "Loss after mini-batch  1001: 0.188\n",
      "Loss after mini-batch  1201: 0.186\n",
      "Loss after mini-batch  1401: 0.193\n",
      "Loss after mini-batch  1601: 0.182\n",
      "Loss after mini-batch  1801: 0.184\n",
      "Loss after mini-batch  2001: 0.188\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch   201: 0.180\n",
      "Loss after mini-batch   401: 0.179\n",
      "Loss after mini-batch   601: 0.183\n",
      "Loss after mini-batch   801: 0.180\n",
      "Loss after mini-batch  1001: 0.176\n",
      "Loss after mini-batch  1201: 0.189\n",
      "Loss after mini-batch  1401: 0.176\n",
      "Loss after mini-batch  1601: 0.185\n",
      "Loss after mini-batch  1801: 0.177\n",
      "Loss after mini-batch  2001: 0.185\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch   201: 0.179\n",
      "Loss after mini-batch   401: 0.177\n",
      "Loss after mini-batch   601: 0.175\n",
      "Loss after mini-batch   801: 0.178\n",
      "Loss after mini-batch  1001: 0.173\n",
      "Loss after mini-batch  1201: 0.178\n",
      "Loss after mini-batch  1401: 0.176\n",
      "Loss after mini-batch  1601: 0.174\n",
      "Loss after mini-batch  1801: 0.179\n",
      "Loss after mini-batch  2001: 0.180\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "for epoch in range(0, 5):  # 5 epochs at maximum\n",
    "\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 200 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace480ba-9316-49a4-9763-dc0f61f66989",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b950a3ed-ffe1-477f-a84f-f71c85dbf9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(mlp.state_dict(), \"housing_model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20fedb5d-c59e-4b0b-ba91-3dd15df1f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = torch.jit.script(mlp)\n",
    "scripted.save(\"housing_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101c0fe-65f1-411e-9192-e8a6b585ba0d",
   "metadata": {},
   "source": [
    "### Load and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7411b00f-88d2-40f5-b716-a26733c968ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_mlp = MLP().to(device)\n",
    "loaded_mlp.load_state_dict(torch.load(\"housing_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e226f449-2931-4492-9003-503cdc61f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d46af47e-db7e-42ee-9bd3-6e7d93850be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7498],\n",
       "        [3.0116],\n",
       "        [1.1925],\n",
       "        [4.0598],\n",
       "        [2.0545],\n",
       "        [2.9072],\n",
       "        [2.0551],\n",
       "        [4.6094],\n",
       "        [1.0068],\n",
       "        [1.1174]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_mlp(testX.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ae2c0f-1da5-45a4-bf32-ed8b562d7907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5000, 2.9130, 0.7020, 5.0000, 1.7970, 2.7080, 2.1470, 5.0000, 0.6000,\n",
       "        0.8480])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "422e317f-c9bd-4f76-9463-7af2935d401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_mlp = torch.jit.load(\"housing_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cda8ec8-644e-4888-bfa0-b79425ece7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7498, 3.0116, 1.1925, 4.0598, 2.0545, 2.9072, 2.0551, 4.6094, 1.0068,\n",
       "        1.1174], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_mlp(testX.to(device)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae694c-0127-4a61-8630-06004866cd14",
   "metadata": {},
   "source": [
    "### Columns as separate input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32e11813-cf75-448e-a46e-f210cc7f52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from inspect import signature\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc7da567-65df-4895-a867-0be05de27ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1d81591db0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3340e01-b3bc-4cce-bb21-890517e1bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dea2ecd8-34e2-4ed5-8bd6-c9d56c951eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, scale_data=True):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            # Apply scaling if necessary\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X.astype(np.float32))\n",
    "            self.y = torch.from_numpy(y.astype(np.float32))\n",
    "            \n",
    "            # Split dataset into separate variables\n",
    "            self.MedInc = self.X[:,0]\n",
    "            self.HouseAge = self.X[:,1]\n",
    "            self.AveRooms = self.X[:,2]\n",
    "            self.AveBedrms = self.X[:,3]\n",
    "            self.Population = self.X[:,4]\n",
    "            self.AveOccup = self.X[:,5]\n",
    "            self.Latitude = self.X[:,6]\n",
    "            self.Longitude = self.X[:,7]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.MedInc)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Note: also returning combined X for ease of use later\n",
    "        return self.MedInc[i], self.HouseAge[i], self.AveRooms[i], self.AveBedrms[i], self.Population[i], self.AveOccup[i], self.Latitude[i], self.Longitude[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f52f4640-e190-413e-8e01-d67492408f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = HousingDataset2(housing.data, housing.target)\n",
    "trainloader2 = torch.utils.data.DataLoader(dataset2, batch_size=10, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2179934-6ae0-4d58-ae2c-d82f90d48074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.4159, -0.3706, -0.2024,  0.1064,  0.1057,  0.3343, -0.2691, -0.0891,\n",
       "          0.1397, -0.3399]),\n",
       " tensor([ 0.3465,  0.5849, -0.8454, -1.9578,  1.0616, -1.4811,  1.3000, -0.3686,\n",
       "         -0.2097,  0.3465]),\n",
       " tensor([ 0.2294, -0.1514,  0.1928,  0.2968,  0.1675, -0.7187, -0.6491,  0.0260,\n",
       "          0.1816, -0.4621]),\n",
       " tensor([-0.1113, -0.2040,  0.0087,  0.0363, -0.0081,  0.2041, -0.0872, -0.1563,\n",
       "         -0.1881, -0.0519]),\n",
       " tensor([-0.3130,  0.3943,  0.5435,  2.7556, -0.3651,  0.0967,  1.7074,  0.3996,\n",
       "          0.4049,  0.6115]),\n",
       " tensor([ 0.0527,  0.0550, -0.0279, -0.0217, -0.0372,  0.0529, -0.1372,  0.0449,\n",
       "         -0.0229, -0.0284]),\n",
       " tensor([-0.5955, -0.8155,  0.9449, -0.4925, -0.6751, -0.8483, -0.7312,  1.1790,\n",
       "         -0.7547, -0.6704]),\n",
       " tensor([ 0.3193,  0.6687, -1.2679,  0.7685,  0.7186,  0.8234,  0.6088, -1.3378,\n",
       "          1.2676,  0.5189]),\n",
       " tensor([1.8790, 1.1770, 3.3160, 1.5430, 2.3400, 1.5240, 2.8750, 1.2360, 1.2100,\n",
       "         2.0530])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainloader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fc3383b-fb1c-4daf-9844-88df7abf799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inc, age, rms, bdrms, pop, occup, lat, lon):       \n",
    "        combined = torch.column_stack((inc, age, rms, bdrms, pop, occup, lat, lon))\n",
    "        return self.layers(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25e9de54-a8da-46da-ba89-177a75227420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MLP\n",
    "mlp2 = MLP2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "631116aa-e496-4125-9970-14aeb816c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(mlp2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "509d0581-5911-4f21-b0c8-b94523f66dd2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch   201: 0.733\n",
      "Loss after mini-batch   401: 0.534\n",
      "Loss after mini-batch   601: 0.403\n",
      "Loss after mini-batch   801: 0.330\n",
      "Loss after mini-batch  1001: 0.269\n",
      "Loss after mini-batch  1201: 0.232\n",
      "Loss after mini-batch  1401: 0.226\n",
      "Loss after mini-batch  1601: 0.223\n",
      "Loss after mini-batch  1801: 0.214\n",
      "Loss after mini-batch  2001: 0.214\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch   201: 0.211\n",
      "Loss after mini-batch   401: 0.205\n",
      "Loss after mini-batch   601: 0.199\n",
      "Loss after mini-batch   801: 0.192\n",
      "Loss after mini-batch  1001: 0.194\n",
      "Loss after mini-batch  1201: 0.196\n",
      "Loss after mini-batch  1401: 0.193\n",
      "Loss after mini-batch  1601: 0.194\n",
      "Loss after mini-batch  1801: 0.187\n",
      "Loss after mini-batch  2001: 0.197\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch   201: 0.190\n",
      "Loss after mini-batch   401: 0.183\n",
      "Loss after mini-batch   601: 0.181\n",
      "Loss after mini-batch   801: 0.190\n",
      "Loss after mini-batch  1001: 0.188\n",
      "Loss after mini-batch  1201: 0.186\n",
      "Loss after mini-batch  1401: 0.193\n",
      "Loss after mini-batch  1601: 0.182\n",
      "Loss after mini-batch  1801: 0.184\n",
      "Loss after mini-batch  2001: 0.188\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch   201: 0.180\n",
      "Loss after mini-batch   401: 0.179\n",
      "Loss after mini-batch   601: 0.183\n",
      "Loss after mini-batch   801: 0.180\n",
      "Loss after mini-batch  1001: 0.176\n",
      "Loss after mini-batch  1201: 0.189\n",
      "Loss after mini-batch  1401: 0.176\n",
      "Loss after mini-batch  1601: 0.185\n",
      "Loss after mini-batch  1801: 0.177\n",
      "Loss after mini-batch  2001: 0.185\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch   201: 0.179\n",
      "Loss after mini-batch   401: 0.177\n",
      "Loss after mini-batch   601: 0.175\n",
      "Loss after mini-batch   801: 0.178\n",
      "Loss after mini-batch  1001: 0.173\n",
      "Loss after mini-batch  1201: 0.178\n",
      "Loss after mini-batch  1401: 0.176\n",
      "Loss after mini-batch  1601: 0.174\n",
      "Loss after mini-batch  1801: 0.179\n",
      "Loss after mini-batch  2001: 0.180\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "for epoch in range(0, 5):  # 5 epochs at maximum\n",
    "\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader2, 0):\n",
    "\n",
    "        # Get and prepare inputs\n",
    "        a,b,c,d,e,f,g,h,targets = data\n",
    "        a,b,c,d,e,f,g,h,targets = a.to(device),b.to(device),c.to(device),d.to(device),e.to(device),f.to(device),g.to(device),h.to(device),targets.to(device)\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp2(a,b,c,d,e,f,g,h)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 200 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5029a35d-8fbd-4a11-b3b0-55bcc0a072dd",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca720ac4-8b4e-489b-844f-d54dd0659755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to housing_model2.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(mlp2.state_dict(), \"housing_model2.pth\")\n",
    "print(\"Saved PyTorch Model State to housing_model2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdcced78-62ee-45fa-b334-6f73a2b21d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = torch.jit.script(mlp2)\n",
    "scripted.save(\"housing_model2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb33c2-2e3f-487c-8b12-c4e8f13a67a2",
   "metadata": {},
   "source": [
    "### Load and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c54b12f2-9981-477b-8c21-a652a1736fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e,f,g,h,targets = next(iter(trainloader2))\n",
    "a,b,c,d,e,f,g,h,targets = a.to(device), b.to(device), c.to(device), d.to(device), e.to(device), f.to(device), g.to(device), h.to(device), targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31b2fa69-9a8a-4409-8652-23c547536e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_mlp2 = MLP2().to(device)\n",
    "loaded_mlp2.load_state_dict(torch.load(\"housing_model2.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80a21d52-ea98-4c74-98e8-1e088cdfa742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8778],\n",
       "        [0.6233],\n",
       "        [3.9021],\n",
       "        [2.4543],\n",
       "        [1.0209],\n",
       "        [1.8093],\n",
       "        [1.4593],\n",
       "        [3.2933],\n",
       "        [2.9263],\n",
       "        [1.4790]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_mlp2(a,b,c,d,e,f,g,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90d29fb0-5923-4684-8aa6-62618e8f1ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(inc, age, rms, bdrms, pop, occup, lat, lon)\n"
     ]
    }
   ],
   "source": [
    "print(signature(loaded_mlp2.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "165772b2-8277-4b6e-a178-c99ea2a031fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_mlp2 = torch.jit.load(\"housing_model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e53d927e-fa6d-419d-b570-8ca9b0756812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8778],\n",
       "        [0.6233],\n",
       "        [3.9021],\n",
       "        [2.4543],\n",
       "        [1.0209],\n",
       "        [1.8093],\n",
       "        [1.4593],\n",
       "        [3.2933],\n",
       "        [2.9263],\n",
       "        [1.4790]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_mlp2(a,b,c,d,e,f,g,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13631d1f-2c71-4bee-afcb-bd3b55ec87c5",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9937e-2c70-4d67-b95f-4d9d5ab17c12",
   "metadata": {},
   "source": [
    "### Convert dataset to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf35da14-61a3-4e7b-9d4f-086bf5e931b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95148019-ea95-40e5-a529-fcdb9a06f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(housing.data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f82d957c-6747-4408-aac8-45305afbfe5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.344766</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.628559</td>\n",
       "      <td>-0.153758</td>\n",
       "      <td>-0.974429</td>\n",
       "      <td>-0.049597</td>\n",
       "      <td>1.052549</td>\n",
       "      <td>-1.327837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.332238</td>\n",
       "      <td>-0.607019</td>\n",
       "      <td>0.327041</td>\n",
       "      <td>-0.263336</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>-0.092512</td>\n",
       "      <td>1.043185</td>\n",
       "      <td>-1.322845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.782699</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>1.155620</td>\n",
       "      <td>-0.049016</td>\n",
       "      <td>-0.820777</td>\n",
       "      <td>-0.025843</td>\n",
       "      <td>1.038502</td>\n",
       "      <td>-1.332825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932967</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.156966</td>\n",
       "      <td>-0.049833</td>\n",
       "      <td>-0.766028</td>\n",
       "      <td>-0.050329</td>\n",
       "      <td>1.038502</td>\n",
       "      <td>-1.337818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012881</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.344711</td>\n",
       "      <td>-0.032906</td>\n",
       "      <td>-0.759847</td>\n",
       "      <td>-0.085616</td>\n",
       "      <td>1.038502</td>\n",
       "      <td>-1.337818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>-1.216128</td>\n",
       "      <td>-0.289187</td>\n",
       "      <td>-0.155023</td>\n",
       "      <td>0.077354</td>\n",
       "      <td>-0.512592</td>\n",
       "      <td>-0.049110</td>\n",
       "      <td>1.801647</td>\n",
       "      <td>-0.758824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>-0.691593</td>\n",
       "      <td>-0.845393</td>\n",
       "      <td>0.276881</td>\n",
       "      <td>0.462365</td>\n",
       "      <td>-0.944405</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>1.806329</td>\n",
       "      <td>-0.818721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>-1.142593</td>\n",
       "      <td>-0.924851</td>\n",
       "      <td>-0.090318</td>\n",
       "      <td>0.049414</td>\n",
       "      <td>-0.369537</td>\n",
       "      <td>-0.071734</td>\n",
       "      <td>1.778238</td>\n",
       "      <td>-0.823714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>-1.054583</td>\n",
       "      <td>-0.845393</td>\n",
       "      <td>-0.040211</td>\n",
       "      <td>0.158778</td>\n",
       "      <td>-0.604429</td>\n",
       "      <td>-0.091225</td>\n",
       "      <td>1.778238</td>\n",
       "      <td>-0.873626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>-0.780129</td>\n",
       "      <td>-1.004309</td>\n",
       "      <td>-0.070443</td>\n",
       "      <td>0.138403</td>\n",
       "      <td>-0.033977</td>\n",
       "      <td>-0.043682</td>\n",
       "      <td>1.750146</td>\n",
       "      <td>-0.833695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "0      2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597   \n",
       "1      2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512   \n",
       "2      1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843   \n",
       "3      0.932967  1.856182  0.156966  -0.049833   -0.766028 -0.050329   \n",
       "4     -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616   \n",
       "...         ...       ...       ...        ...         ...       ...   \n",
       "20635 -1.216128 -0.289187 -0.155023   0.077354   -0.512592 -0.049110   \n",
       "20636 -0.691593 -0.845393  0.276881   0.462365   -0.944405  0.005021   \n",
       "20637 -1.142593 -0.924851 -0.090318   0.049414   -0.369537 -0.071734   \n",
       "20638 -1.054583 -0.845393 -0.040211   0.158778   -0.604429 -0.091225   \n",
       "20639 -0.780129 -1.004309 -0.070443   0.138403   -0.033977 -0.043682   \n",
       "\n",
       "       Latitude  Longitude  \n",
       "0      1.052549  -1.327837  \n",
       "1      1.043185  -1.322845  \n",
       "2      1.038502  -1.332825  \n",
       "3      1.038502  -1.337818  \n",
       "4      1.038502  -1.337818  \n",
       "...         ...        ...  \n",
       "20635  1.801647  -0.758824  \n",
       "20636  1.806329  -0.818721  \n",
       "20637  1.778238  -0.823714  \n",
       "20638  1.778238  -0.873626  \n",
       "20639  1.750146  -0.833695  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = pd.DataFrame(X, columns=housing.feature_names)\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ba338cd-76d2-46bd-baf5-7d18a339a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pdf.to_dict('series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "224b5036-d2ed-4edf-975f-66127862343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b32ea98-a7f1-4011-a067-700377f1717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        float32\n",
       "HouseAge      float32\n",
       "AveRooms      float32\n",
       "AveBedrms     float32\n",
       "Population    float32\n",
       "AveOccup      float32\n",
       "Latitude      float32\n",
       "Longitude     float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6388cce9-6469-4f5a-898a-1a0b74eec438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 16:15:22 WARN Utils: Your hostname, dgx2h0194.spark.sjc4.nvmetal.net resolves to a loopback address: 127.0.1.1; using 10.150.30.2 instead (on interface enp134s0f0np0)\n",
      "24/09/25 16:15:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 16:15:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------+------------+-----------+------------+---------+----------+\n",
      "|      MedInc|  HouseAge|    AveRooms|   AveBedrms| Population|    AveOccup| Latitude| Longitude|\n",
      "+------------+----------+------------+------------+-----------+------------+---------+----------+\n",
      "|    2.344766| 0.9821427|  0.62855947| -0.15375753|-0.97442853|-0.049596533|1.0525488|-1.3278369|\n",
      "|   2.3322382|-0.6070189|  0.32704142| -0.26333576|  0.8614389| -0.09251223|1.0431849|-1.3228445|\n",
      "|   1.7826993| 1.8561815|   1.1556205|-0.049016476|-0.82077736|-0.025842525| 1.038502|-1.3328254|\n",
      "|  0.93296736| 1.8561815|  0.15696616|-0.049833003|-0.76602805|-0.050329294| 1.038502|-1.3378178|\n",
      "|-0.012881001| 1.8561815|  0.34471077|-0.032905966| -0.7598467| -0.08561575| 1.038502|-1.3378178|\n",
      "| 0.087446585| 1.8561815| -0.26972958| 0.014669393|-0.89407074|-0.089618415| 1.038502|-1.3378178|\n",
      "| -0.11136628| 1.8561815| -0.20091766| -0.30663314| -0.2927116| -0.09072491|1.0338209|-1.3378178|\n",
      "| -0.39513668| 1.8561815|   -0.255232|-0.073541574|-0.23707923| -0.12347647|1.0338209|-1.3378178|\n",
      "| -0.94235915| 1.0616008| -0.45870265|  0.04425391|-0.19380963| -0.10049919|1.0338209|-1.3428102|\n",
      "| -0.09446957| 1.8561815| -0.18528317| -0.22468716|  0.1108437| -0.08650142|1.0338209|-1.3378178|\n",
      "| -0.35139465| 1.8561815| 0.019648364|-0.036026947|-0.45519334| -0.07769971| 1.038502|-1.3428102|\n",
      "| -0.31591678| 1.8561815| -0.26535577| -0.15225175| 0.06934021| -0.09836594| 1.038502|-1.3428102|\n",
      "| -0.41882363| 1.8561815|-0.042985205| -0.17694615|-0.28917935| -0.06975886| 1.038502|-1.3428102|\n",
      "|  -0.6301118| 1.8561815|  -0.5775806| 0.002165105| -0.9541183| -0.10474847|1.0338209|-1.3428102|\n",
      "|  -1.0285273| 1.8561815|   -0.471319|  -0.1835785|-0.18851131| -0.10743675| 1.038502|-1.3428102|\n",
      "|  -0.9188827| 1.6972654|  -0.4795964| -0.05213217|-0.64328367|-0.041451186| 1.038502|-1.3428102|\n",
      "|   -0.576737| 1.8561815|  0.20636784| -0.10199789| -0.5585106| -0.06498151| 1.038502|-1.3477987|\n",
      "| -0.92140937| 1.8561815|  -0.5562374| -0.27364123| -0.6865533| -0.08974189| 1.038502|-1.3477987|\n",
      "| -0.98936474| 1.6972654|-0.034486752|-0.022697322| -0.3845491| -0.06815911|1.0338209|-1.3428102|\n",
      "|  -0.6671161| 1.8561815| 0.014734507|-0.027513746|  -0.649465|-0.054070402|1.0338209|-1.3477987|\n",
      "+------------+----------+------------+------------+-----------+------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "num_threads = 6\n",
    "\n",
    "# Creating a local Spark session for demonstration, in case it hasn't already been created.\n",
    "\n",
    "_config = {\n",
    "    \"spark.master\": f\"local[{num_threads}]\",\n",
    "    \"spark.driver.host\": \"127.0.0.1\",\n",
    "    \"spark.task.maxFailures\": \"1\",\n",
    "    \"spark.driver.memory\": \"8g\",\n",
    "    \"spark.executor.memory\": \"8g\",\n",
    "    \"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\": \"false\",\n",
    "    \"spark.sql.pyspark.jvmStacktrace.enabled\": \"true\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "    \"spark.python.worker.reuse\": \"true\",\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"spark-dl-example\")\n",
    "for key, value in _config.items():\n",
    "    spark = spark.config(key, value)\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Spark is somehow auto-converting Pandas float32 to DoubleType(), so forcing FloatType()\n",
    "schema = StructType([\n",
    "StructField(\"MedInc\",FloatType(),True),\n",
    "StructField(\"HouseAge\",FloatType(),True),\n",
    "StructField(\"AveRooms\",FloatType(),True),\n",
    "StructField(\"AveBedrms\",FloatType(),True),\n",
    "StructField(\"Population\",FloatType(),True),\n",
    "StructField(\"AveOccup\",FloatType(),True),\n",
    "StructField(\"Latitude\",FloatType(),True),\n",
    "StructField(\"Longitude\",FloatType(),True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(pdf, schema=schema)\n",
    "df.show(truncate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b33d367-fbf9-4918-b755-5447125547c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('MedInc', FloatType(), True), StructField('HouseAge', FloatType(), True), StructField('AveRooms', FloatType(), True), StructField('AveBedrms', FloatType(), True), StructField('Population', FloatType(), True), StructField('AveOccup', FloatType(), True), StructField('Latitude', FloatType(), True), StructField('Longitude', FloatType(), True)])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9932f-c21f-4eda-954e-26c38925ff84",
   "metadata": {},
   "source": [
    "### Save DataFrame as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "751bff7a-b687-4184-b3fa-b5f5b46ef5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"california_housing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bb9ee-27fd-4604-89f8-6b438af0b984",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "986d1a97-ea84-4707-b94a-78498780c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import array, struct, col\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e40c266-24de-454d-a776-f3716ba50e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"california_housing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac802fb6-f159-4776-b55d-b9c421e8c57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b8de001-e791-4a91-bd6f-c80bdf1c4472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+\n",
      "|     MedInc|   HouseAge|    AveRooms|   AveBedrms| Population|    AveOccup|   Latitude|   Longitude|\n",
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+\n",
      "|  1.0956708|-0.20972852|  0.31022108| -0.18931988| 0.04726388| -0.04799644| -0.5299223| -0.08999105|\n",
      "|  1.3705455|-0.44810274|    1.084947|  0.20813987|-0.63621926|-0.030498274| -0.5533313| -0.10496436|\n",
      "|-0.38650405| 0.74376845|  -0.4251157| -0.20934148|-0.55144614| -0.10040703|-0.55801415| -0.08001011|\n",
      "| 0.34589827|  0.5053942|  -0.4629227|  -0.1270842|-0.03750922|  -0.0846248|-0.56269526| -0.08001011|\n",
      "|-0.24527684|-0.20972852|  -0.3831463|-0.024081098| 0.38459018| -0.10704114|-0.55801415|-0.084998675|\n",
      "|-0.71417433|  0.1081038|  -0.4463608| 0.089077316|-0.29536074|-0.113285266|-0.56269526|-0.075017735|\n",
      "| -0.6849603|-0.13027044| -0.92365605| -0.29838318| -0.5726394| -0.05663764|-0.56269526|-0.075017735|\n",
      "|-0.10462865|   1.379433|  -0.4576288| -0.07466751| -0.6000141| -0.06395305|-0.56269526|-0.075017735|\n",
      "|-0.66811633|  0.5848523|   -0.657354| -0.16929275|-0.79870105| -0.13064373|-0.56269526|-0.075017735|\n",
      "|-0.80286896| 0.34647804|  -1.0271798| -0.07952393| -0.5938327|-0.091999345|-0.56269526|-0.075017735|\n",
      "| -0.8807729| -0.8453931| -0.82756793|-0.045432895| -0.6574125| -0.10614947|-0.56269526| -0.07002536|\n",
      "|-0.37602907| 0.18756187|  -0.8635072| -0.20399933|-0.15230612|-0.053884454| -0.5673781| -0.07002536|\n",
      "| -0.6462716|  1.4588912|  -0.5396882| -0.02265808|-0.56115973| -0.09757202|-0.56269526| -0.07002536|\n",
      "|  1.3312252|  1.6972654|   0.7846057|  0.11038007|-0.14965697|-0.022669494|-0.55801415|-0.075017735|\n",
      "| 0.13734722|  1.8561815|-0.102805294|  -0.2753284|-0.63092095| -0.10281715|-0.55801415| -0.07002536|\n",
      "|  0.6757792| 0.66431034| -0.35916984| -0.30885154|-0.66006166| -0.09292161|-0.56269526| -0.06503299|\n",
      "|-0.18390115|  1.5383493| -0.23601562|  -0.0384139|-0.37130332| -0.10095731|-0.56269526| -0.07002536|\n",
      "| -0.6227951|  0.8232265| -0.72581476|  0.09524004|-0.58941746| -0.11721337|-0.56269526| -0.06503299|\n",
      "| -0.9188827|  1.8561815| -0.74252385| -0.07211478| -0.8949538| -0.14981508|-0.56269526| -0.06503299|\n",
      "|  2.0294127| 0.26701993|  0.66258544| -0.03582772|-0.10727042| -0.05741223|-0.54396737| -0.06503299|\n",
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650dda22-31b7-419b-96d4-387a036f3b07",
   "metadata": {},
   "source": [
    "### Using TorchScript Model (single input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d608e2f-66a8-44b5-9cde-5f7837bf4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absolute path to model\n",
    "model_dir = \"{}/housing_model.pt\".format(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2f45f5d-c941-4197-a274-1eec2af3fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using {} device\".format(device))\n",
    "    \n",
    "    scripted_mlp = torch.jit.load(model_dir)\n",
    "    scripted_mlp.to(device)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        torch_inputs = torch.from_numpy(inputs).to(device)\n",
    "        outputs = scripted_mlp(torch_inputs) # .flatten()\n",
    "        return outputs.detach().cpu().numpy()\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "220a00a4-e842-4f5d-a4b3-7693d09e2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=FloatType(),\n",
    "                             input_tensor_shapes=[[8]],\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f3bf287-8ffc-4456-8772-e97c418d6aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda device                                                   (0 + 6) / 6]\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.2 ms, sys: 12.9 ms, total: 53.1 ms\n",
      "Wall time: 4.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", classify(struct(*columns)))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cd23b71-296d-4ce7-b56c-567cc2eec79c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 186 ms, sys: 24.2 ms, total: 210 ms\n",
      "Wall time: 550 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", classify(array(*columns)))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13c52980-fc55-4e81-ae54-b476b98f11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should raise ValueError\n",
    "# preds = df.withColumn(\"preds\", classify(*columns))\n",
    "# results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "764a40d8-25f7-425c-ba03-fe8c45f4b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "|     MedInc|   HouseAge|    AveRooms|   AveBedrms| Population|    AveOccup|   Latitude|   Longitude|    preds|\n",
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "|  1.0956708|-0.20972852|  0.31022108| -0.18931988| 0.04726388| -0.04799644| -0.5299223| -0.08999105|3.5726128|\n",
      "|  1.3705455|-0.44810274|    1.084947|  0.20813987|-0.63621926|-0.030498274| -0.5533313| -0.10496436|  3.82839|\n",
      "|-0.38650405| 0.74376845|  -0.4251157| -0.20934148|-0.55144614| -0.10040703|-0.55801415| -0.08001011|2.6030526|\n",
      "| 0.34589827|  0.5053942|  -0.4629227|  -0.1270842|-0.03750922|  -0.0846248|-0.56269526| -0.08001011|3.2851157|\n",
      "|-0.24527684|-0.20972852|  -0.3831463|-0.024081098| 0.38459018| -0.10704114|-0.55801415|-0.084998675| 2.791944|\n",
      "|-0.71417433|  0.1081038|  -0.4463608| 0.089077316|-0.29536074|-0.113285266|-0.56269526|-0.075017735|2.4510148|\n",
      "| -0.6849603|-0.13027044| -0.92365605| -0.29838318| -0.5726394| -0.05663764|-0.56269526|-0.075017735|2.2057915|\n",
      "|-0.10462865|   1.379433|  -0.4576288| -0.07466751| -0.6000141| -0.06395305|-0.56269526|-0.075017735|2.9585156|\n",
      "|-0.66811633|  0.5848523|   -0.657354| -0.16929275|-0.79870105| -0.13064373|-0.56269526|-0.075017735|2.4481673|\n",
      "|-0.80286896| 0.34647804|  -1.0271798| -0.07952393| -0.5938327|-0.091999345|-0.56269526|-0.075017735|2.4634523|\n",
      "| -0.8807729| -0.8453931| -0.82756793|-0.045432895| -0.6574125| -0.10614947|-0.56269526| -0.07002536|2.2022953|\n",
      "|-0.37602907| 0.18756187|  -0.8635072| -0.20399933|-0.15230612|-0.053884454| -0.5673781| -0.07002536|2.6299968|\n",
      "| -0.6462716|  1.4588912|  -0.5396882| -0.02265808|-0.56115973| -0.09757202|-0.56269526| -0.07002536| 2.528467|\n",
      "|  1.3312252|  1.6972654|   0.7846057|  0.11038007|-0.14965697|-0.022669494|-0.55801415|-0.075017735|4.3057375|\n",
      "| 0.13734722|  1.8561815|-0.102805294|  -0.2753284|-0.63092095| -0.10281715|-0.55801415| -0.07002536| 3.271628|\n",
      "|  0.6757792| 0.66431034| -0.35916984| -0.30885154|-0.66006166| -0.09292161|-0.56269526| -0.06503299| 3.558448|\n",
      "|-0.18390115|  1.5383493| -0.23601562|  -0.0384139|-0.37130332| -0.10095731|-0.56269526| -0.07002536|2.9498477|\n",
      "| -0.6227951|  0.8232265| -0.72581476|  0.09524004|-0.58941746| -0.11721337|-0.56269526| -0.06503299| 2.653997|\n",
      "| -0.9188827|  1.8561815| -0.74252385| -0.07211478| -0.8949538| -0.14981508|-0.56269526| -0.06503299| 2.464116|\n",
      "|  2.0294127| 0.26701993|  0.66258544| -0.03582772|-0.10727042| -0.05741223|-0.54396737| -0.06503299| 4.484191|\n",
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773953dd-e645-4848-8f33-ed82f8242a43",
   "metadata": {},
   "source": [
    "### Using TorchScript Model (separate input variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a69a9d2-5c7f-4e71-bb65-ae51927ccacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7214e2ac-fd2c-473e-a9c7-a65488570b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"california_housing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ee170b9-8ba6-4681-a10c-4cea71c1be15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b7af043-5f20-49c7-bed6-39a9d13988e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absolute path to model\n",
    "model2_dir = \"{}/housing_model2.pt\".format(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "104b2378-e191-4560-9a2e-276b8dcf0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using {} device\".format(device))\n",
    "    scripted_mlp = torch.jit.load(model2_dir)\n",
    "    scripted_mlp.to(device)\n",
    "    \n",
    "    def predict(inc, age, rms, bdrms, pop, occ, lat, lon):\n",
    "        outputs = scripted_mlp(\n",
    "            torch.from_numpy(inc).to(device),\n",
    "            torch.from_numpy(age).to(device),\n",
    "            torch.from_numpy(rms).to(device),\n",
    "            torch.from_numpy(bdrms).to(device),\n",
    "            torch.from_numpy(pop).to(device),\n",
    "            torch.from_numpy(occ).to(device),\n",
    "            torch.from_numpy(lat).to(device),\n",
    "            torch.from_numpy(lon).to(device),\n",
    "        )\n",
    "        return outputs.detach().cpu().numpy()\n",
    "\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "020056dc-f8b0-483a-88eb-7e1ff2a0fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=FloatType(),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b73518e-04ec-49c7-bf1e-93520d94028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device\n",
      "Using cuda device=========================================>         (5 + 1) / 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.2 ms, sys: 8.87 ms, total: 45.1 ms\n",
      "Wall time: 2.94 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df.withColumn(\"preds\", classify(struct(*columns)))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86b56805-a211-43cb-878d-78957b08f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 ms, sys: 4.29 ms, total: 37.8 ms\n",
      "Wall time: 524 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", classify(*columns))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5032b474-db92-4f04-b732-8b9d418cf211",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "|     MedInc|   HouseAge|    AveRooms|   AveBedrms| Population|    AveOccup|   Latitude|   Longitude|    preds|\n",
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "|  1.0956708|-0.20972852|  0.31022108| -0.18931988| 0.04726388| -0.04799644| -0.5299223| -0.08999105|3.5726128|\n",
      "|  1.3705455|-0.44810274|    1.084947|  0.20813987|-0.63621926|-0.030498274| -0.5533313| -0.10496436|  3.82839|\n",
      "|-0.38650405| 0.74376845|  -0.4251157| -0.20934148|-0.55144614| -0.10040703|-0.55801415| -0.08001011|2.6030526|\n",
      "| 0.34589827|  0.5053942|  -0.4629227|  -0.1270842|-0.03750922|  -0.0846248|-0.56269526| -0.08001011|3.2851157|\n",
      "|-0.24527684|-0.20972852|  -0.3831463|-0.024081098| 0.38459018| -0.10704114|-0.55801415|-0.084998675| 2.791944|\n",
      "|-0.71417433|  0.1081038|  -0.4463608| 0.089077316|-0.29536074|-0.113285266|-0.56269526|-0.075017735|2.4510148|\n",
      "| -0.6849603|-0.13027044| -0.92365605| -0.29838318| -0.5726394| -0.05663764|-0.56269526|-0.075017735|2.2057915|\n",
      "|-0.10462865|   1.379433|  -0.4576288| -0.07466751| -0.6000141| -0.06395305|-0.56269526|-0.075017735|2.9585156|\n",
      "|-0.66811633|  0.5848523|   -0.657354| -0.16929275|-0.79870105| -0.13064373|-0.56269526|-0.075017735|2.4481673|\n",
      "|-0.80286896| 0.34647804|  -1.0271798| -0.07952393| -0.5938327|-0.091999345|-0.56269526|-0.075017735|2.4634523|\n",
      "| -0.8807729| -0.8453931| -0.82756793|-0.045432895| -0.6574125| -0.10614947|-0.56269526| -0.07002536|2.2022953|\n",
      "|-0.37602907| 0.18756187|  -0.8635072| -0.20399933|-0.15230612|-0.053884454| -0.5673781| -0.07002536|2.6299968|\n",
      "| -0.6462716|  1.4588912|  -0.5396882| -0.02265808|-0.56115973| -0.09757202|-0.56269526| -0.07002536| 2.528467|\n",
      "|  1.3312252|  1.6972654|   0.7846057|  0.11038007|-0.14965697|-0.022669494|-0.55801415|-0.075017735|4.3057375|\n",
      "| 0.13734722|  1.8561815|-0.102805294|  -0.2753284|-0.63092095| -0.10281715|-0.55801415| -0.07002536| 3.271628|\n",
      "|  0.6757792| 0.66431034| -0.35916984| -0.30885154|-0.66006166| -0.09292161|-0.56269526| -0.06503299| 3.558448|\n",
      "|-0.18390115|  1.5383493| -0.23601562|  -0.0384139|-0.37130332| -0.10095731|-0.56269526| -0.07002536|2.9498477|\n",
      "| -0.6227951|  0.8232265| -0.72581476|  0.09524004|-0.58941746| -0.11721337|-0.56269526| -0.06503299| 2.653997|\n",
      "| -0.9188827|  1.8561815| -0.74252385| -0.07211478| -0.8949538| -0.14981508|-0.56269526| -0.06503299| 2.464116|\n",
      "|  2.0294127| 0.26701993|  0.66258544| -0.03582772|-0.10727042| -0.05741223|-0.54396737| -0.06503299| 4.484191|\n",
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1445875-fa94-4318-9bb8-0b9bfab0a795",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9ab4cdf-8103-447e-9ac8-944e2e527239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6632636e-67a3-406c-832c-758aac4245fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy custom model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir models\n",
    "cp -r models_config/housing_model models\n",
    "mkdir -p models/housing_model/1\n",
    "cp housing_model.pt models/housing_model/1/model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f8022-d9a4-4f60-bfa0-c37241d24292",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6fd1612-de6a-461c-a2ad-1a3fcd277d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> starting triton: 07b6cb3f8bb2                                  (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"64M\",\n",
    "            volumes={triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "            \n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8514e-01de-481f-86aa-75afd99bcc7c",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5eae04bc-75ca-421a-87c8-ac507ce1f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"california_housing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b350bd8e-9b8f-4511-9ddf-76d917b21b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69b343ec-688d-4e4d-985e-db72beaaf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool_),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3e64fda-117b-4810-a9a2-dd498239496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"housing_model\"),\n",
    "                             return_type=FloatType(),\n",
    "                             input_tensor_shapes=[[8]],\n",
    "                             batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a24149a5-3adc-4089-8769-13cf1e44547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 170 ms, sys: 4.32 ms, total: 174 ms\n",
      "Wall time: 1.09 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df.withColumn(\"preds\", classify(struct(*columns)))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df2ce39f-30af-491a-8472-800fb1ce8458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.1 ms, sys: 2.77 ms, total: 40.9 ms\n",
      "Wall time: 261 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.withColumn(\"preds\", classify(array(*columns)))\n",
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca6f3eaa-9569-45d0-88bf-9aa0757e1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should raise ValueError\n",
    "# predictions = df.withColumn(\"preds\", classify(*columns))\n",
    "# preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b79c62c8-e1e8-4467-8aef-8939c31833b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "|     MedInc|   HouseAge|    AveRooms|   AveBedrms| Population|    AveOccup|   Latitude|   Longitude|    preds|\n",
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "|  1.0956708|-0.20972852|  0.31022108| -0.18931988| 0.04726388| -0.04799644| -0.5299223| -0.08999105|3.5726128|\n",
      "|  1.3705455|-0.44810274|    1.084947|  0.20813987|-0.63621926|-0.030498274| -0.5533313| -0.10496436|3.8283901|\n",
      "|-0.38650405| 0.74376845|  -0.4251157| -0.20934148|-0.55144614| -0.10040703|-0.55801415| -0.08001011|2.6030524|\n",
      "| 0.34589827|  0.5053942|  -0.4629227|  -0.1270842|-0.03750922|  -0.0846248|-0.56269526| -0.08001011|3.2851157|\n",
      "|-0.24527684|-0.20972852|  -0.3831463|-0.024081098| 0.38459018| -0.10704114|-0.55801415|-0.084998675|2.7919443|\n",
      "|-0.71417433|  0.1081038|  -0.4463608| 0.089077316|-0.29536074|-0.113285266|-0.56269526|-0.075017735| 2.451015|\n",
      "| -0.6849603|-0.13027044| -0.92365605| -0.29838318| -0.5726394| -0.05663764|-0.56269526|-0.075017735|2.2057915|\n",
      "|-0.10462865|   1.379433|  -0.4576288| -0.07466751| -0.6000141| -0.06395305|-0.56269526|-0.075017735| 2.958516|\n",
      "|-0.66811633|  0.5848523|   -0.657354| -0.16929275|-0.79870105| -0.13064373|-0.56269526|-0.075017735|2.4481673|\n",
      "|-0.80286896| 0.34647804|  -1.0271798| -0.07952393| -0.5938327|-0.091999345|-0.56269526|-0.075017735|2.4634526|\n",
      "| -0.8807729| -0.8453931| -0.82756793|-0.045432895| -0.6574125| -0.10614947|-0.56269526| -0.07002536| 2.202295|\n",
      "|-0.37602907| 0.18756187|  -0.8635072| -0.20399933|-0.15230612|-0.053884454| -0.5673781| -0.07002536|2.6299965|\n",
      "| -0.6462716|  1.4588912|  -0.5396882| -0.02265808|-0.56115973| -0.09757202|-0.56269526| -0.07002536| 2.528467|\n",
      "|  1.3312252|  1.6972654|   0.7846057|  0.11038007|-0.14965697|-0.022669494|-0.55801415|-0.075017735| 4.305738|\n",
      "| 0.13734722|  1.8561815|-0.102805294|  -0.2753284|-0.63092095| -0.10281715|-0.55801415| -0.07002536|3.2716281|\n",
      "|  0.6757792| 0.66431034| -0.35916984| -0.30885154|-0.66006166| -0.09292161|-0.56269526| -0.06503299| 3.558448|\n",
      "|-0.18390115|  1.5383493| -0.23601562|  -0.0384139|-0.37130332| -0.10095731|-0.56269526| -0.07002536| 2.949848|\n",
      "| -0.6227951|  0.8232265| -0.72581476|  0.09524004|-0.58941746| -0.11721337|-0.56269526| -0.06503299| 2.653997|\n",
      "| -0.9188827|  1.8561815| -0.74252385| -0.07211478| -0.8949538| -0.14981508|-0.56269526| -0.06503299| 2.464116|\n",
      "|  2.0294127| 0.26701993|  0.66258544| -0.03582772|-0.10727042| -0.05741223|-0.54396737| -0.06503299| 4.484191|\n",
      "+-----------+-----------+------------+------------+-----------+------------+-----------+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec23b0-eaf2-4b6a-aa38-7a09873ed6eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15e9b3df-f3c9-46bb-bbeb-42496f7663de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> stopping containers: ['07b6cb3f8bb2']\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0138a029-87c5-497f-ac5c-3eed0e11b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24147e7-5695-44a0-9961-b94bfba1cfff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
