{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e87c927",
   "metadata": {},
   "source": [
    "# PySpark PyTorch Inference\n",
    "\n",
    "### Image Classification\n",
    "Based on: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html  \n",
    "\n",
    "Also demonstrates accelerated inference on GPU with Torch-TensorRT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d714f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c942a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:09<00:00, 2705809.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 194153.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:04<00:00, 895139.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 7445612.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a89aa8e-ef62-4aac-8260-4b004f2c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a97111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) torch.float32\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af350",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512d0bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c1b7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d9076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = torch.flatten(X, start_dim=1, end_dim=-1)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c5650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            X = torch.flatten(X, start_dim=1, end_dim=-1)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854608e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302226  [   64/60000]\n",
      "loss: 2.292731  [ 6464/60000]\n",
      "loss: 2.268726  [12864/60000]\n",
      "loss: 2.258445  [19264/60000]\n",
      "loss: 2.246346  [25664/60000]\n",
      "loss: 2.218145  [32064/60000]\n",
      "loss: 2.220705  [38464/60000]\n",
      "loss: 2.184827  [44864/60000]\n",
      "loss: 2.177805  [51264/60000]\n",
      "loss: 2.150883  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.142085 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.154124  [   64/60000]\n",
      "loss: 2.145146  [ 6464/60000]\n",
      "loss: 2.078245  [12864/60000]\n",
      "loss: 2.094302  [19264/60000]\n",
      "loss: 2.034551  [25664/60000]\n",
      "loss: 1.979704  [32064/60000]\n",
      "loss: 2.002105  [38464/60000]\n",
      "loss: 1.913208  [44864/60000]\n",
      "loss: 1.922536  [51264/60000]\n",
      "loss: 1.854262  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 1.846595 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.882692  [   64/60000]\n",
      "loss: 1.854482  [ 6464/60000]\n",
      "loss: 1.723529  [12864/60000]\n",
      "loss: 1.771578  [19264/60000]\n",
      "loss: 1.648987  [25664/60000]\n",
      "loss: 1.608422  [32064/60000]\n",
      "loss: 1.631619  [38464/60000]\n",
      "loss: 1.525892  [44864/60000]\n",
      "loss: 1.562530  [51264/60000]\n",
      "loss: 1.463108  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.477499 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.546377  [   64/60000]\n",
      "loss: 1.519038  [ 6464/60000]\n",
      "loss: 1.359307  [12864/60000]\n",
      "loss: 1.441518  [19264/60000]\n",
      "loss: 1.316529  [25664/60000]\n",
      "loss: 1.316562  [32064/60000]\n",
      "loss: 1.335615  [38464/60000]\n",
      "loss: 1.252431  [44864/60000]\n",
      "loss: 1.299245  [51264/60000]\n",
      "loss: 1.205835  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.228535 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.304784  [   64/60000]\n",
      "loss: 1.295127  [ 6464/60000]\n",
      "loss: 1.120219  [12864/60000]\n",
      "loss: 1.235545  [19264/60000]\n",
      "loss: 1.106600  [25664/60000]\n",
      "loss: 1.131119  [32064/60000]\n",
      "loss: 1.159875  [38464/60000]\n",
      "loss: 1.085509  [44864/60000]\n",
      "loss: 1.137354  [51264/60000]\n",
      "loss: 1.057327  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.074583 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97839",
   "metadata": {},
   "source": [
    "### Save Model State Dict\n",
    "This saves the serialized object to disk using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d5d24de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "print(\"Saved PyTorch Model State to model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac221ca7-e227-4c8c-8577-1eeda4a61fc7",
   "metadata": {},
   "source": [
    "### Save Model as TorchScript\n",
    "This saves an [intermediate representation of the compute graph](https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format), which does not require pickle (or even python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d9b3a45-7618-43e4-8bd3-8bb317a484d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TorchScript Model to ts_model.pt\n"
     ]
    }
   ],
   "source": [
    "scripted = torch.jit.script(model)\n",
    "scripted.save(\"ts_model.pt\")\n",
    "print(\"Saved TorchScript Model to ts_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee8916-f437-4a2a-9bf4-14ff5376d305",
   "metadata": {},
   "source": [
    "### Load Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe3b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_state = NeuralNetwork().to(device)\n",
    "model_from_state.load_state_dict(torch.load(\"model.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c405bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "model_from_state.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = torch.flatten(x.to(device), start_dim=1, end_dim=-1)\n",
    "    pred = model_from_state(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c482a-1c5d-4bf2-bc3f-8a4e53d442b5",
   "metadata": {},
   "source": [
    "### Load Torchscript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef3c419e-d384-446c-b07b-1af93e07d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to original device (GPU) and move to CPU. \n",
    "ts_model = torch.jit.load(\"ts_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "038af830-a360-45eb-ab4e-b1adab0af164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = ts_model(torch.flatten(x.to(device), start_dim=1, end_dim=-1))\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76980495",
   "metadata": {},
   "source": [
    "### Compile using the Torch JIT Compiler\n",
    "This leverages the [Torch-TensorRT inference compiler](https://pytorch.org/TensorRT/) for accelerated inference on GPUs using the `torch.compile` JIT interface under the hood. The compiler stack returns a [boxed-function](http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/) that triggers compilation on the first call.  \n",
    "\n",
    "Modules compiled in this fashion are [not serializable with pickle](https://github.com/pytorch/pytorch/issues/101107#issuecomment-1542688089), so we cannot send the compiled model directly to Spark. Instead, we will recompile and cache the model on the executor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bc856",
   "metadata": {},
   "source": [
    "(You may see a warning about modelopt quantization. This is safe to ignore, as [implicit quantization](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#intro-quantization) is deprecated in the latest TensorRT. See [this link](https://pytorch.org/TensorRT/tutorials/_rendered_examples/dynamo/vgg16_fp8_ptq.html) for a guide to explicit quantization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3e3bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "import torch_tensorrt as trt\n",
    "\n",
    "inputs_bs1 = torch.randn((1, 784), dtype=torch.float).to(\"cuda\")\n",
    "# This indicates dimension 0 of inputs_bs1 is dynamic whose range of values is [1, 50]. No recompilation will happen when the batch size changes.\n",
    "torch._dynamo.mark_dynamic(inputs_bs1, 0, min=1, max=64)\n",
    "trt_model = trt.compile(\n",
    "    model,\n",
    "    ir=\"torch_compile\",\n",
    "    inputs=inputs_bs1,\n",
    "    enabled_precisions={torch.float},\n",
    ")\n",
    "\n",
    "stream = torch.cuda.Stream()\n",
    "with torch.no_grad(), torch.cuda.stream(stream):\n",
    "    pred = trt_model(torch.flatten(x.to(device), start_dim=1, end_dim=-1))\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec04be8",
   "metadata": {},
   "source": [
    "### Compile using the Torch-TensorRT AOT Compiler\n",
    "Alternatively, use the Torch-TensorRT Dynamo backend for Ahead-of-Time (AOT) compilation to eagerly optimize the model in an explicit compilation phase. We first export the model to produce a traced graph representing the Tensor computation in an AOT fashion, which produces a `ExportedProgram` object which can be [serialized and reloaded](https://pytorch.org/TensorRT/user_guide/saving_models.html). We can then compile this IR using the Torch-TensorRT AOT compiler for inference.   \n",
    "\n",
    "[Read the docs](https://pytorch.org/TensorRT/user_guide/torch_tensorrt_explained.html) for more information on JIT vs AOT compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b8f1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch_tensorrt.dynamo._compiler:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=False, workspace_size=0, min_block_size=5, torch_executed_ops=set(), pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=True, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False, timing_cache_path='/tmp/timing_cache.bin')\n",
      "\n",
      "INFO:torch_tensorrt.dynamo._compiler:Partitioning the graph via the fast partitioner\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 770, GPU 761 (MiB)\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageChange] Init builder kernel library: CPU +1632, GPU +286, now: CPU 2402, GPU 1047 (MiB)\n",
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/torch_tensorrt/dynamo/conversion/impl/activation/base.py:40: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
      "  if input_val.dynamic_range is not None and dyn_range_fn is not None:\n",
      "\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.005393\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Global timing cache in use. Profiling results in this builder pass will be stored.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Detected 1 inputs and 1 output network tensors.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Host Persistent Memory: 21984\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Device Persistent Memory: 0\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Scratch Memory: 0\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[BlockAssignment] Started assigning block shifts. This will take 4 steps to complete.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[BlockAssignment] Algorithm ShiftNTopDown took 0.130137ms to assign 2 blocks to 4 nodes requiring 4096 bytes.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Activation Memory: 4096\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Weights Memory: 2678824\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Engine generation completed in 0.0193205 seconds.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 15 MiB\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3993 MiB\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:00.021830\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 2833124 bytes of Memory\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 26 bytes of code generator cache.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 408 timing cache entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# Preparing the inputs for batch_size = 1. \n",
    "inputs = (torch.randn((1, 784), dtype=torch.float).cuda(),)\n",
    "\n",
    "# Produce traced graph in the ExportedProgram format\n",
    "exp_program = trt.dynamo.trace(model_from_state, inputs)\n",
    "# Compile the traced graph to produce an optimized module\n",
    "trt_gm = trt.dynamo.compile(exp_program, inputs=inputs, require_full_compilation=True)\n",
    "\n",
    "stream = torch.cuda.Stream()\n",
    "with torch.no_grad(), torch.cuda.stream(stream):\n",
    "    trt_gm(torch.flatten(x.to(device), start_dim=1, end_dim=-1))\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2bbfe1",
   "metadata": {},
   "source": [
    "We can save the compiled model using `torch_tensorrt.save`. Unfortunately, serializing the model to be reloaded at a later date currently only supports *static inputs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d87e4b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/torch_tensorrt/dynamo/_exporter.py:364: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer\n",
      "  engine_node = gm.graph.get_attr(engine_name)\n",
      "\n",
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/torch/fx/graph.py:1545: UserWarning: Node _run_on_acc_0_engine target _run_on_acc_0_engine _run_on_acc_0_engine of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved AOT compiled TensorRT model to trt_model_aot.ep\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.stream(stream):\n",
    "    trt.save(trt_gm, \"trt_model_aot.ep\", inputs=[torch.randn((1, 784), dtype=torch.float).to(\"cuda\")])\n",
    "    print(\"Saved AOT compiled TensorRT model to trt_model_aot.ep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad918393",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1daec3",
   "metadata": {},
   "source": [
    "### Convert numpy dataset to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c5feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f063cbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_data.data.numpy()\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c828393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), dtype('float64'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(10000, 784) / 255.0\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7760bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2         3    4         5         6    7         8    \\\n",
       "0     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "2     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.003922   \n",
       "3     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "4     0.0  0.0  0.0  0.007843  0.0  0.003922  0.003922  0.0  0.000000   \n",
       "...   ...  ...  ...       ...  ...       ...       ...  ...       ...   \n",
       "9995  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9996  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9997  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9998  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9999  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "           9    ...       774       775  776       777       778       779  \\\n",
       "0     0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "1     0.000000  ...  0.007843  0.011765  0.0  0.011765  0.682353  0.741176   \n",
       "2     0.000000  ...  0.643137  0.227451  0.0  0.000000  0.000000  0.000000   \n",
       "3     0.082353  ...  0.003922  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "4     0.000000  ...  0.278431  0.047059  0.0  0.000000  0.000000  0.000000   \n",
       "...        ...  ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9996  0.121569  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9997  0.000000  ...  0.105882  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9998  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9999  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "           780  781  782  783  \n",
       "0     0.000000  0.0  0.0  0.0  \n",
       "1     0.262745  0.0  0.0  0.0  \n",
       "2     0.000000  0.0  0.0  0.0  \n",
       "3     0.000000  0.0  0.0  0.0  \n",
       "4     0.000000  0.0  0.0  0.0  \n",
       "...        ...  ...  ...  ...  \n",
       "9995  0.000000  0.0  0.0  0.0  \n",
       "9996  0.000000  0.0  0.0  0.0  \n",
       "9997  0.000000  0.0  0.0  0.0  \n",
       "9998  0.000000  0.0  0.0  0.0  \n",
       "9999  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf784 = pd.DataFrame(data)\n",
    "pdf784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7d2bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72.2 ms, sys: 50.1 ms, total: 122 ms\n",
      "Wall time: 122 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00784313725490196, 0.0, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   data\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...\n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4     [0.0, 0.0, 0.0, 0.00784313725490196, 0.0, 0.00...\n",
       "...                                                 ...\n",
       "9995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "pdf1 = pd.DataFrame()\n",
    "pdf1['data'] = pdf784.values.tolist()\n",
    "pdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "conda_env = os.environ.get(\"CONDA_PREFIX\")\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.task.maxFailures\", \"1\")\n",
    "conf.set(\"spark.driver.memory\", \"8g\")\n",
    "conf.set(\"spark.executor.memory\", \"8g\")\n",
    "conf.set(\"spark.pyspark.python\", f\"{conda_env}/bin/python\")\n",
    "conf.set(\"spark.pyspark.driver.python\", f\"{conda_env}/bin/python\")\n",
    "conf.set(\"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\", \"false\")\n",
    "conf.set(\"spark.sql.pyspark.jvmStacktrace.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "conf.set(\"spark.python.worker.reuse\", \"true\")\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"spark-dl-examples\").config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320760db",
   "metadata": {},
   "source": [
    "#### Create Spark DataFrame from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4863d5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 386 ms, sys: 44.6 ms, total: 431 ms\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(\"data\",ArrayType(FloatType()), True)])\n",
    "df = spark.createDataFrame(pdf1, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "406edba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "831f4a01-3a49-4114-b9a0-2ae54526d72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.2 ms, sys: 18.7 ms, total: 79.8 ms\n",
      "Wall time: 818 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(str(x), FloatType(), True) for x in range(784)])\n",
    "df784 = spark.createDataFrame(pdf784, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7448",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8ebae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/03 00:05:14 WARN TaskSetManager: Stage 0 contains a task of very large size (4032 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 ms, sys: 2.26 ms, total: 4.57 ms\n",
      "Wall time: 1.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.write.mode(\"overwrite\").parquet(\"fashion_mnist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "922314ce-2996-4666-9fc9-bcd98d16bb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/03 00:05:15 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/10/03 00:05:15 WARN TaskSetManager: Stage 1 contains a task of very large size (7849 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.82 ms, sys: 352 μs, total: 3.17 ms\n",
      "Wall time: 653 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df784.write.mode(\"overwrite\").parquet(\"fashion_mnist_784\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688429e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "088cb37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=118, family=2, type=1, proto=6, laddr=('127.0.0.1', 47988), raddr=('127.0.0.1', 39729)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c77eb4-7bd6-40c7-9a35-ee899a66ece3",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59395856-a588-43c6-93c8-c83100716ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1 columns of 784 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "133cc9a5-64c6-4820-807e-b87cf7e0b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79b151d9-d112-43b6-a479-887e2fd0e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cabcd546-2e8e-40d0-8b79-7598a7a83aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "823c3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute path to model\n",
    "model_path = \"{}/model.pt\".format(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inference on Spark, we'll compile the model with the Torch-TensorRT AOT compiler and cache on the executor. We can specify dynamic batch sizes before compilation to [optimize across multiple input shapes](https://pytorch.org/TensorRT/user_guide/dynamic_shapes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73dc73cb-25e3-4798-a019-e1abd684eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import torch\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        raise ValueError(\"This function uses the TensorRT model which requires a GPU device\")\n",
    "\n",
    "    import torch_tensorrt as trt\n",
    "\n",
    "    # Define model\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28*28, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 10)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits\n",
    "\n",
    "    model = NeuralNetwork().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "\n",
    "    # Preparing the inputs for dynamic batch sizing.\n",
    "    inputs = [trt.Input(min_shape=(1, 784), \n",
    "                   opt_shape=(50, 784), \n",
    "                   max_shape=(64, 784), \n",
    "                   dtype=torch.float32)]\n",
    "\n",
    "    # Trace the computation graph and compile to produce an optimized module\n",
    "    trt_gm = trt.compile(model, ir=\"dynamo\", inputs=inputs, require_full_compilation=True)\n",
    "\n",
    "    def predict(inputs: np.ndarray):\n",
    "        stream = torch.cuda.Stream()\n",
    "        with torch.no_grad(), torch.cuda.stream(stream):\n",
    "            # use array to combine columns into tensors\n",
    "            torch_inputs = torch.from_numpy(inputs).to(device)\n",
    "            outputs = trt_gm(torch_inputs)\n",
    "            return outputs.detach().cpu().numpy()\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df68cca1-2d47-4e88-8aad-9899402aee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(predict_batch_fn,\n",
    "                          input_tensor_shapes=[[784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63555b3b-3673-4712-97aa-fd728c6c4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=119, family=2, type=1, proto=6, laddr=('127.0.0.1', 55648), raddr=('127.0.0.1', 45167)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 186 ms, sys: 60.8 ms, total: 247 ms\n",
      "Wall time: 8.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dbf058a-70d6-4199-af9d-13843d078950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=119, family=2, type=1, proto=6, laddr=('127.0.0.1', 46588), raddr=('127.0.0.1', 45069)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 257 ms, sys: 64.4 ms, total: 321 ms\n",
      "Wall time: 646 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f5ed801-6ca5-43a0-bf9c-2535a0dfe2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=119, family=2, type=1, proto=6, laddr=('127.0.0.1', 60232), raddr=('127.0.0.1', 41967)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 55.1 ms, total: 263 ms\n",
      "Wall time: 651 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbec03-9b64-46c4-a748-f889be571384",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1f1e5fd-5866-4b78-b9d3-709e6b383a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds[0].preds\n",
    "img = preds[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76b76502-adb7-45ec-a365-2e61cdd576fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c163953a-1504-444f-b39f-86b61d34e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc0fad05-50ab-4ae5-b9fd-e50133c4c92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56f36efb-e3a2-49f9-b9fb-1657bc25e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2660890817642212, -3.161794900894165, 2.806877851486206, -0.6098713874816895, 2.6638317108154297, -1.4545137882232666, 2.6738216876983643, -3.9595861434936523, 2.0358901023864746, -1.9140053987503052]\n",
      "predicted label: Pullover\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(\"predicted label:\", classes[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca1195-ea0f-405f-87fe-857e5c0c76a5",
   "metadata": {},
   "source": [
    "### 784 columns of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0ab0af6-b5c9-4b74-9dd6-baa7737cc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_784\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13ae45dc-85a0-4864-8a58-9dc29ae4efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=120, family=2, type=1, proto=6, laddr=('127.0.0.1', 36068), raddr=('127.0.0.1', 38353)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 254 ms, sys: 72.7 ms, total: 327 ms\n",
      "Wall time: 3.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b3fb48b-f871-41f2-ac57-346899a6fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=120, family=2, type=1, proto=6, laddr=('127.0.0.1', 45966), raddr=('127.0.0.1', 44779)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 271 ms, sys: 65.4 ms, total: 337 ms\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc48ec42-0df6-4e6a-b019-1270ab71d2cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d815c701-9f5b-422c-b3f9-fbc30456953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=120, family=2, type=1, proto=6, laddr=('127.0.0.1', 60714), raddr=('127.0.0.1', 44361)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b571b742-5079-42b2-8524-9181a0dec2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = preds.iloc[0]\n",
    "predictions = sample.preds\n",
    "img = sample.drop('preds').to_numpy(dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d33d6a4e-e6b9-489d-ac21-c4eddc801784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d10061e-aca6-4f81-bdfe-72e327ed7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01f70e08-2c1d-419f-8676-3f6f4aba760f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e1c07cc-b2bc-4902-a9a6-4ac7f02c5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2660891 -3.161795   2.8068779 -0.6098714  2.6638317 -1.4545138\n",
      "  2.6738217 -3.9595861  2.03589   -1.9140054]\n",
      "predicted label: Pullover\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(\"predicted label:\", classes[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937adc9-508d-4ccd-b92d-8ecaa27ee4e4",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53ca290a-ccc3-4923-a292-944921bab36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8fa92fe4-2e04-4d82-a357-bfdfca38bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models/fashion_mnist/1\n",
    "cp ts_model.pt models/fashion_mnist/1/model.pt\n",
    "\n",
    "# add config.pbtxt\n",
    "cp models_config/fashion_mnist/config.pbtxt models/fashion_mnist/config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b329c-5921-436f-bfca-a382a6762da4",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e869730-3597-4074-bab0-f87768f8996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=123, family=2, type=1, proto=6, laddr=('127.0.0.1', 40988), raddr=('127.0.0.1', 38021)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"64M\",\n",
    "            volumes={triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "            \n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4362d-7514-4b84-b238-f704a97e1e72",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab94d4d1-dac6-4474-9eb0-59478aa98f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12b5f2fc-52e9-428a-b683-6ab1b639aa24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "960657d0-31c9-4df6-8eb8-ac3d23137f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool_),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0262fd4a-9845-44b9-8c75-1c105e7deeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"fashion_mnist\"),\n",
    "                          input_tensor_shapes=[[784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc5f6baa-052e-4b89-94b6-4821cf01952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=123, family=2, type=1, proto=6, laddr=('127.0.0.1', 45762), raddr=('127.0.0.1', 33677)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 157 ms, sys: 42 ms, total: 199 ms\n",
      "Wall time: 958 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a85dea35-e41d-482d-8a8f-52d3c108f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=123, family=2, type=1, proto=6, laddr=('127.0.0.1', 41512), raddr=('127.0.0.1', 34837)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 385 ms, sys: 60.8 ms, total: 446 ms\n",
      "Wall time: 730 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc3f0dbe-c52b-41d6-8097-8cebaa5ee5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=123, family=2, type=1, proto=6, laddr=('127.0.0.1', 46536), raddr=('127.0.0.1', 34003)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 188 ms, sys: 41.9 ms, total: 230 ms\n",
      "Wall time: 566 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99fb5e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample prediction\n",
    "sample = preds[0]\n",
    "predictions = sample.preds\n",
    "img = sample.data\n",
    "\n",
    "img = np.array(img).reshape(28,28)\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "\n",
    "print(\"Predicted label:\", classes[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26690a-9dc4-4c36-9904-568d73e2be3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab2fe42f-a072-4370-bac2-52fd95363530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/socket.py:777: ResourceWarning: unclosed <socket.socket fd=123, family=2, type=1, proto=6, laddr=('127.0.0.1', 43680), raddr=('127.0.0.1', 41097)>\n",
      "  self._sock = None\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0608fff-7cfb-489e-96c9-8e1d92e57562",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de2664-3d60-487b-90da-6d0f3b8b9203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-dl-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
