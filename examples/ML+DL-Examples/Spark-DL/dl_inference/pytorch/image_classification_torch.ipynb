{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e87c927",
   "metadata": {},
   "source": [
    "# PySpark PyTorch Inference\n",
    "\n",
    "### Image Classification\n",
    "Based on: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html  \n",
    "\n",
    "Also demonstrates accelerated inference on GPU with Torch-TensorRT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d714f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c942a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a89aa8e-ef62-4aac-8260-4b004f2c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a97111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) torch.float32\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af350",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512d0bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c1b7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d9076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = torch.flatten(X, start_dim=1, end_dim=-1)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c5650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            X = torch.flatten(X, start_dim=1, end_dim=-1)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "854608e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301038  [   64/60000]\n",
      "loss: 2.289769  [ 6464/60000]\n",
      "loss: 2.268618  [12864/60000]\n",
      "loss: 2.264085  [19264/60000]\n",
      "loss: 2.244277  [25664/60000]\n",
      "loss: 2.209504  [32064/60000]\n",
      "loss: 2.220515  [38464/60000]\n",
      "loss: 2.185288  [44864/60000]\n",
      "loss: 2.186121  [51264/60000]\n",
      "loss: 2.149065  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 37.8%, Avg loss: 2.151644 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.164946  [   64/60000]\n",
      "loss: 2.157853  [ 6464/60000]\n",
      "loss: 2.100765  [12864/60000]\n",
      "loss: 2.117897  [19264/60000]\n",
      "loss: 2.058581  [25664/60000]\n",
      "loss: 1.995217  [32064/60000]\n",
      "loss: 2.026708  [38464/60000]\n",
      "loss: 1.948186  [44864/60000]\n",
      "loss: 1.959582  [51264/60000]\n",
      "loss: 1.881658  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.886264 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.922469  [   64/60000]\n",
      "loss: 1.893279  [ 6464/60000]\n",
      "loss: 1.780482  [12864/60000]\n",
      "loss: 1.822908  [19264/60000]\n",
      "loss: 1.696129  [25664/60000]\n",
      "loss: 1.653140  [32064/60000]\n",
      "loss: 1.675662  [38464/60000]\n",
      "loss: 1.584822  [44864/60000]\n",
      "loss: 1.609127  [51264/60000]\n",
      "loss: 1.500899  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 1.521902 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.593910  [   64/60000]\n",
      "loss: 1.555975  [ 6464/60000]\n",
      "loss: 1.412051  [12864/60000]\n",
      "loss: 1.480928  [19264/60000]\n",
      "loss: 1.348195  [25664/60000]\n",
      "loss: 1.352939  [32064/60000]\n",
      "loss: 1.361179  [38464/60000]\n",
      "loss: 1.298819  [44864/60000]\n",
      "loss: 1.325064  [51264/60000]\n",
      "loss: 1.226879  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.254962 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.337471  [   64/60000]\n",
      "loss: 1.314826  [ 6464/60000]\n",
      "loss: 1.155245  [12864/60000]\n",
      "loss: 1.257553  [19264/60000]\n",
      "loss: 1.123370  [25664/60000]\n",
      "loss: 1.155071  [32064/60000]\n",
      "loss: 1.168100  [38464/60000]\n",
      "loss: 1.119365  [44864/60000]\n",
      "loss: 1.149572  [51264/60000]\n",
      "loss: 1.067573  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.090368 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97839",
   "metadata": {},
   "source": [
    "### Save Model State Dict\n",
    "This saves the serialized object to disk using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5d24de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "print(\"Saved PyTorch Model State to model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac221ca7-e227-4c8c-8577-1eeda4a61fc7",
   "metadata": {},
   "source": [
    "### Save Model as TorchScript\n",
    "This saves an [intermediate representation of the compute graph](https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format), which does not require pickle (or even python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d9b3a45-7618-43e4-8bd3-8bb317a484d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TorchScript Model to ts_model.pt\n"
     ]
    }
   ],
   "source": [
    "scripted = torch.jit.script(model)\n",
    "scripted.save(\"ts_model.pt\")\n",
    "print(\"Saved TorchScript Model to ts_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee8916-f437-4a2a-9bf4-14ff5376d305",
   "metadata": {},
   "source": [
    "### Load Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe3b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_state = NeuralNetwork().to(device)\n",
    "model_from_state.load_state_dict(torch.load(\"model.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c405bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "model_from_state.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = torch.flatten(x.to(device), start_dim=1, end_dim=-1)\n",
    "    pred = model_from_state(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c482a-1c5d-4bf2-bc3f-8a4e53d442b5",
   "metadata": {},
   "source": [
    "### Load Torchscript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3c419e-d384-446c-b07b-1af93e07d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to original device (GPU) and move to CPU. \n",
    "ts_model = torch.jit.load(\"ts_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92d6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "038af830-a360-45eb-ab4e-b1adab0af164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = ts_model(torch.flatten(x.to(device), start_dim=1, end_dim=-1))\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76980495",
   "metadata": {},
   "source": [
    "### Compile using the Torch JIT Compiler\n",
    "This leverages the [Torch-TensorRT inference compiler](https://pytorch.org/TensorRT/) for accelerated inference on GPUs using the `torch.compile` JIT interface under the hood. The compiler stack returns a [boxed-function](http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/) that triggers compilation on the first call.  \n",
    "\n",
    "Modules compiled in this fashion are [not serializable with pickle](https://github.com/pytorch/pytorch/issues/101107#issuecomment-1542688089), so we cannot send the compiled model directly to Spark. Instead, we will recompile and cache the model on the executor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bc856",
   "metadata": {},
   "source": [
    "(You may see a warning about modelopt quantization. This is safe to ignore, as [implicit quantization](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#intro-quantization) is deprecated in the latest TensorRT. See [this link](https://pytorch.org/TensorRT/tutorials/_rendered_examples/dynamo/vgg16_fp8_ptq.html) for a guide to explicit quantization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "362b266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_tensorrt as trt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0ac1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: set the filename for the TensorRT timing cache\n",
    "timestamp = time.time()\n",
    "timing_cache = f\"/tmp/timing_cache-{timestamp}.bin\"\n",
    "with open(timing_cache, \"wb\") as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3e3bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch_tensorrt.dynamo.utils:Using Default Torch-TRT Runtime (as requested by user)\n",
      "INFO:torch_tensorrt.dynamo.utils:Device not specified, using Torch default current device - cuda:0. If this is incorrect, please specify an input device, via the device keyword.\n",
      "INFO:torch_tensorrt.dynamo.utils:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=False, workspace_size=0, min_block_size=5, torch_executed_ops=set(), pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False, timing_cache_path='/tmp/timing_cache-1729187850.4862776.bin')\n",
      "\n",
      "WARNING:torch_tensorrt.dynamo._compiler:Node _param_constant1 of op type get_attr does not have metadata. This could sometimes lead to undefined behavior.\n",
      "WARNING:torch_tensorrt.dynamo._compiler:Some nodes do not have metadata (shape and dtype information). This could lead to problems sometimes if the graph has PyTorch and TensorRT segments.\n",
      "INFO:torch_tensorrt.dynamo._compiler:Partitioning the graph via the fast partitioner\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 457, GPU 713 (MiB)\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageChange] Init builder kernel library: CPU +1634, GPU +288, now: CPU 2238, GPU 1001 (MiB)\n",
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/torch_tensorrt/dynamo/conversion/impl/activation/base.py:40: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
      "  if input_val.dynamic_range is not None and dyn_range_fn is not None:\n",
      "\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.005662\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Global timing cache in use. Profiling results in this builder pass will be stored.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Detected 1 inputs and 1 output network tensors.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Host Persistent Memory: 21984\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Device Persistent Memory: 0\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Scratch Memory: 0\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[BlockAssignment] Started assigning block shifts. This will take 4 steps to complete.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[BlockAssignment] Algorithm ShiftNTopDown took 0.115746ms to assign 2 blocks to 4 nodes requiring 4096 bytes.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Activation Memory: 4096\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Weights Memory: 2678824\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Engine generation completed in 1.58824 seconds.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 5 MiB\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3950 MiB\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:01.591865\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 2832188 bytes of Memory\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 26 bytes of code generator cache.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 43 timing cache entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "inputs_bs1 = torch.randn((1, 784), dtype=torch.float).to(\"cuda\")\n",
    "# This indicates dimension 0 of inputs_bs1 is dynamic whose range of values is [1, 50]. No recompilation will happen when the batch size changes.\n",
    "torch._dynamo.mark_dynamic(inputs_bs1, 0, min=1, max=64)\n",
    "trt_model = trt.compile(\n",
    "    model,\n",
    "    ir=\"torch_compile\",\n",
    "    inputs=inputs_bs1,\n",
    "    enabled_precisions={torch.float},\n",
    "    timing_cache_path=timing_cache,\n",
    ")\n",
    "\n",
    "stream = torch.cuda.Stream()\n",
    "with torch.no_grad(), torch.cuda.stream(stream):\n",
    "    pred = trt_model(torch.flatten(x.to(device), start_dim=1, end_dim=-1))\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec04be8",
   "metadata": {},
   "source": [
    "### Compile using the Torch-TensorRT AOT Compiler\n",
    "Alternatively, use the Torch-TensorRT Dynamo backend for Ahead-of-Time (AOT) compilation to eagerly optimize the model in an explicit compilation phase. We first export the model to produce a traced graph representing the Tensor computation in an AOT fashion, which produces a `ExportedProgram` object which can be [serialized and reloaded](https://pytorch.org/TensorRT/user_guide/saving_models.html). We can then compile this IR using the Torch-TensorRT AOT compiler for inference.   \n",
    "\n",
    "[Read the docs](https://pytorch.org/TensorRT/user_guide/torch_tensorrt_explained.html) for more information on JIT vs AOT compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b8f1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch_tensorrt.dynamo._compiler:Compilation Settings: CompilationSettings(enabled_precisions={<dtype.f32: 7>}, debug=False, workspace_size=0, min_block_size=5, torch_executed_ops=set(), pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=True, disable_tf32=False, assume_dynamic_shape_support=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.STANDARD: 1>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, dryrun=False, hardware_compatible=False, timing_cache_path='/tmp/timing_cache-1729187850.4862776.bin')\n",
      "\n",
      "INFO:torch_tensorrt.dynamo._compiler:Partitioning the graph via the fast partitioner\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 758, GPU 715 (MiB)\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageChange] Init builder kernel library: CPU +1633, GPU +286, now: CPU 2391, GPU 1001 (MiB)\n",
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/torch_tensorrt/dynamo/conversion/impl/activation/base.py:40: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
      "  if input_val.dynamic_range is not None and dyn_range_fn is not None:\n",
      "\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.004664\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Global timing cache in use. Profiling results in this builder pass will be stored.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Detected 1 inputs and 1 output network tensors.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Host Persistent Memory: 21984\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Device Persistent Memory: 0\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Scratch Memory: 0\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[BlockAssignment] Started assigning block shifts. This will take 4 steps to complete.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[BlockAssignment] Algorithm ShiftNTopDown took 0.113766ms to assign 2 blocks to 4 nodes requiring 4096 bytes.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Activation Memory: 4096\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Total Weights Memory: 2678824\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Engine generation completed in 0.022595 seconds.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 5 MiB\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:[MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3968 MiB\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:00:00.025016\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 2833124 bytes of Memory\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 26 bytes of code generator cache.\n",
      "INFO:torch_tensorrt [TensorRT Conversion Context]:Serialized 43 timing cache entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# Preparing the inputs for batch_size = 1. \n",
    "inputs = (torch.randn((1, 784), dtype=torch.float).cuda(),)\n",
    "\n",
    "# Produce traced graph in the ExportedProgram format\n",
    "exp_program = trt.dynamo.trace(model_from_state, inputs)\n",
    "# Compile the traced graph to produce an optimized module\n",
    "trt_gm = trt.dynamo.compile(exp_program, \n",
    "                            inputs=inputs, \n",
    "                            timing_cache_path=timing_cache)\n",
    "\n",
    "stream = torch.cuda.Stream()\n",
    "with torch.no_grad(), torch.cuda.stream(stream):\n",
    "    trt_gm(torch.flatten(x.to(device), start_dim=1, end_dim=-1))\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2bbfe1",
   "metadata": {},
   "source": [
    "We can save the compiled model using `torch_tensorrt.save`. Unfortunately, serializing the model to be reloaded at a later date currently only supports *static inputs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d87e4b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved AOT compiled TensorRT model to trt_model_aot.ep\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.stream(stream):\n",
    "    trt.save(trt_gm, \"trt_model_aot.ep\", inputs=[torch.randn((1, 784), dtype=torch.float).to(\"cuda\")])\n",
    "    print(\"Saved AOT compiled TensorRT model to trt_model_aot.ep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad918393",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1daec3",
   "metadata": {},
   "source": [
    "### Convert numpy dataset to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c5feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f063cbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_data.data.numpy()\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c828393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), dtype('float64'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(10000, 784) / 255.0\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7760bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2         3    4         5         6    7         8    \\\n",
       "0     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "2     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.003922   \n",
       "3     0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "4     0.0  0.0  0.0  0.007843  0.0  0.003922  0.003922  0.0  0.000000   \n",
       "...   ...  ...  ...       ...  ...       ...       ...  ...       ...   \n",
       "9995  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9996  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9997  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9998  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "9999  0.0  0.0  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "           9    ...       774       775  776       777       778       779  \\\n",
       "0     0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "1     0.000000  ...  0.007843  0.011765  0.0  0.011765  0.682353  0.741176   \n",
       "2     0.000000  ...  0.643137  0.227451  0.0  0.000000  0.000000  0.000000   \n",
       "3     0.082353  ...  0.003922  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "4     0.000000  ...  0.278431  0.047059  0.0  0.000000  0.000000  0.000000   \n",
       "...        ...  ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9996  0.121569  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9997  0.000000  ...  0.105882  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9998  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "9999  0.000000  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "           780  781  782  783  \n",
       "0     0.000000  0.0  0.0  0.0  \n",
       "1     0.262745  0.0  0.0  0.0  \n",
       "2     0.000000  0.0  0.0  0.0  \n",
       "3     0.000000  0.0  0.0  0.0  \n",
       "4     0.000000  0.0  0.0  0.0  \n",
       "...        ...  ...  ...  ...  \n",
       "9995  0.000000  0.0  0.0  0.0  \n",
       "9996  0.000000  0.0  0.0  0.0  \n",
       "9997  0.000000  0.0  0.0  0.0  \n",
       "9998  0.000000  0.0  0.0  0.0  \n",
       "9999  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf784 = pd.DataFrame(data)\n",
    "pdf784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7d2bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.6 ms, sys: 56.2 ms, total: 144 ms\n",
      "Wall time: 143 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00784313725490196, 0.0, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   data\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...\n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4     [0.0, 0.0, 0.0, 0.00784313725490196, 0.0, 0.00...\n",
       "...                                                 ...\n",
       "9995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 1 column of array<float>\n",
    "pdf1 = pd.DataFrame()\n",
    "pdf1['data'] = pdf784.values.tolist()\n",
    "pdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5d7ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 00:30:18 WARN Utils: Your hostname, cb4ae00-lcedt resolves to a loopback address: 127.0.1.1; using 10.110.47.100 instead (on interface eno1)\n",
      "24/10/08 00:30:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/08 00:30:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "conda_env = os.environ.get(\"CONDA_PREFIX\")\n",
    "\n",
    "conf = SparkConf()\n",
    "if 'spark' not in globals():\n",
    "    # If Spark is not already started with Jupyter, attach to Spark Standalone\n",
    "    import socket\n",
    "    hostname = socket.gethostname()\n",
    "    conf.setMaster(f\"spark://{hostname}:7077\") # assuming Master is on default port 7077\n",
    "conf.set(\"spark.task.maxFailures\", \"1\")\n",
    "conf.set(\"spark.driver.memory\", \"8g\")\n",
    "conf.set(\"spark.executor.memory\", \"8g\")\n",
    "conf.set(\"spark.pyspark.python\", f\"{conda_env}/bin/python\")\n",
    "conf.set(\"spark.pyspark.driver.python\", f\"{conda_env}/bin/python\")\n",
    "conf.set(\"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\", \"false\")\n",
    "conf.set(\"spark.sql.pyspark.jvmStacktrace.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "conf.set(\"spark.python.worker.reuse\", \"true\")\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"spark-dl-examples\").config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320760db",
   "metadata": {},
   "source": [
    "#### Create Spark DataFrame from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4863d5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 389 ms, sys: 63.2 ms, total: 452 ms\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(\"data\",ArrayType(FloatType()), True)])\n",
    "df = spark.createDataFrame(pdf1, schema).repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "406edba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "831f4a01-3a49-4114-b9a0-2ae54526d72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61 ms, sys: 21.6 ms, total: 82.6 ms\n",
      "Wall time: 854 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# force FloatType since Spark defaults to DoubleType\n",
    "schema = StructType([StructField(str(x), FloatType(), True) for x in range(784)])\n",
    "df784 = spark.createDataFrame(pdf784, schema).repartition(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7448",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8ebae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 00:30:21 WARN TaskSetManager: Stage 0 contains a task of very large size (4032 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.09 ms, sys: 2.57 ms, total: 4.66 ms\n",
      "Wall time: 1.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.write.mode(\"overwrite\").parquet(\"fashion_mnist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "922314ce-2996-4666-9fc9-bcd98d16bb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 00:30:23 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/10/08 00:30:23 WARN TaskSetManager: Stage 3 contains a task of very large size (7849 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 ms, sys: 22 μs, total: 3.03 ms\n",
      "Wall time: 734 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df784.write.mode(\"overwrite\").parquet(\"fashion_mnist_784\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688429e",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c77eb4-7bd6-40c7-9a35-ee899a66ece3",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59395856-a588-43c6-93c8-c83100716ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1 columns of 784 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "133cc9a5-64c6-4820-807e-b87cf7e0b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79b151d9-d112-43b6-a479-887e2fd0e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cabcd546-2e8e-40d0-8b79-7598a7a83aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "823c3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute path to model\n",
    "model_path = \"{}/model.pt\".format(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c2bac",
   "metadata": {},
   "source": [
    "For inference on Spark, we'll compile the model with the Torch-TensorRT AOT compiler and cache on the executor. We can specify dynamic batch sizes before compilation to [optimize across multiple input shapes](https://pytorch.org/TensorRT/user_guide/dynamic_shapes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73dc73cb-25e3-4798-a019-e1abd684eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import torch\n",
    "    import torch_tensorrt as trt\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        raise ValueError(\"This function uses the TensorRT model which requires a GPU device\")\n",
    "\n",
    "    # Define model\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28*28, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 10)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits\n",
    "\n",
    "    model = NeuralNetwork().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "\n",
    "    # Preparing the inputs for dynamic batch sizing.\n",
    "    inputs = [trt.Input(min_shape=(1, 784), \n",
    "                   opt_shape=(50, 784), \n",
    "                   max_shape=(64, 784), \n",
    "                   dtype=torch.float32)]\n",
    "\n",
    "    # Trace the computation graph and compile to produce an optimized module\n",
    "    trt_gm = trt.compile(model, ir=\"dynamo\", inputs=inputs, require_full_compilation=True)\n",
    "\n",
    "    def predict(inputs: np.ndarray):\n",
    "        print(\"Predicting on process PID: {}\".format(os.getpid()))\n",
    "        stream = torch.cuda.Stream()\n",
    "        with torch.no_grad(), torch.cuda.stream(stream):\n",
    "            # use array to combine columns into tensors\n",
    "            torch_inputs = torch.from_numpy(inputs).to(device)\n",
    "            outputs = trt_gm(torch_inputs)\n",
    "            return outputs.detach().cpu().numpy()\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df68cca1-2d47-4e88-8aad-9899402aee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(predict_batch_fn,\n",
    "                          input_tensor_shapes=[[784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63555b3b-3673-4712-97aa-fd728c6c4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 189 ms, sys: 53.6 ms, total: 242 ms\n",
      "Wall time: 9.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dbf058a-70d6-4199-af9d-13843d078950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 195 ms, sys: 75 ms, total: 270 ms\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f5ed801-6ca5-43a0-bf9c-2535a0dfe2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 199 ms, sys: 54.9 ms, total: 254 ms\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbec03-9b64-46c4-a748-f889be571384",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1f1e5fd-5866-4b78-b9d3-709e6b383a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = preds[0].preds\n",
    "img = preds[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76b76502-adb7-45ec-a365-2e61cdd576fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c163953a-1504-444f-b39f-86b61d34e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc0fad05-50ab-4ae5-b9fd-e50133c4c92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56f36efb-e3a2-49f9-b9fb-1657bc25e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.309907078742981, -3.8460376262664795, 0.845407247543335, -2.5534284114837646, 0.7116107940673828, 0.9341840147972107, 0.4921048879623413, 0.22850888967514038, 2.951157331466675, 1.0042279958724976]\n",
      "predicted label: Bag\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(\"predicted label:\", classes[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca1195-ea0f-405f-87fe-857e5c0c76a5",
   "metadata": {},
   "source": [
    "### 784 columns of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0ab0af6-b5c9-4b74-9dd6-baa7737cc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_784\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13ae45dc-85a0-4864-8a58-9dc29ae4efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 266 ms, sys: 69.9 ms, total: 336 ms\n",
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b3fb48b-f871-41f2-ac57-346899a6fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 271 ms, sys: 66.2 ms, total: 337 ms\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc48ec42-0df6-4e6a-b019-1270ab71d2cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d815c701-9f5b-422c-b3f9-fbc30456953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df.withColumn(\"preds\", mnist(array(*df.columns))).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b571b742-5079-42b2-8524-9181a0dec2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = preds.iloc[0]\n",
    "predictions = sample.preds\n",
    "img = sample.drop('preds').to_numpy(dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d33d6a4e-e6b9-489d-ac21-c4eddc801784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d10061e-aca6-4f81-bdfe-72e327ed7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01f70e08-2c1d-419f-8676-3f6f4aba760f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e1c07cc-b2bc-4902-a9a6-4ac7f02c5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.5953586   3.9101725   0.65233815  3.2538052   1.270339   -3.0440047\n",
      "  1.1500907  -3.7935097  -1.8807431  -3.321768  ]\n",
      "predicted label: Trouser\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(\"predicted label:\", classes[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937adc9-508d-4ccd-b92d-8ecaa27ee4e4",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53ca290a-ccc3-4923-a292-944921bab36d",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, Union, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8fa92fe4-2e04-4d82-a357-bfdfca38bd8c",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models/fashion_mnist/1\n",
    "cp ts_model.pt models/fashion_mnist/1/model.pt\n",
    "\n",
    "# add config.pbtxt\n",
    "cp models_config/fashion_mnist/config.pbtxt models/fashion_mnist/config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b329c-5921-436f-bfca-a382a6762da4",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e869730-3597-4074-bab0-f87768f8996a",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"64M\",\n",
    "            volumes={triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "            \n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4362d-7514-4b84-b238-f704a97e1e72",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab94d4d1-dac6-4474-9eb0-59478aa98f7d",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet(\"fashion_mnist_1\")\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12b5f2fc-52e9-428a-b683-6ab1b639aa24",
   "metadata": {
    "scrolled": true,
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('data', ArrayType(FloatType(), True), True)])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "960657d0-31c9-4df6-8eb8-ac3d23137f7a",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool_),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0262fd4a-9845-44b9-8c75-1c105e7deeca",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "mnist = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"fashion_mnist\"),\n",
    "                          input_tensor_shapes=[[784]],\n",
    "                          return_type=ArrayType(FloatType()),\n",
    "                          batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc5f6baa-052e-4b89-94b6-4821cf01952a",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 326 ms, sys: 39.6 ms, total: 365 ms\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(struct(df.columns))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a85dea35-e41d-482d-8a8f-52d3c108f038",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 199 ms, sys: 63.2 ms, total: 262 ms\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*df.columns)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc3f0dbe-c52b-41d6-8097-8cebaa5ee5a8",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 195 ms, sys: 25.4 ms, total: 220 ms\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df.withColumn(\"preds\", mnist(*[col(c) for c in df.columns])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99fb5e8d",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample prediction\n",
    "sample = preds[0]\n",
    "predictions = sample.preds\n",
    "img = sample.data\n",
    "\n",
    "img = np.array(img).reshape(28,28)\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "\n",
    "print(\"Predicted label:\", classes[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26690a-9dc4-4c36-9904-568d73e2be3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fe42f-a072-4370-bac2-52fd95363530",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0608fff-7cfb-489e-96c9-8e1d92e57562",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de2664-3d60-487b-90da-6d0f3b8b9203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-dl-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
