{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "## Sentence Transformers with PyTorch\n",
    "\n",
    "From: https://huggingface.co/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731faab7-a700-46f8-bba5-1c8764e5eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "#Sentences we want to encode. Example:\n",
    "sentence = ['This framework generates embeddings for each input sentence']\n",
    "\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embedding = model.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96eea5ca-3cf7-46e3-b40c-598538112d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.76214486e-01,  1.20601125e-01, -2.93624103e-01,\n",
       "        -2.29858145e-01, -8.22926834e-02,  2.37709388e-01,\n",
       "         3.39985073e-01, -7.80964196e-01,  1.18127652e-01,\n",
       "         1.63373873e-01, -1.37715250e-01,  2.40282789e-01,\n",
       "         4.25125629e-01,  1.72417969e-01,  1.05279535e-01,\n",
       "         5.18164277e-01,  6.22218847e-02,  3.99285913e-01,\n",
       "        -1.81652412e-01, -5.85578680e-01,  4.49718609e-02,\n",
       "        -1.72750548e-01, -2.68443346e-01, -1.47386059e-01,\n",
       "        -1.89217880e-01,  1.92150414e-01, -3.83842528e-01,\n",
       "        -3.96007061e-01,  4.30648923e-01, -3.15319657e-01,\n",
       "         3.65950078e-01,  6.05156757e-02,  3.57325763e-01,\n",
       "         1.59736335e-01, -3.00983846e-01,  2.63250172e-01,\n",
       "        -3.94311100e-01,  1.84855402e-01, -3.99549127e-01,\n",
       "        -2.67889708e-01, -5.45117438e-01, -3.13405506e-02,\n",
       "        -4.30644155e-01,  1.33278280e-01, -1.74793780e-01,\n",
       "        -4.35465664e-01, -4.77378994e-01,  7.12554976e-02,\n",
       "        -7.37000555e-02,  5.69137216e-01, -2.82579571e-01,\n",
       "         5.24972752e-02, -8.20007920e-01,  1.98296949e-01,\n",
       "         1.69511899e-01,  2.71779835e-01,  2.64610946e-01,\n",
       "        -2.55740788e-02, -1.74096361e-01,  1.63314417e-01,\n",
       "        -3.95260990e-01, -3.17558348e-02, -2.62556106e-01,\n",
       "         3.52754414e-01,  3.01434726e-01, -1.47197217e-01,\n",
       "         2.10075825e-01, -1.84010521e-01, -4.12895858e-01,\n",
       "         4.14775848e-01, -1.89769641e-01, -1.35482341e-01,\n",
       "        -3.79272312e-01, -4.68024462e-02, -3.33602279e-02,\n",
       "         9.00392383e-02, -3.30132902e-01, -3.87313813e-02,\n",
       "         3.75082284e-01, -1.46996781e-01,  4.34959829e-01,\n",
       "         5.38325727e-01, -2.65445381e-01,  1.64445877e-01,\n",
       "         4.17078376e-01, -4.72505912e-02, -7.48733133e-02,\n",
       "        -4.26260769e-01, -1.96994558e-01,  6.10316731e-02,\n",
       "        -4.74262834e-01, -6.48334503e-01,  3.71462464e-01,\n",
       "         2.50956893e-01,  1.22529812e-01,  8.88766348e-02,\n",
       "        -1.06724337e-01,  5.33985645e-02,  9.74505991e-02,\n",
       "        -3.46655659e-02, -1.02882951e-01,  2.32288763e-01,\n",
       "        -2.53739774e-01, -5.13112128e-01,  1.85216263e-01,\n",
       "        -3.04357678e-01, -3.55209261e-02, -1.26975074e-01,\n",
       "        -7.71634579e-02, -5.15329897e-01, -2.28071898e-01,\n",
       "         2.03344952e-02,  7.38175958e-02, -1.52558297e-01,\n",
       "        -4.00837839e-01, -2.47749329e-01,  3.97470683e-01,\n",
       "        -2.60260522e-01,  2.50905901e-01,  1.68228999e-01,\n",
       "         1.33900374e-01, -2.10833065e-02, -4.70035344e-01,\n",
       "         4.78850007e-01,  2.80345649e-01, -4.64546829e-01,\n",
       "         3.21746975e-01,  2.34207228e-01,  2.45772153e-01,\n",
       "        -4.71482247e-01,  5.00401378e-01,  4.10190135e-01,\n",
       "         5.15216708e-01,  2.62549281e-01,  2.11592019e-02,\n",
       "        -3.89687359e-01, -2.41743013e-01, -2.14834556e-01,\n",
       "        -8.62650350e-02, -1.65323585e-01, -5.21897338e-02,\n",
       "         3.41874927e-01,  4.50314492e-01, -3.06973577e-01,\n",
       "        -2.02294320e-01,  6.85521543e-01, -5.33892214e-01,\n",
       "         3.58471721e-01,  1.45286605e-01, -7.07059205e-02,\n",
       "        -1.50529414e-01, -8.56281519e-02, -7.67852366e-02,\n",
       "         1.89544842e-01, -1.04067370e-01,  5.33543825e-01,\n",
       "        -5.27887166e-01,  2.42331922e-02, -2.64348000e-01,\n",
       "        -2.23186865e-01, -3.81208926e-01,  7.59915262e-02,\n",
       "        -4.64484811e-01, -3.36549312e-01,  4.21229661e-01,\n",
       "         1.07479259e-01,  1.90457746e-01,  2.89501133e-03,\n",
       "        -1.08513586e-01,  1.53545484e-01,  3.16023380e-01,\n",
       "        -2.70840749e-02, -5.40594578e-01,  8.97288620e-02,\n",
       "        -1.15549564e-01,  3.97804052e-01, -4.97683257e-01,\n",
       "        -2.84893304e-01,  4.99864556e-02,  3.61279517e-01,\n",
       "         6.90535605e-01,  1.46821499e-01,  1.73396409e-01,\n",
       "        -1.74582183e-01, -3.15702558e-01,  6.72998279e-02,\n",
       "         2.17250288e-01,  9.78536159e-02, -1.29472852e-01,\n",
       "        -1.86929807e-01,  1.34878218e-01, -1.53885365e-01,\n",
       "         7.44715482e-02, -1.85536280e-01, -2.80628264e-01,\n",
       "        -1.14144072e-01,  4.12249416e-01,  6.39495328e-02,\n",
       "        -1.45715266e-01, -9.82061177e-02, -1.33081883e-01,\n",
       "        -1.88410595e-01, -2.84842886e-02, -3.49510461e-02,\n",
       "         3.34261991e-02,  6.98899105e-02,  1.90354407e-01,\n",
       "        -2.96723992e-01,  2.64720735e-03,  1.09140679e-01,\n",
       "         1.70895495e-02,  2.60589302e-01,  3.29038441e-01,\n",
       "        -6.61557838e-02,  2.39665434e-01, -2.26194918e-01,\n",
       "        -3.36868651e-02,  1.49400264e-01, -3.21265340e-01,\n",
       "        -2.68577605e-01,  5.72631776e-01, -4.92308438e-01,\n",
       "         2.00666487e-01, -3.49261642e-01, -2.89887916e-02,\n",
       "         6.09010577e-01, -5.72333097e-01,  2.35000551e-01,\n",
       "         6.47176709e-03, -3.14949714e-02,  2.78107561e-02,\n",
       "        -3.90340656e-01, -2.08949938e-01, -3.04452598e-01,\n",
       "        -7.20197111e-02, -8.29838812e-02,  3.73792946e-01,\n",
       "         7.38936290e-02, -2.21076142e-02,  9.88138840e-02,\n",
       "        -1.51426643e-01, -1.40430748e-01,  2.26017803e-01,\n",
       "         2.76090115e-01, -8.87749195e-02, -1.12816125e-01,\n",
       "        -2.66286045e-01,  2.77834475e-01, -4.75609750e-02,\n",
       "         6.71005994e-02, -2.78585460e-02, -2.39992272e-02,\n",
       "         2.51708835e-01,  4.68793720e-01, -5.39325356e-01,\n",
       "         1.10598549e-01, -3.44947219e-01,  4.15989816e-01,\n",
       "         7.28483200e-02, -3.19647491e-01,  4.90374267e-01,\n",
       "        -7.30334781e-03, -2.64251698e-03,  9.63711202e-01,\n",
       "         3.23885113e-01, -7.79617652e-02, -2.37589464e-01,\n",
       "         2.34038487e-01, -3.16054076e-01, -1.65644055e-03,\n",
       "        -1.09070659e+00,  3.38409215e-01,  4.70605232e-02,\n",
       "         1.07435577e-01, -2.06672296e-01,  4.26454749e-03,\n",
       "        -1.38477178e-03, -5.31455398e-01, -2.75648445e-01,\n",
       "        -1.64648503e-01, -3.42916340e-01, -4.26119000e-01,\n",
       "         6.01812065e-01,  4.55971599e-01, -2.72702038e-01,\n",
       "        -3.45807038e-02,  2.62752354e-01, -6.34197099e-03,\n",
       "         2.79631108e-01, -2.53559142e-01, -1.68626413e-01,\n",
       "         3.82934958e-02,  2.07762957e-01, -4.31525975e-01,\n",
       "        -7.23999068e-02, -1.26854643e-01,  2.07029581e-02,\n",
       "         5.74441195e-01,  3.54672492e-01,  9.28302184e-02,\n",
       "         6.70506060e-02,  1.11520484e-01, -1.86512619e-02,\n",
       "         4.62351859e-01,  2.72504538e-01, -3.60474080e-01,\n",
       "         5.29415429e-01, -1.00330205e-03, -8.81359726e-02,\n",
       "         1.49975389e-01,  5.25861159e-02,  4.63517547e-01,\n",
       "        -3.96831512e-01,  2.42640600e-01, -2.08912313e-01,\n",
       "         3.65672231e-01, -4.73552034e-04,  5.33963442e-01,\n",
       "        -1.97879553e-01,  3.11583012e-01, -6.96714818e-01,\n",
       "        -4.29500431e-01, -4.49359208e-01, -2.71371286e-02,\n",
       "        -6.98711649e-02,  2.06174791e-01, -1.57107696e-01,\n",
       "         4.43521231e-01, -6.74266890e-02, -3.00924033e-01,\n",
       "         5.14859557e-01,  3.36029500e-01,  6.63375705e-02,\n",
       "        -1.15235046e-01, -2.95982361e-02,  2.79471934e-01,\n",
       "        -3.48197855e-02, -7.29324892e-02, -4.58473377e-02,\n",
       "         1.54262841e-01,  8.09356093e-01,  5.20327985e-01,\n",
       "        -4.02114868e-01, -3.23152877e-02, -1.10364109e-01,\n",
       "         7.50501826e-02, -1.51098520e-01,  8.45740259e-01,\n",
       "        -1.80843890e-01,  3.22573215e-01,  1.04707994e-01,\n",
       "         3.19663793e-01, -1.55085549e-01,  1.69236690e-01,\n",
       "        -2.56996930e-01,  2.01208994e-01,  1.77392900e-01,\n",
       "        -2.74333268e-01, -3.36944222e-01,  5.02357125e-01,\n",
       "        -1.18357331e-01, -2.01166943e-01, -5.36485672e-01,\n",
       "        -7.69809857e-02,  1.15381116e-02, -2.36464322e-01,\n",
       "        -2.98769549e-02,  1.31366700e-01,  2.94184446e-01,\n",
       "         9.90919620e-02, -5.43897390e-01,  1.40812904e-01,\n",
       "         3.66998702e-01,  5.04863672e-02,  1.99122533e-01,\n",
       "        -2.80674607e-01,  4.34192300e-01, -1.40275136e-01,\n",
       "         5.78048766e-01,  1.77715778e-01,  8.98361728e-02,\n",
       "         3.29651356e-01,  6.13008700e-02, -3.24933410e-01]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8938317-e31e-4e8d-b2d8-f92c1b5a300c",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbda3e66-005a-4ad0-8017-c1cc7cbf0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ec67ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "24/09/25 17:05:29 WARN Utils: Your hostname, dgx2h0194.spark.sjc4.nvmetal.net resolves to a loopback address: 127.0.1.1; using 10.150.30.2 instead (on interface enp134s0f0np0)\n",
      "24/09/25 17:05:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 17:05:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "num_threads = 6\n",
    "\n",
    "# Creating a local Spark session for demonstration, in case it hasn't already been created.\n",
    "\n",
    "_config = {\n",
    "    \"spark.master\": f\"local[{num_threads}]\",\n",
    "    \"spark.driver.host\": \"127.0.0.1\",\n",
    "    \"spark.task.maxFailures\": \"1\",\n",
    "    \"spark.driver.memory\": \"8g\",\n",
    "    \"spark.executor.memory\": \"8g\",\n",
    "    \"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\": \"false\",\n",
    "    \"spark.sql.pyspark.jvmStacktrace.enabled\": \"true\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "    \"spark.python.worker.reuse\": \"true\",\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"spark-dl-example\")\n",
    "for key, value in _config.items():\n",
    "    spark = spark.config(key, value)\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc1edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load IMDB reviews (test) dataset and write to parquet\n",
    "data = load_dataset(\"imdb\", split=\"test\")\n",
    "\n",
    "lines = []\n",
    "for example in data:\n",
    "    lines.append([example[\"text\"].split(\".\")[0]])\n",
    "\n",
    "len(lines)\n",
    "\n",
    "df = spark.createDataFrame(lines, ['lines']).repartition(10)\n",
    "df.schema\n",
    "\n",
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836e5f84-12c6-4c95-838e-53de7e46a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36703d23-37a3-40df-b09a-c68206d285b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story that is completely ununderst...|\n",
      "|                                                        Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                                                 I tried|\n",
      "|                                             This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|After I saw this I concluded that it was most likely a chick flick; afterward I found out that Keira's mother wrote t...|\n",
      "|Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-actors (lower than Don \"The Drag...|\n",
      "|I haven't seen this movie in years, the last time i did i was really drunk after 5 pints of tenant's at my local With...|\n",
      "|                                                                                Now don't get me wrong I love bad movies|\n",
      "|There I am sitting at home in the morning, suddenly my brother flips on what appears to be the stupidest looking movi...|\n",
      "|Yes, it was an awful movie, but there was a song near the beginning of the movie, I think, called \"I got a Woody\" or ...|\n",
      "|                                                        This was the most uninteresting horror flick I have seen to date|\n",
      "|Another in the long line of Conan wannabes that tired to cash in on that movie's success, this Italian monstrosity is...|\n",
      "|Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cranked-up Cuckoo theme (with er...|\n",
      "|Julie Andrews satirically prods her own goody-two-shoes image in this overproduced musical comedy-drama, but if she a...|\n",
      "|                                                                                            'Leatherheads' tries so hard|\n",
      "|                                   If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery Combs given the lead? Henrik...|\n",
      "|                                                                                                   Woa, talk about awful|\n",
      "|                                                                                      The guy mentioned to sue for the 1|\n",
      "|                                                                                           (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f780c026-0f3f-4aea-8b61-5b3dbae83fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "    def predict(inputs):\n",
    "        return model.encode(inputs.tolist())\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c88ddc-ca19-4430-8b0e-b9fae143b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = predict_batch_udf(predict_batch_fn,\n",
    "                           return_type=ArrayType(FloatType()),\n",
    "                           batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85344c22-4a4d-4cb0-8771-5836ae2794db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 ms, sys: 474 μs, total: 14.1 ms\n",
      "Wall time: 5.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23bb885-6ab0-4471-943d-4c10414100fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.65 ms, sys: 4.27 ms, total: 12.9 ms\n",
      "Wall time: 5.44 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(\"lines\"))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93bc6da3-d853-4233-b805-cb4a46f4f9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.11 ms, sys: 5.83 ms, total: 10.9 ms\n",
      "Wall time: 5.27 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2073616f-7151-4760-92f2-441dd0bfe9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       lines|                                                    encoding|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|A ridiculous movie, a terrible editing job, worst screenp...|[-0.13450998, -0.53543544, 0.054044724, -0.1395307, 0.549...|\n",
      "|Most of this film was okay, for a sequel of a sequel of a...|[-0.059694894, 0.13422318, -0.008580661, 0.10549253, -0.1...|\n",
      "|                                                     I tried|[0.36901277, 0.09817391, 0.44426093, -0.41252792, -0.3193...|\n",
      "|This movie attempted to make Stu Ungar's life interesting...|[-0.060258333, -0.15493791, -0.16713744, 0.31275272, 0.02...|\n",
      "|After I saw this I concluded that it was most likely a ch...|[0.13928875, -0.20784612, -0.22824976, -0.054931596, -0.0...|\n",
      "|Jeff Speakman never really made it beyond the lowest rank...|[0.14455551, -0.20156205, -0.20821445, -0.20774455, 0.034...|\n",
      "|I haven't seen this movie in years, the last time i did i...|[0.2815332, -0.037591986, 0.15386294, 0.11313074, -0.0129...|\n",
      "|                    Now don't get me wrong I love bad movies|[0.06719108, -0.6140374, 0.090577155, 0.13216184, -0.0889...|\n",
      "|There I am sitting at home in the morning, suddenly my br...|[-0.08504674, -0.19166522, -0.009252191, -0.123004645, 0....|\n",
      "|Yes, it was an awful movie, but there was a song near the...|[0.08346512, -0.23578641, 0.3226514, 0.25514194, 0.024855...|\n",
      "|This was the most uninteresting horror flick I have seen ...|[0.27159688, -0.012542346, -0.3189818, 0.058205746, 0.560...|\n",
      "|Another in the long line of Conan wannabes that tired to ...|[0.17248641, 0.38624954, -0.1419171, 0.05956771, -0.55486...|\n",
      "|Oh, why did it have to end like this? Laurel and Hardy's ...|[0.13119501, -0.31394944, 0.41252437, -0.070720136, 0.305...|\n",
      "|Julie Andrews satirically prods her own goody-two-shoes i...|[0.19234581, -0.63681465, 0.34188664, 0.15537423, 0.16873...|\n",
      "|                                'Leatherheads' tries so hard|[-0.010949258, 0.16067491, -0.008709184, -0.12315141, -0....|\n",
      "|If I wouldn't have had any expectations of this film, it ...|[0.22964647, -0.0050940826, 0.060505625, -0.055414334, -0...|\n",
      "|With several name actors (Lance Henrikson, David Warner, ...|[-0.12687303, -0.119252555, -0.27171782, -0.23525026, 0.0...|\n",
      "|                                       Woa, talk about awful|[0.0198607, 0.06868033, 0.7532427, 0.24146342, -0.2680221...|\n",
      "|                          The guy mentioned to sue for the 1|[-0.15802965, 0.48863316, -0.10316777, -0.0767561, -0.291...|\n",
      "|                               (Warning: Some spoilers ahead|[-0.43086466, -0.19871014, 0.31926548, -0.54000306, 0.405...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b730f5a3-f7eb-42aa-8869-881ecd0f5542",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8211920-234e-480f-bf87-6d719090e292",
   "metadata": {},
   "source": [
    "This notebook uses the [Python backend with a custom execution environment](https://github.com/triton-inference-server/python_backend#creating-custom-execution-environments) with the compatible versions of Python/Numpy for Triton 24.08, using a conda-pack environment created as follows:\n",
    "```\n",
    "conda create -n huggingface -c conda-forge python=3.10.0\n",
    "conda activate huggingface\n",
    "\n",
    "export PYTHONNOUSERSITE=True\n",
    "pip install numpy<2 conda-pack sentencepiece sentence_transformers transformers\n",
    "\n",
    "conda-pack  # huggingface.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "772e337e-1098-4c7b-ba81-8cb221a518e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69d0c93a-bb0b-46c5-9d28-7b08a2e70964",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy custom model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models\n",
    "cp -r models_config/hf_transformer models\n",
    "\n",
    "# add custom execution environment\n",
    "cp huggingface.tar.gz models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d7d4b-1a0b-4c5f-bc93-be2a039b6ea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1654cdc1-4f9a-4fd5-b7ac-6ca4215bde5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> starting triton: a6855c050b3a                                  (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "huggingface_cache_dir = \"{}/.cache/huggingface\".format(os.path.expanduser('~'))\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={\n",
    "                triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                huggingface_cache_dir: {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34de5f-89f8-455e-b45e-a557a4ab0f05",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2969d502-e97b-49d6-bf80-7d177ae867cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f1e6d6-6519-49e7-8465-4419547633b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 17:07:00 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29b0cc0d-c480-4e4a-bd41-207dc314cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool_),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c712b8f-6eb4-4fb8-9f0a-04feef847fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"hf_transformer\"),\n",
    "                           return_type=ArrayType(FloatType()),\n",
    "                           input_tensor_shapes=[[1]],\n",
    "                           batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "934c1a1f-b126-45b0-9c15-265236820ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 762 μs, total: 11.3 ms\n",
      "Wall time: 1.47 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f84cd3f6-b6a8-4142-859a-91f3c183457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.41 ms, sys: 0 ns, total: 5.41 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(\"lines\"))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "921a4c01-e296-4406-be90-86f20c8c582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 ms, sys: 196 μs, total: 4.86 ms\n",
      "Wall time: 198 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f67584e-9c4e-474f-b6ea-7811b14d116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       lines|                                                    encoding|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|A ridiculous movie, a terrible editing job, worst screenp...|[-0.13450995, -0.5354353, 0.054044887, -0.13953091, 0.549...|\n",
      "|Most of this film was okay, for a sequel of a sequel of a...|[-0.05969492, 0.13422322, -0.008580784, 0.10549266, -0.15...|\n",
      "|                                                     I tried|[0.36901197, 0.09817381, 0.44426036, -0.41252798, -0.3193...|\n",
      "|This movie attempted to make Stu Ungar's life interesting...|[-0.060258564, -0.15493858, -0.16713741, 0.31275284, 0.02...|\n",
      "|After I saw this I concluded that it was most likely a ch...|[0.13928875, -0.20784627, -0.22824982, -0.054931726, -0.0...|\n",
      "|Jeff Speakman never really made it beyond the lowest rank...|[0.14455555, -0.20156224, -0.20821439, -0.20774448, 0.034...|\n",
      "|I haven't seen this movie in years, the last time i did i...|[0.28153294, -0.037592027, 0.153863, 0.11313069, -0.01294...|\n",
      "|                    Now don't get me wrong I love bad movies|[0.06719094, -0.6140378, 0.09057657, 0.13216195, -0.08894...|\n",
      "|There I am sitting at home in the morning, suddenly my br...|[-0.08504678, -0.19166525, -0.009252314, -0.1230049, 0.16...|\n",
      "|Yes, it was an awful movie, but there was a song near the...|[0.08346511, -0.23578608, 0.32265142, 0.25514176, 0.02485...|\n",
      "|This was the most uninteresting horror flick I have seen ...|[0.27159724, -0.012542226, -0.31898203, 0.05820527, 0.560...|\n",
      "|Another in the long line of Conan wannabes that tired to ...|[0.17248617, 0.38624978, -0.14191712, 0.059567716, -0.554...|\n",
      "|Oh, why did it have to end like this? Laurel and Hardy's ...|[0.13119487, -0.31394964, 0.41252464, -0.0707198, 0.30527...|\n",
      "|Julie Andrews satirically prods her own goody-two-shoes i...|[0.19234547, -0.6368142, 0.34188676, 0.15537412, 0.168731...|\n",
      "|                                'Leatherheads' tries so hard|[-0.010949731, 0.16067511, -0.008709337, -0.12315144, -0....|\n",
      "|If I wouldn't have had any expectations of this film, it ...|[0.2296466, -0.005093502, 0.060506, -0.05541419, -0.18879...|\n",
      "|With several name actors (Lance Henrikson, David Warner, ...|[-0.12687282, -0.119252615, -0.2717178, -0.23525046, 0.00...|\n",
      "|                                       Woa, talk about awful|[0.019860342, 0.06868049, 0.753242, 0.24146327, -0.268022...|\n",
      "|                          The guy mentioned to sue for the 1|[-0.15803002, 0.48863262, -0.10316757, -0.0767559, -0.291...|\n",
      "|                               (Warning: Some spoilers ahead|[-0.4308653, -0.19870996, 0.31926543, -0.5400026, 0.40511...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0077c-785f-41af-9fa9-812e7fb63810",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e5466b-b5dc-4fe1-9012-0c87cdd72962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> stopping containers: ['a6855c050b3a']\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e82b9518-da7b-4ebc-8990-c8ab909bec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a60f2d-295a-4270-a2fd-16559962edda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
