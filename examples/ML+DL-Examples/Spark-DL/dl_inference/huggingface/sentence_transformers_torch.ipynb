{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "## Sentence Transformers with PyTorch\n",
    "\n",
    "From: https://huggingface.co/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731faab7-a700-46f8-bba5-1c8764e5eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "#Sentences we want to encode. Example:\n",
    "sentence = ['This framework generates embeddings for each input sentence']\n",
    "\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embedding = model.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96eea5ca-3cf7-46e3-b40c-598538112d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.76214442e-01,  1.20601296e-01, -2.93623716e-01,\n",
       "        -2.29858190e-01, -8.22924674e-02,  2.37709299e-01,\n",
       "         3.39985251e-01, -7.80964315e-01,  1.18127771e-01,\n",
       "         1.63373649e-01, -1.37715235e-01,  2.40282759e-01,\n",
       "         4.25125599e-01,  1.72417864e-01,  1.05279371e-01,\n",
       "         5.18164277e-01,  6.22220002e-02,  3.99285853e-01,\n",
       "        -1.81652412e-01, -5.85578561e-01,  4.49717119e-02,\n",
       "        -1.72750711e-01, -2.68443465e-01, -1.47386044e-01,\n",
       "        -1.89217836e-01,  1.92150354e-01, -3.83842438e-01,\n",
       "        -3.96006793e-01,  4.30649072e-01, -3.15319508e-01,\n",
       "         3.65950257e-01,  6.05155677e-02,  3.57325852e-01,\n",
       "         1.59736365e-01, -3.00983936e-01,  2.63250053e-01,\n",
       "        -3.94311160e-01,  1.84855491e-01, -3.99548888e-01,\n",
       "        -2.67889440e-01, -5.45117259e-01, -3.13406847e-02,\n",
       "        -4.30644035e-01,  1.33278221e-01, -1.74793795e-01,\n",
       "        -4.35465544e-01, -4.77378845e-01,  7.12555349e-02,\n",
       "        -7.37000108e-02,  5.69136977e-01, -2.82579541e-01,\n",
       "         5.24972938e-02, -8.20007920e-01,  1.98296875e-01,\n",
       "         1.69511825e-01,  2.71779895e-01,  2.64610827e-01,\n",
       "        -2.55740192e-02, -1.74096331e-01,  1.63314164e-01,\n",
       "        -3.95260692e-01, -3.17558199e-02, -2.62556046e-01,\n",
       "         3.52754325e-01,  3.01434696e-01, -1.47197351e-01,\n",
       "         2.10075766e-01, -1.84010506e-01, -4.12895888e-01,\n",
       "         4.14775968e-01, -1.89769372e-01, -1.35482132e-01,\n",
       "        -3.79272133e-01, -4.68024760e-02, -3.33600678e-02,\n",
       "         9.00393650e-02, -3.30132693e-01, -3.87316309e-02,\n",
       "         3.75082195e-01, -1.46996602e-01,  4.34959680e-01,\n",
       "         5.38325369e-01, -2.65445441e-01,  1.64445907e-01,\n",
       "         4.17078286e-01, -4.72506545e-02, -7.48733431e-02,\n",
       "        -4.26260769e-01, -1.96994647e-01,  6.10317551e-02,\n",
       "        -4.74263012e-01, -6.48334503e-01,  3.71462375e-01,\n",
       "         2.50956684e-01,  1.22529879e-01,  8.88766125e-02,\n",
       "        -1.06724329e-01,  5.33985868e-02,  9.74508449e-02,\n",
       "        -3.46654281e-02, -1.02883153e-01,  2.32288867e-01,\n",
       "        -2.53739476e-01, -5.13112068e-01,  1.85216203e-01,\n",
       "        -3.04357886e-01, -3.55210863e-02, -1.26974985e-01,\n",
       "        -7.71633387e-02, -5.15329778e-01, -2.28072032e-01,\n",
       "         2.03342997e-02,  7.38175735e-02, -1.52558237e-01,\n",
       "        -4.00837719e-01, -2.47749358e-01,  3.97470653e-01,\n",
       "        -2.60260284e-01,  2.50905961e-01,  1.68228880e-01,\n",
       "         1.33900225e-01, -2.10832842e-02, -4.70035255e-01,\n",
       "         4.78849858e-01,  2.80345500e-01, -4.64546949e-01,\n",
       "         3.21746677e-01,  2.34206975e-01,  2.45772198e-01,\n",
       "        -4.71482277e-01,  5.00401437e-01,  4.10190135e-01,\n",
       "         5.15216708e-01,  2.62549102e-01,  2.11588554e-02,\n",
       "        -3.89687389e-01, -2.41742820e-01, -2.14834481e-01,\n",
       "        -8.62649754e-02, -1.65323481e-01, -5.21897934e-02,\n",
       "         3.41874897e-01,  4.50314581e-01, -3.06973636e-01,\n",
       "        -2.02294186e-01,  6.85521483e-01, -5.33892512e-01,\n",
       "         3.58471423e-01,  1.45286620e-01, -7.07060024e-02,\n",
       "        -1.50529534e-01, -8.56281444e-02, -7.67851248e-02,\n",
       "         1.89544514e-01, -1.04067288e-01,  5.33543706e-01,\n",
       "        -5.27887106e-01,  2.42331605e-02, -2.64347732e-01,\n",
       "        -2.23186329e-01, -3.81208688e-01,  7.59916008e-02,\n",
       "        -4.64484870e-01, -3.36549312e-01,  4.21229631e-01,\n",
       "         1.07479282e-01,  1.90457791e-01,  2.89488304e-03,\n",
       "        -1.08513549e-01,  1.53545469e-01,  3.16023290e-01,\n",
       "        -2.70841252e-02, -5.40594518e-01,  8.97289664e-02,\n",
       "        -1.15549237e-01,  3.97803903e-01, -4.97683197e-01,\n",
       "        -2.84893334e-01,  4.99865375e-02,  3.61279637e-01,\n",
       "         6.90535605e-01,  1.46821395e-01,  1.73396334e-01,\n",
       "        -1.74582303e-01, -3.15702558e-01,  6.72996640e-02,\n",
       "         2.17250317e-01,  9.78535116e-02, -1.29472956e-01,\n",
       "        -1.86930090e-01,  1.34878308e-01, -1.53885514e-01,\n",
       "         7.44716972e-02, -1.85536057e-01, -2.80628145e-01,\n",
       "        -1.14144035e-01,  4.12249386e-01,  6.39496595e-02,\n",
       "        -1.45715207e-01, -9.82060283e-02, -1.33081973e-01,\n",
       "        -1.88410848e-01, -2.84842458e-02, -3.49509083e-02,\n",
       "         3.34262103e-02,  6.98897168e-02,  1.90354183e-01,\n",
       "        -2.96723932e-01,  2.64685880e-03,  1.09140687e-01,\n",
       "         1.70896612e-02,  2.60589182e-01,  3.29038411e-01,\n",
       "        -6.61557391e-02,  2.39665508e-01, -2.26195022e-01,\n",
       "        -3.36868055e-02,  1.49400383e-01, -3.21265429e-01,\n",
       "        -2.68577725e-01,  5.72631598e-01, -4.92308080e-01,\n",
       "         2.00666428e-01, -3.49261582e-01, -2.89887153e-02,\n",
       "         6.09010518e-01, -5.72333336e-01,  2.35000357e-01,\n",
       "         6.47177128e-03, -3.14948186e-02,  2.78106369e-02,\n",
       "        -3.90340745e-01, -2.08949968e-01, -3.04452598e-01,\n",
       "        -7.20196590e-02, -8.29839259e-02,  3.73792678e-01,\n",
       "         7.38938823e-02, -2.21077465e-02,  9.88135710e-02,\n",
       "        -1.51426226e-01, -1.40430659e-01,  2.26017982e-01,\n",
       "         2.76089966e-01, -8.87748376e-02, -1.12816051e-01,\n",
       "        -2.66286016e-01,  2.77834296e-01, -4.75608967e-02,\n",
       "         6.71007708e-02, -2.78585274e-02, -2.39991825e-02,\n",
       "         2.51708657e-01,  4.68793571e-01, -5.39325356e-01,\n",
       "         1.10598564e-01, -3.44947189e-01,  4.15989667e-01,\n",
       "         7.28481486e-02, -3.19647431e-01,  4.90374029e-01,\n",
       "        -7.30341207e-03, -2.64245505e-03,  9.63711023e-01,\n",
       "         3.23885083e-01, -7.79618695e-02, -2.37589434e-01,\n",
       "         2.34038591e-01, -3.16054046e-01, -1.65636267e-03,\n",
       "        -1.09070635e+00,  3.38409066e-01,  4.70604561e-02,\n",
       "         1.07435375e-01, -2.06672251e-01,  4.26479476e-03,\n",
       "        -1.38499646e-03, -5.31455338e-01, -2.75648326e-01,\n",
       "        -1.64648369e-01, -3.42916459e-01, -4.26118642e-01,\n",
       "         6.01812124e-01,  4.55971569e-01, -2.72702008e-01,\n",
       "        -3.45808305e-02,  2.62752414e-01, -6.34176936e-03,\n",
       "         2.79631048e-01, -2.53558934e-01, -1.68626472e-01,\n",
       "         3.82936969e-02,  2.07762867e-01, -4.31525886e-01,\n",
       "        -7.23999590e-02, -1.26854643e-01,  2.07028575e-02,\n",
       "         5.74441195e-01,  3.54672313e-01,  9.28302333e-02,\n",
       "         6.70509040e-02,  1.11520365e-01, -1.86510254e-02,\n",
       "         4.62351799e-01,  2.72504389e-01, -3.60473990e-01,\n",
       "         5.29415369e-01, -1.00333418e-03, -8.81361067e-02,\n",
       "         1.49975523e-01,  5.25862351e-02,  4.63517785e-01,\n",
       "        -3.96831334e-01,  2.42640570e-01, -2.08912209e-01,\n",
       "         3.65672082e-01, -4.73295280e-04,  5.33963323e-01,\n",
       "        -1.97879627e-01,  3.11582983e-01, -6.96714699e-01,\n",
       "        -4.29500312e-01, -4.49359298e-01, -2.71370821e-02,\n",
       "        -6.98710978e-02,  2.06174880e-01, -1.57107666e-01,\n",
       "         4.43521231e-01, -6.74267858e-02, -3.00924033e-01,\n",
       "         5.14859557e-01,  3.36029321e-01,  6.63373768e-02,\n",
       "        -1.15234762e-01, -2.95979045e-02,  2.79472023e-01,\n",
       "        -3.48199941e-02, -7.29324371e-02, -4.58472706e-02,\n",
       "         1.54262632e-01,  8.09355795e-01,  5.20327806e-01,\n",
       "        -4.02114660e-01, -3.23150419e-02, -1.10364117e-01,\n",
       "         7.50502497e-02, -1.51098579e-01,  8.45740020e-01,\n",
       "        -1.80843905e-01,  3.22573304e-01,  1.04707941e-01,\n",
       "         3.19663793e-01, -1.55085400e-01,  1.69236585e-01,\n",
       "        -2.56996840e-01,  2.01209217e-01,  1.77392632e-01,\n",
       "        -2.74333328e-01, -3.36944222e-01,  5.02357006e-01,\n",
       "        -1.18357234e-01, -2.01167136e-01, -5.36485553e-01,\n",
       "        -7.69810751e-02,  1.15381386e-02, -2.36464173e-01,\n",
       "        -2.98768189e-02,  1.31366760e-01,  2.94184476e-01,\n",
       "         9.90919322e-02, -5.43897390e-01,  1.40812635e-01,\n",
       "         3.66998672e-01,  5.04862741e-02,  1.99122488e-01,\n",
       "        -2.80674517e-01,  4.34192181e-01, -1.40275106e-01,\n",
       "         5.78048468e-01,  1.77715704e-01,  8.98358151e-02,\n",
       "         3.29651326e-01,  6.13008887e-02, -3.24933261e-01]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8938317-e31e-4e8d-b2d8-f92c1b5a300c",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbda3e66-005a-4ad0-8017-c1cc7cbf0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "conda_env = os.environ.get(\"CONDA_PREFIX\")\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.task.maxFailures\", \"1\")\n",
    "conf.set(\"spark.driver.memory\", \"8g\")\n",
    "conf.set(\"spark.executor.memory\", \"8g\")\n",
    "conf.set(\"spark.pyspark.python\", f\"{conda_env}/bin/python\")\n",
    "conf.set(\"spark.pyspark.driver.python\", f\"{conda_env}/bin/python\")\n",
    "conf.set(\"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\", \"false\")\n",
    "conf.set(\"spark.sql.pyspark.jvmStacktrace.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "conf.set(\"spark.python.worker.reuse\", \"true\")\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"spark-dl-examples\").config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc1edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load IMDB reviews (test) dataset and write to parquet\n",
    "data = load_dataset(\"imdb\", split=\"test\")\n",
    "\n",
    "lines = []\n",
    "for example in data:\n",
    "    lines.append([example[\"text\"].split(\".\")[0]])\n",
    "\n",
    "len(lines)\n",
    "\n",
    "df = spark.createDataFrame(lines, ['lines']).repartition(10)\n",
    "df.schema\n",
    "\n",
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836e5f84-12c6-4c95-838e-53de7e46a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36703d23-37a3-40df-b09a-c68206d285b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                       This is so overly clichéd you'll want to switch it off after the first 45 minutes|\n",
      "|                                                                                   I was very disappointed by this movie|\n",
      "|                                                                             I think vampire movies (usually) are wicked|\n",
      "|                           Though not a complete waste of time, 'Eighteen' really wasn't all sweet as it pretended to be|\n",
      "|This film did well at the box office, and the producers of this mess thought the stars had such good chemistry in thi...|\n",
      "|                                                    Peter Crawford discovers a comet on a collision course with the moon|\n",
      "|This tale of the upper-classes getting their come-uppance and wallowing in their high-class misery is like a contempo...|\n",
      "|Words almost fail me to describe how terrible this Irish vanity project (funded by Canadian taxpayers - both federal ...|\n",
      "|                                                        This was the most uninteresting horror flick I have seen to date|\n",
      "|                                                                                          Heart of Darkness was terrible|\n",
      "|                                                            I saw this movie when it was first released in Pittsburgh Pa|\n",
      "|It was funny because the whole thing was so unrealistic, I mean, come on, like a pop star would just show up at a pub...|\n",
      "|Watching this movie, you just have to ask: What were they thinking? There are so many noticeably bad parts of this mo...|\n",
      "|                                                                In a sense, this movie did not even compare to the novel|\n",
      "|                          Poor Jane Austen ought to be glad she's not around to see this dreadful wreck of an adaptation|\n",
      "|                                                                  I gave this movie a four-star rating for a few reasons|\n",
      "|                                                    It seems that Dee Snyder ran out of ideas halfway through the script|\n",
      "|                 Now, let me see if I have this correct, a lunatic serial killer is going around murdering estate agents|\n",
      "|                                                      Tommy Lee Jones was the best Woodroe and no one can play Woodroe F|\n",
      "|First of all, I would like to say that I am a fan of all of the actors that appear in this film and at the time that ...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f780c026-0f3f-4aea-8b61-5b3dbae83fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "    def predict(inputs):\n",
    "        return model.encode(inputs.tolist())\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c88ddc-ca19-4430-8b0e-b9fae143b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = predict_batch_udf(predict_batch_fn,\n",
    "                           return_type=ArrayType(FloatType()),\n",
    "                           batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85344c22-4a4d-4cb0-8771-5836ae2794db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.71 ms, sys: 4.01 ms, total: 8.71 ms\n",
      "Wall time: 2.61 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23bb885-6ab0-4471-943d-4c10414100fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.29 ms, sys: 808 μs, total: 6.1 ms\n",
      "Wall time: 2.42 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(\"lines\"))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93bc6da3-d853-4233-b805-cb4a46f4f9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.38 ms, sys: 2.02 ms, total: 6.4 ms\n",
      "Wall time: 2.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2073616f-7151-4760-92f2-441dd0bfe9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       lines|                                                    encoding|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|This is so overly clichéd you'll want to switch it off af...|[-0.06755405, -0.13365394, 0.36675274, -0.2772311, -0.085...|\n",
      "|                       I was very disappointed by this movie|[-0.05903806, 0.16684641, 0.16768408, 0.10940918, 0.18100...|\n",
      "|                 I think vampire movies (usually) are wicked|[0.025601083, -0.5308639, -0.319133, -0.013351389, -0.338...|\n",
      "|Though not a complete waste of time, 'Eighteen' really wa...|[0.20991832, 0.5228605, 0.44517252, -0.031682555, -0.4117...|\n",
      "|This film did well at the box office, and the producers o...|[0.18097948, -0.03622232, -0.34149718, 0.061557338, -0.06...|\n",
      "|Peter Crawford discovers a comet on a collision course wi...|[-0.27548054, 0.196654, -0.24626413, -0.39380816, -0.5501...|\n",
      "|This tale of the upper-classes getting their come-uppance...|[0.24201547, 0.011018356, -0.080340266, 0.31388673, -0.28...|\n",
      "|Words almost fail me to describe how terrible this Irish ...|[0.055901285, -0.14539501, -0.14005454, -0.038912475, 0.4...|\n",
      "|This was the most uninteresting horror flick I have seen ...|[0.27159664, -0.012541974, -0.31898177, 0.058205508, 0.56...|\n",
      "|                              Heart of Darkness was terrible|[0.1593065, 0.36501122, 0.10715093, 0.76344764, 0.2555183...|\n",
      "|I saw this movie when it was first released in Pittsburgh Pa|[-0.34647614, 0.115615666, -0.18874267, 0.36590436, -0.06...|\n",
      "|It was funny because the whole thing was so unrealistic, ...|[0.09473594, -0.43785918, 0.14436111, 0.0045353747, -0.08...|\n",
      "|Watching this movie, you just have to ask: What were they...|[0.43020695, -0.09714467, 0.1356213, 0.23126744, -0.03908...|\n",
      "|    In a sense, this movie did not even compare to the novel|[0.2838324, -0.018966805, -0.37275136, 0.27034461, 0.2017...|\n",
      "|Poor Jane Austen ought to be glad she's not around to see...|[0.27462235, -0.32494685, 0.48243234, 0.07208571, 0.22470...|\n",
      "|      I gave this movie a four-star rating for a few reasons|[0.31143323, -0.09470663, -0.10863629, 0.077851094, -0.15...|\n",
      "|It seems that Dee Snyder ran out of ideas halfway through...|[0.44354546, -0.08122106, -0.15206784, -0.29244298, 0.559...|\n",
      "|Now, let me see if I have this correct, a lunatic serial ...|[0.39831734, 0.15871558, -0.35366735, -0.11643518, -0.137...|\n",
      "|Tommy Lee Jones was the best Woodroe and no one can play ...|[-0.20960264, -0.15760101, -0.30596393, -0.51817703, -0.0...|\n",
      "|First of all, I would like to say that I am a fan of all ...|[0.25831866, -0.26871824, 0.026099348, -0.3459879, -0.180...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b730f5a3-f7eb-42aa-8869-881ecd0f5542",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f502a20",
   "metadata": {},
   "source": [
    "This notebook uses the [Python backend with a custom execution environment](https://github.com/triton-inference-server/python_backend#creating-custom-execution-environments) with the compatible versions of Python/Numpy for Triton 24.08, using a conda-pack environment created as follows:\n",
    "```\n",
    "conda create -n huggingface-torch -c conda-forge python=3.10.0\n",
    "conda activate huggingface-torch\n",
    "\n",
    "export PYTHONNOUSERSITE=True\n",
    "pip install numpy==1.26.4 conda-pack sentencepiece sentence_transformers transformers\n",
    "\n",
    "conda-pack  # huggingface-torch.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "772e337e-1098-4c7b-ba81-8cb221a518e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69d0c93a-bb0b-46c5-9d28-7b08a2e70964",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy custom model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models\n",
    "cp -r models_config/hf_transformer_torch models\n",
    "\n",
    "# add custom execution environment\n",
    "cp huggingface-torch.tar.gz models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d7d4b-1a0b-4c5f-bc93-be2a039b6ea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1654cdc1-4f9a-4fd5-b7ac-6ca4215bde5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "huggingface_cache_dir = \"{}/.cache/huggingface\".format(os.path.expanduser('~'))\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={\n",
    "                triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                huggingface_cache_dir: {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34de5f-89f8-455e-b45e-a557a4ab0f05",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2969d502-e97b-49d6-bf80-7d177ae867cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f1e6d6-6519-49e7-8465-4419547633b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/03 17:26:21 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29b0cc0d-c480-4e4a-bd41-207dc314cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool_),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c712b8f-6eb4-4fb8-9f0a-04feef847fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"hf_transformer_torch\"),\n",
    "                           return_type=ArrayType(FloatType()),\n",
    "                           input_tensor_shapes=[[1]],\n",
    "                           batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "934c1a1f-b126-45b0-9c15-265236820ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.96 ms, sys: 4.41 ms, total: 11.4 ms\n",
      "Wall time: 504 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f84cd3f6-b6a8-4142-859a-91f3c183457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 ms, sys: 1.15 ms, total: 3.5 ms\n",
      "Wall time: 417 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(\"lines\"))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "921a4c01-e296-4406-be90-86f20c8c582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 ms, sys: 48 μs, total: 3.15 ms\n",
      "Wall time: 389 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f67584e-9c4e-474f-b6ea-7811b14d116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       lines|                                                    encoding|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|This is so overly clichéd you'll want to switch it off af...|[-0.06755393, -0.1336537, 0.366753, -0.2772312, -0.085145...|\n",
      "|                       I was very disappointed by this movie|[-0.059038587, 0.1668467, 0.16768396, 0.10940957, 0.18100...|\n",
      "|                 I think vampire movies (usually) are wicked|[0.025601566, -0.5308643, -0.31913283, -0.013350786, -0.3...|\n",
      "|Though not a complete waste of time, 'Eighteen' really wa...|[0.2099183, 0.5228606, 0.4451728, -0.031682458, -0.411756...|\n",
      "|This film did well at the box office, and the producers o...|[0.1809797, -0.036222238, -0.34149715, 0.06155738, -0.066...|\n",
      "|Peter Crawford discovers a comet on a collision course wi...|[-0.27548066, 0.196654, -0.24626443, -0.3938084, -0.55015...|\n",
      "|This tale of the upper-classes getting their come-uppance...|[0.24201535, 0.011018419, -0.080340445, 0.31388694, -0.28...|\n",
      "|Words almost fail me to describe how terrible this Irish ...|[0.05590127, -0.14539507, -0.14005487, -0.03891221, 0.444...|\n",
      "|This was the most uninteresting horror flick I have seen ...|[0.2715968, -0.012542339, -0.3189819, 0.05820581, 0.56001...|\n",
      "|                              Heart of Darkness was terrible|[0.15930629, 0.36501077, 0.10715161, 0.7634482, 0.2555183...|\n",
      "|I saw this movie when it was first released in Pittsburgh Pa|[-0.34647676, 0.11561544, -0.18874292, 0.36590466, -0.068...|\n",
      "|It was funny because the whole thing was so unrealistic, ...|[0.09473588, -0.4378593, 0.14436121, 0.0045354995, -0.085...|\n",
      "|Watching this movie, you just have to ask: What were they...|[0.43020678, -0.09714476, 0.13562134, 0.23126753, -0.0390...|\n",
      "|    In a sense, this movie did not even compare to the novel|[0.28383228, -0.01896684, -0.37275153, 0.27034503, 0.2017...|\n",
      "|Poor Jane Austen ought to be glad she's not around to see...|[0.27462238, -0.32494652, 0.48243237, 0.07208576, 0.22470...|\n",
      "|      I gave this movie a four-star rating for a few reasons|[0.311433, -0.09470633, -0.10863638, 0.07785072, -0.15611...|\n",
      "|It seems that Dee Snyder ran out of ideas halfway through...|[0.44354525, -0.08122053, -0.15206799, -0.29244322, 0.559...|\n",
      "|Now, let me see if I have this correct, a lunatic serial ...|[0.39831725, 0.15871589, -0.35366756, -0.11643555, -0.137...|\n",
      "|Tommy Lee Jones was the best Woodroe and no one can play ...|[-0.20960276, -0.157601, -0.30596414, -0.5181772, -0.0852...|\n",
      "|First of all, I would like to say that I am a fan of all ...|[0.25831848, -0.26871827, 0.026099432, -0.34598774, -0.18...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0077c-785f-41af-9fa9-812e7fb63810",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e5466b-b5dc-4fe1-9012-0c87cdd72962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e82b9518-da7b-4ebc-8990-c8ab909bec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a60f2d-295a-4270-a2fd-16559962edda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-dl-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
