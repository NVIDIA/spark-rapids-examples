{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f7ac5d-4a95-4170-a0ac-a7faac9d9ef4",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "### Text Classification using Pipelines with PyTorch\n",
    "\n",
    "Based on: https://huggingface.co/docs/transformers/quicktour#pipeline-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dd0f77b-ee1b-4477-a038-d25a4f1da0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1f756c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device if gpu is available\n",
    "device = 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "553b28d2-a5d1-4d07-8a49-8f82b808e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b91fe91-b725-4564-ae93-56e3fb51e47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier((\"We are very happy to show you the ðŸ¤— Transformers library.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0be39eb3-462c-42ff-b8f4-09f4e4fe3a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752f929",
   "metadata": {},
   "source": [
    "#### Use another model and tokenizer in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9861865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "506e7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "312017fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.7272651791572571}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device)\n",
    "classifier(\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ðŸ¤— Transformers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92b15e-0da0-46c3-81a3-fabaedbfc42c",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69dd6a1a-f450-47f0-9dbf-ad250585a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, struct, pandas_udf\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.types import FloatType, StringType, StructField, StructType\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e0e0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 6\n",
    "\n",
    "# Creating a local Spark session for demonstration, in case it hasn't already been created.\n",
    "\n",
    "_config = {\n",
    "    \"spark.master\": f\"local[{num_threads}]\",\n",
    "    \"spark.driver.host\": \"127.0.0.1\",\n",
    "    \"spark.task.maxFailures\": \"1\",\n",
    "    \"spark.driver.memory\": \"8g\",\n",
    "    \"spark.executor.memory\": \"8g\",\n",
    "    \"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\": \"false\",\n",
    "    \"spark.sql.pyspark.jvmStacktrace.enabled\": \"true\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "    \"spark.python.worker.reuse\": \"true\",\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"spark-dl-example\")\n",
    "for key, value in _config.items():\n",
    "    spark = spark.config(key, value)\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42d70208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the IMDB dataset\n",
    "data = load_dataset(\"imdb\", split=\"test\")\n",
    "\n",
    "lines = []\n",
    "for example in data:\n",
    "    # first sentence only\n",
    "    lines.append([example[\"text\"]])\n",
    "\n",
    "len(lines)\n",
    "\n",
    "df = spark.createDataFrame(lines, ['lines']).repartition(10).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac24f3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 17:23:32 WARN TaskSetManager: Stage 0 contains a task of very large size (5123 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9665b7b6-d7e9-4bd4-b29d-7a449ac5b574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+\n",
      "|                                                                        sentence|\n",
      "+--------------------------------------------------------------------------------+\n",
      "|In following Dylan Moran's star from the charming misanthrope bookstore owner...|\n",
      "|Here in Australia Nights in Rodanthe is being promoted in the same class as t...|\n",
      "|           The Tender Hook, or, Who Killed The Australian Film Industry? Case No|\n",
      "|The only reason I'm even giving this movie a 4 is because it was made in to a...|\n",
      "|Hooray for Title Misspellings! After reading reviews and contemplating, my gi...|\n",
      "|                        This movie makes you wish imdb would let you vote a zero|\n",
      "|To me this film is just a very very lame teen party movie with all the normal...|\n",
      "|                                                                         I tried|\n",
      "|Awkward disaster mishmash has a team of scavengers coming across the overturn...|\n",
      "|According to the blurb on the back of the DVD case; Jonothan Ross 'laughed un...|\n",
      "|           It'll be a blue Christmas indeed if you subject you're family to this|\n",
      "|This is the story of a maniac cop who, for some reason, has it in for a young...|\n",
      "|I bought a tape of this film based on the recommendation of other IMDb users ...|\n",
      "|             I usually don't consider turning a movie off unless it's REALLY bad|\n",
      "|I watched this years ago on television when I was sick (I don't know, I tend ...|\n",
      "|Am I the only one to notice that the \"realism\" of the 19th century ship is er...|\n",
      "|This movie, despite its list of B, C, and D list celebs, is a complete waste ...|\n",
      "|To put in simple words or rather a word, would be best suited by PATHETIC !!!...|\n",
      "|You may like Tim Burton's fantasies, but not in a commercial-like show off la...|\n",
      "|                      I've expected a comedy about the NVA, but this is a parody|\n",
      "+--------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only use first sentence of IMDB reviews\n",
    "@pandas_udf(\"string\")\n",
    "def first_sentence(text: pd.Series) -> pd.Series:\n",
    "    return pd.Series([s.split(\".\")[0] for s in text])\n",
    "\n",
    "df = spark.read.parquet(\"imdb_test\").withColumn(\"sentence\", first_sentence(col(\"lines\"))).select(\"sentence\").limit(100).cache()\n",
    "df.show(truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0da9d25c-5ebe-4503-bb19-154fcc047cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import torch\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    pipe = pipeline(\"sentiment-analysis\", device=device)\n",
    "    def predict(inputs):\n",
    "        return pipe(inputs.tolist())\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78afef29-ee30-4267-9fb6-be2dcb86cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=StructType([\n",
    "                                 StructField(\"label\", StringType(), True),\n",
    "                                 StructField(\"score\", FloatType(), True)\n",
    "                             ]),\n",
    "                             batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5bc327e-89cf-4731-82e6-e66cb93deef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 ms, sys: 9.57 ms, total: 10.8 ms\n",
      "Wall time: 5.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "preds = df.withColumn(\"preds\", classify(struct(\"sentence\"))).select(\"sentence\", \"preds.*\")\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac642895-cfd6-47ee-9b21-02e7835424e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 ms, sys: 4.6 ms, total: 6.42 ms\n",
      "Wall time: 756 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "preds = df.withColumn(\"preds\", classify(\"sentence\")).select(\"sentence\", \"preds.*\")\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76a44d80-d5db-405f-989c-7246379cfb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.31 ms, sys: 0 ns, total: 4.31 ms\n",
      "Wall time: 711 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "preds = df.withColumn(\"preds\", classify(col(\"sentence\"))).select(\"sentence\", \"preds.*\")\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c01761b3-c766-46b0-ae0b-fcf968ffb3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+--------+----------+\n",
      "|                                                                        sentence|   label|     score|\n",
      "+--------------------------------------------------------------------------------+--------+----------+\n",
      "|In following Dylan Moran's star from the charming misanthrope bookstore owner...|NEGATIVE|0.94646263|\n",
      "|Here in Australia Nights in Rodanthe is being promoted in the same class as t...|NEGATIVE| 0.9811111|\n",
      "|           The Tender Hook, or, Who Killed The Australian Film Industry? Case No|NEGATIVE|0.98526716|\n",
      "|The only reason I'm even giving this movie a 4 is because it was made in to a...|NEGATIVE| 0.9995627|\n",
      "|Hooray for Title Misspellings! After reading reviews and contemplating, my gi...|NEGATIVE|0.99946946|\n",
      "|                        This movie makes you wish imdb would let you vote a zero|NEGATIVE| 0.9981305|\n",
      "|To me this film is just a very very lame teen party movie with all the normal...|NEGATIVE| 0.9989936|\n",
      "|                                                                         I tried|POSITIVE|  0.907131|\n",
      "|Awkward disaster mishmash has a team of scavengers coming across the overturn...|NEGATIVE|0.99977237|\n",
      "|According to the blurb on the back of the DVD case; Jonothan Ross 'laughed un...|NEGATIVE|0.95564646|\n",
      "|           It'll be a blue Christmas indeed if you subject you're family to this|POSITIVE| 0.9996747|\n",
      "|This is the story of a maniac cop who, for some reason, has it in for a young...|NEGATIVE|0.95095587|\n",
      "|I bought a tape of this film based on the recommendation of other IMDb users ...|NEGATIVE| 0.9994485|\n",
      "|             I usually don't consider turning a movie off unless it's REALLY bad|NEGATIVE| 0.9983766|\n",
      "|I watched this years ago on television when I was sick (I don't know, I tend ...|NEGATIVE| 0.9987041|\n",
      "|Am I the only one to notice that the \"realism\" of the 19th century ship is er...|NEGATIVE|   0.99914|\n",
      "|This movie, despite its list of B, C, and D list celebs, is a complete waste ...|NEGATIVE|0.99979585|\n",
      "|To put in simple words or rather a word, would be best suited by PATHETIC !!!...|NEGATIVE|0.99920565|\n",
      "|You may like Tim Burton's fantasies, but not in a commercial-like show off la...|NEGATIVE| 0.9734402|\n",
      "|                      I've expected a comedy about the NVA, but this is a parody|NEGATIVE| 0.9439922|\n",
      "+--------------------------------------------------------------------------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb826fde-99d9-43fe-8ddc-f5acbe76b4e9",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10368010-f94d-4167-91a1-2cf9ed91a2c9",
   "metadata": {},
   "source": [
    "This notebook uses the [Python backend with a custom execution environment](https://github.com/triton-inference-server/python_backend#creating-custom-execution-environments) with the compatible versions of Python/Numpy for Triton 24.08, using a conda-pack environment created as follows:\n",
    "```\n",
    "conda create -n huggingface -c conda-forge python=3.10.0\n",
    "conda activate huggingface\n",
    "\n",
    "export PYTHONNOUSERSITE=True\n",
    "pip install numpy==1.26.4 conda-pack sentencepiece sentence_transformers transformers\n",
    "\n",
    "conda-pack  # huggingface.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d4be844-4b8c-47df-bd09-0c280c7ff16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct, pandas_udf\n",
    "from pyspark.sql.types import FloatType, StringType, StructField, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e53df9f-43cb-4c38-b8ac-dc2cbad99815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy custom model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models\n",
    "cp -r models_config/hf_pipeline models\n",
    "\n",
    "# add custom execution environment\n",
    "cp huggingface.tar.gz models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a5b06-126a-4bc4-baae-a45ea30832a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "144acb8e-4c08-40fc-a9ed-f721c409ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> starting triton: 051f90cdbb4f                                  (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "huggingface_cache_dir = \"{}/.cache/huggingface\".format(os.path.expanduser('~'))\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"256M\",\n",
    "            volumes={\n",
    "                triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                huggingface_cache_dir: {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        \n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        \n",
    "        elapsed = 0\n",
    "        timeout = 120\n",
    "        ready = False\n",
    "        while not ready and elapsed < timeout:\n",
    "            try:\n",
    "                time.sleep(5)\n",
    "                elapsed += 5\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d77ab-60d3-45eb-a9c2-dc811eca0af4",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d53fb283-bf9e-4571-8c68-b75a41f1f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence of IMDB reviews\n",
    "@pandas_udf(\"string\")\n",
    "def first_sentence(text: pd.Series) -> pd.Series:\n",
    "    return pd.Series([s.split(\".\")[0] for s in text])\n",
    "\n",
    "df = spark.read.parquet(\"imdb_test\").withColumn(\"sentence\", first_sentence(col(\"lines\"))).select(\"sentence\").limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29b0cc0d-c480-4e4a-bd41-207dc314cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool_),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3930cfcd-3284-4c6a-a9b5-36b8053fe899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "classify = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"hf_pipeline\"),\n",
    "                             return_type=StructType([\n",
    "                                 StructField(\"label\", StringType(), True),\n",
    "                                 StructField(\"score\", FloatType(), True)\n",
    "                             ]),\n",
    "                             input_tensor_shapes=[[1]],\n",
    "                             batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8eecbf23-4e9e-4d4c-8645-98209b25db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 ms, sys: 5.09 ms, total: 12.2 ms\n",
      "Wall time: 6.01 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "preds = df.withColumn(\"preds\", classify(struct(\"sentence\"))).select(\"sentence\", \"preds.*\")\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "566ba28c-0ca4-4479-a24a-c8a362228b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.46 ms, sys: 6.75 ms, total: 11.2 ms\n",
      "Wall time: 5.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "preds = df.withColumn(\"preds\", classify(\"sentence\")).select(\"sentence\", \"preds.*\")\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44c7e776-08da-484a-ba07-9d6add1a0f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.91 ms, sys: 1.55 ms, total: 10.5 ms\n",
      "Wall time: 5.73 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# note: expanding the \"struct\" return_type to top-level columns\n",
    "preds = df.withColumn(\"preds\", classify(col(\"sentence\"))).select(\"sentence\", \"preds.*\")\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f61d79f8-661e-4d9e-a3aa-c0754b854603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "|sentence                                                                                                                                                                                                                                                                                                |label   |score     |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "|In following Dylan Moran's star from the charming misanthrope bookstore owner in the surrealist sitcom Black Books, I could see his comic potential begging to be utilised in theater or larger cinematic avenues                                                                                       |NEGATIVE|0.94646263|\n",
      "|Here in Australia Nights in Rodanthe is being promoted in the same class as the Notebook                                                                                                                                                                                                                |NEGATIVE|0.9811111 |\n",
      "|The Tender Hook, or, Who Killed The Australian Film Industry? Case No                                                                                                                                                                                                                                   |NEGATIVE|0.98526716|\n",
      "|The only reason I'm even giving this movie a 4 is because it was made in to an episode of Mystery Science Theater 3000                                                                                                                                                                                  |NEGATIVE|0.9995627 |\n",
      "|Hooray for Title Misspellings! After reading reviews and contemplating, my girlfriend and I confirmed that this movie is an utter piece of trash                                                                                                                                                        |NEGATIVE|0.99946946|\n",
      "|This movie makes you wish imdb would let you vote a zero                                                                                                                                                                                                                                                |NEGATIVE|0.9981305 |\n",
      "|To me this film is just a very very lame teen party movie with all the normal clichÃ©s and boring stereotyped characters (Nerds, Jocks, Popular girls, Sleezy guys, etc) but with an underlying anti drug/drinking theme                                                                                 |NEGATIVE|0.9989936 |\n",
      "|I tried                                                                                                                                                                                                                                                                                                 |POSITIVE|0.907131  |\n",
      "|Awkward disaster mishmash has a team of scavengers coming across the overturned S                                                                                                                                                                                                                       |NEGATIVE|0.99977237|\n",
      "|According to the blurb on the back of the DVD case; Jonothan Ross 'laughed until a little bit of wee came out'                                                                                                                                                                                          |NEGATIVE|0.95564646|\n",
      "|It'll be a blue Christmas indeed if you subject you're family to this                                                                                                                                                                                                                                   |POSITIVE|0.9996747 |\n",
      "|This is the story of a maniac cop who, for some reason, has it in for a young college stud and his mates                                                                                                                                                                                                |NEGATIVE|0.95095587|\n",
      "|I bought a tape of this film based on the recommendation of other IMDb users and have to say that I was very disappointed                                                                                                                                                                               |NEGATIVE|0.9994485 |\n",
      "|I usually don't consider turning a movie off unless it's REALLY bad                                                                                                                                                                                                                                     |NEGATIVE|0.9983766 |\n",
      "|I watched this years ago on television when I was sick (I don't know, I tend to be more complacent with my TV viewing when I'm sick; too much effort to use the remote control, I guess)                                                                                                                |NEGATIVE|0.9987041 |\n",
      "|Am I the only one to notice that the \"realism\" of the 19th century ship is erroneous                                                                                                                                                                                                                    |NEGATIVE|0.99914   |\n",
      "|This movie, despite its list of B, C, and D list celebs, is a complete waste of 90 minutes                                                                                                                                                                                                              |NEGATIVE|0.99979585|\n",
      "|To put in simple words or rather a word, would be best suited by PATHETIC !!!!!! The movie starts with attracting a little interest by the plot, but, BUT as few minutes by audience is getting restless for restrooms and getting snacks, or to get a breathe of fresh air outside the closed dark hall|NEGATIVE|0.99920565|\n",
      "|You may like Tim Burton's fantasies, but not in a commercial-like show off lasting 8 minutes                                                                                                                                                                                                            |NEGATIVE|0.9734402 |\n",
      "|I've expected a comedy about the NVA, but this is a parody                                                                                                                                                                                                                                              |NEGATIVE|0.9439922 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197c146-1794-47f0-bcd9-7e8d8ab8625f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "425d3b28-7705-45ba-8a18-ad34fc895219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> stopping containers: ['051f90cdbb4f']\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f19643c-4ee4-44f2-b762-2078c0c8eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a538c47-317d-4cac-b9b9-559e88677518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
