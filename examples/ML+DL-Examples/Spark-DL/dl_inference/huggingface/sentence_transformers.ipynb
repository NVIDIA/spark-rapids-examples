{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "### Sentence Transformers\n",
    "\n",
    "From: https://huggingface.co/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731faab7-a700-46f8-bba5-1c8764e5eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leey/.pyenv/versions/3.9.10/envs/spark_rapids_examples/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "#Sentences we want to encode. Example:\n",
    "sentence = ['This framework generates embeddings for each input sentence']\n",
    "\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embedding = model.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96eea5ca-3cf7-46e3-b40c-598538112d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.76214516e-01,  1.20601304e-01, -2.93624043e-01,\n",
       "        -2.29858175e-01, -8.22924003e-02,  2.37709180e-01,\n",
       "         3.39985013e-01, -7.80964136e-01,  1.18127793e-01,\n",
       "         1.63374111e-01, -1.37715325e-01,  2.40282863e-01,\n",
       "         4.25125599e-01,  1.72417879e-01,  1.05279416e-01,\n",
       "         5.18164098e-01,  6.22219592e-02,  3.99285942e-01,\n",
       "        -1.81652382e-01, -5.85578799e-01,  4.49718162e-02,\n",
       "        -1.72750458e-01, -2.68443376e-01, -1.47386298e-01,\n",
       "        -1.89217895e-01,  1.92150623e-01, -3.83842528e-01,\n",
       "        -3.96006793e-01,  4.30648834e-01, -3.15320045e-01,\n",
       "         3.65949810e-01,  6.05160184e-02,  3.57326001e-01,\n",
       "         1.59736484e-01, -3.00984085e-01,  2.63250291e-01,\n",
       "        -3.94310981e-01,  1.84855387e-01, -3.99549156e-01,\n",
       "        -2.67889678e-01, -5.45117497e-01, -3.13403830e-02,\n",
       "        -4.30644304e-01,  1.33278236e-01, -1.74793929e-01,\n",
       "        -4.35465544e-01, -4.77378905e-01,  7.12556019e-02,\n",
       "        -7.37000927e-02,  5.69136977e-01, -2.82579631e-01,\n",
       "         5.24974912e-02, -8.20008039e-01,  1.98296875e-01,\n",
       "         1.69511944e-01,  2.71780223e-01,  2.64610887e-01,\n",
       "        -2.55740248e-02, -1.74096078e-01,  1.63314238e-01,\n",
       "        -3.95261019e-01, -3.17557529e-02, -2.62556016e-01,\n",
       "         3.52754653e-01,  3.01434726e-01, -1.47197261e-01,\n",
       "         2.10075721e-01, -1.84010327e-01, -4.12896097e-01,\n",
       "         4.14775908e-01, -1.89769432e-01, -1.35482103e-01,\n",
       "        -3.79272342e-01, -4.68020253e-02, -3.33600566e-02,\n",
       "         9.00392979e-02, -3.30133080e-01, -3.87317017e-02,\n",
       "         3.75082225e-01, -1.46996513e-01,  4.34959859e-01,\n",
       "         5.38325727e-01, -2.65445322e-01,  1.64445966e-01,\n",
       "         4.17078137e-01, -4.72507551e-02, -7.48731717e-02,\n",
       "        -4.26260680e-01, -1.96994469e-01,  6.10315353e-02,\n",
       "        -4.74262595e-01, -6.48334563e-01,  3.71462375e-01,\n",
       "         2.50956744e-01,  1.22529656e-01,  8.88765603e-02,\n",
       "        -1.06724449e-01,  5.33984527e-02,  9.74504799e-02,\n",
       "        -3.46659198e-02, -1.02882944e-01,  2.32289046e-01,\n",
       "        -2.53739715e-01, -5.13112009e-01,  1.85215965e-01,\n",
       "        -3.04357857e-01, -3.55209708e-02, -1.26975283e-01,\n",
       "        -7.71633461e-02, -5.15329778e-01, -2.28072166e-01,\n",
       "         2.03343891e-02,  7.38176629e-02, -1.52558297e-01,\n",
       "        -4.00837600e-01, -2.47749388e-01,  3.97470415e-01,\n",
       "        -2.60260761e-01,  2.50905871e-01,  1.68229103e-01,\n",
       "         1.33900389e-01, -2.10832264e-02, -4.70035672e-01,\n",
       "         4.78850305e-01,  2.80345857e-01, -4.64546710e-01,\n",
       "         3.21746945e-01,  2.34207466e-01,  2.45772362e-01,\n",
       "        -4.71482247e-01,  5.00401437e-01,  4.10190284e-01,\n",
       "         5.15217066e-01,  2.62549222e-01,  2.11592801e-02,\n",
       "        -3.89687479e-01, -2.41742760e-01, -2.14834422e-01,\n",
       "        -8.62650797e-02, -1.65323481e-01, -5.21896258e-02,\n",
       "         3.41875046e-01,  4.50314254e-01, -3.06973517e-01,\n",
       "        -2.02294275e-01,  6.85521781e-01, -5.33892572e-01,\n",
       "         3.58471453e-01,  1.45286813e-01, -7.07055628e-02,\n",
       "        -1.50529206e-01, -8.56279060e-02, -7.67850205e-02,\n",
       "         1.89544708e-01, -1.04067393e-01,  5.33544004e-01,\n",
       "        -5.27887166e-01,  2.42331959e-02, -2.64348119e-01,\n",
       "        -2.23186791e-01, -3.81208628e-01,  7.59914368e-02,\n",
       "        -4.64485019e-01, -3.36549103e-01,  4.21229810e-01,\n",
       "         1.07479259e-01,  1.90457568e-01,  2.89495080e-03,\n",
       "        -1.08513527e-01,  1.53545514e-01,  3.16023558e-01,\n",
       "        -2.70837210e-02, -5.40594459e-01,  8.97289440e-02,\n",
       "        -1.15549557e-01,  3.97803813e-01, -4.97683465e-01,\n",
       "        -2.84893245e-01,  4.99861389e-02,  3.61279517e-01,\n",
       "         6.90535426e-01,  1.46821350e-01,  1.73396409e-01,\n",
       "        -1.74582213e-01, -3.15702498e-01,  6.72999024e-02,\n",
       "         2.17250124e-01,  9.78534073e-02, -1.29472524e-01,\n",
       "        -1.86929733e-01,  1.34877980e-01, -1.53885141e-01,\n",
       "         7.44716451e-02, -1.85536250e-01, -2.80628234e-01,\n",
       "        -1.14144124e-01,  4.12249714e-01,  6.39493242e-02,\n",
       "        -1.45715356e-01, -9.82063636e-02, -1.33081853e-01,\n",
       "        -1.88410729e-01, -2.84840688e-02, -3.49510685e-02,\n",
       "         3.34260389e-02,  6.98895752e-02,  1.90354556e-01,\n",
       "        -2.96724111e-01,  2.64700665e-03,  1.09140664e-01,\n",
       "         1.70893949e-02,  2.60589182e-01,  3.29038322e-01,\n",
       "        -6.61561564e-02,  2.39665493e-01, -2.26194724e-01,\n",
       "        -3.36869434e-02,  1.49400219e-01, -3.21265519e-01,\n",
       "        -2.68578082e-01,  5.72631419e-01, -4.92308617e-01,\n",
       "         2.00666517e-01, -3.49261880e-01, -2.89886966e-02,\n",
       "         6.09010518e-01, -5.72333217e-01,  2.35000581e-01,\n",
       "         6.47170283e-03, -3.14947553e-02,  2.78106760e-02,\n",
       "        -3.90340686e-01, -2.08949789e-01, -3.04452747e-01,\n",
       "        -7.20199049e-02, -8.29839855e-02,  3.73792797e-01,\n",
       "         7.38939270e-02, -2.21075043e-02,  9.88139212e-02,\n",
       "        -1.51426777e-01, -1.40430599e-01,  2.26017937e-01,\n",
       "         2.76090086e-01, -8.87750760e-02, -1.12816244e-01,\n",
       "        -2.66285956e-01,  2.77834475e-01, -4.75612208e-02,\n",
       "         6.71006441e-02, -2.78584342e-02, -2.39992719e-02,\n",
       "         2.51708895e-01,  4.68793869e-01, -5.39325416e-01,\n",
       "         1.10598333e-01, -3.44947278e-01,  4.15990025e-01,\n",
       "         7.28482902e-02, -3.19647491e-01,  4.90374297e-01,\n",
       "        -7.30326539e-03, -2.64258590e-03,  9.63711143e-01,\n",
       "         3.23884934e-01, -7.79617876e-02, -2.37589255e-01,\n",
       "         2.34038249e-01, -3.16054285e-01, -1.65644684e-03,\n",
       "        -1.09070671e+00,  3.38409394e-01,  4.70604822e-02,\n",
       "         1.07435532e-01, -2.06672445e-01,  4.26434958e-03,\n",
       "        -1.38471671e-03, -5.31455398e-01, -2.75648385e-01,\n",
       "        -1.64648548e-01, -3.42916548e-01, -4.26118731e-01,\n",
       "         6.01812005e-01,  4.55971926e-01, -2.72701979e-01,\n",
       "        -3.45803909e-02,  2.62752384e-01, -6.34182245e-03,\n",
       "         2.79631168e-01, -2.53559083e-01, -1.68626398e-01,\n",
       "         3.82935070e-02,  2.07763270e-01, -4.31525737e-01,\n",
       "        -7.24000186e-02, -1.26854718e-01,  2.07032599e-02,\n",
       "         5.74441671e-01,  3.54672760e-01,  9.28299800e-02,\n",
       "         6.70504868e-02,  1.11520380e-01, -1.86511762e-02,\n",
       "         4.62352008e-01,  2.72504658e-01, -3.60473931e-01,\n",
       "         5.29415190e-01, -1.00307481e-03, -8.81362036e-02,\n",
       "         1.49975210e-01,  5.25863320e-02,  4.63517606e-01,\n",
       "        -3.96831453e-01,  2.42640764e-01, -2.08912343e-01,\n",
       "         3.65672171e-01, -4.73377790e-04,  5.33963263e-01,\n",
       "        -1.97879702e-01,  3.11582834e-01, -6.96714938e-01,\n",
       "        -4.29500610e-01, -4.49359357e-01, -2.71370225e-02,\n",
       "        -6.98709935e-02,  2.06174642e-01, -1.57107607e-01,\n",
       "         4.43521231e-01, -6.74267113e-02, -3.00924242e-01,\n",
       "         5.14859617e-01,  3.36029500e-01,  6.63374960e-02,\n",
       "        -1.15235247e-01, -2.95980442e-02,  2.79471934e-01,\n",
       "        -3.48198377e-02, -7.29323775e-02, -4.58472818e-02,\n",
       "         1.54262766e-01,  8.09356093e-01,  5.20328283e-01,\n",
       "        -4.02114809e-01, -3.23153809e-02, -1.10363849e-01,\n",
       "         7.50504881e-02, -1.51098818e-01,  8.45739901e-01,\n",
       "        -1.80844069e-01,  3.22573632e-01,  1.04708232e-01,\n",
       "         3.19663674e-01, -1.55085340e-01,  1.69236794e-01,\n",
       "        -2.56996810e-01,  2.01208934e-01,  1.77392989e-01,\n",
       "        -2.74333209e-01, -3.36944401e-01,  5.02356768e-01,\n",
       "        -1.18357144e-01, -2.01166883e-01, -5.36485732e-01,\n",
       "        -7.69810155e-02,  1.15381051e-02, -2.36464351e-01,\n",
       "        -2.98769865e-02,  1.31366819e-01,  2.94184357e-01,\n",
       "         9.90916416e-02, -5.43897390e-01,  1.40812859e-01,\n",
       "         3.66998732e-01,  5.04862480e-02,  1.99122518e-01,\n",
       "        -2.80674607e-01,  4.34192210e-01, -1.40274912e-01,\n",
       "         5.78049004e-01,  1.77715704e-01,  8.98363292e-02,\n",
       "         3.29651982e-01,  6.13008998e-02, -3.24933499e-01]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8938317-e31e-4e8d-b2d8-f92c1b5a300c",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbda3e66-005a-4ad0-8017-c1cc7cbf0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836e5f84-12c6-4c95-838e-53de7e46a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36703d23-37a3-40df-b09a-c68206d285b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:==============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happened\" next. We will never know for sure what happened because ...|\n",
      "|Hard up, No proper jobs going down at the pit, why not rent your kids! DIY pimp story without the gratuitous sex scen...|\n",
      "|I watched this movie to see the direction one of the most promising young talents in movies was going. Unfortunately,...|\n",
      "|This movie makes you wish imdb would let you vote a zero. One of the two movies I've ever walked out of. It's very ha...|\n",
      "|I never want to see this movie again!<br /><br />Not only is it dreadfully bad, but I can't stand seeing my hero Stan...|\n",
      "|(As a note, I'd like to say that I saw this movie at my annual church camp, where the entire youth group laughed at i...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gentlemen. It was funny, twisted and completely inspired. I was...|\n",
      "|Did you ever think, like after watching a horror movie with a group of friends: \"Wow, this is so cool! We have got to...|\n",
      "|Awful, awful, awful...<br /><br />I loved the original film. It was funny, charming, and had heart... this piece of j...|\n",
      "|This movie seems a little clunky around the edges, like not quite enough zaniness was thrown it when it should have b...|\n",
      "|I rented this movie hoping that it would provide some good entertainment and some cool poker knowledge or stories. Wh...|\n",
      "|Well, where to start describing this celluloid debacle? You already know the big fat NADA passing as a plot, so let's...|\n",
      "|I hoped for this show to be somewhat realistic. It stroke me as just another mainstream show after I watched it. I di...|\n",
      "|All I have to say is one word...SUCKS!!!!. The only reason I gave this a 2 is because Josh Hartnett was in it and he'...|\n",
      "|Honestly awful film, bad editing, awful lighting, dire dialog and scrappy screenplay.<br /><br />The lighting at is s...|\n",
      "|This critique tells the story of 4 little friends who went to watch Angels and Demons the movie on the first night it...|\n",
      "|This review contains a partial spoiler.<br /><br />Shallow from the outset, 'D.O.A.' at least starts as if it might b...|\n",
      "|I'm rather surprised that anybody found this film touching or moving.<br /><br />The basic premise of the film sounde...|\n",
      "|If you like bad movies (and you must to watch this one) here's a good one. Not quite as funny as the first, but much ...|\n",
      "|This is really bad, the characters were bland, the story was boring, and there is no sex scene. Furthermore, it lacks...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f780c026-0f3f-4aea-8b61-5b3dbae83fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "    def predict(inputs):\n",
    "        return model.encode(inputs.tolist())\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c88ddc-ca19-4430-8b0e-b9fae143b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = predict_batch_udf(predict_batch_fn,\n",
    "                           return_type=ArrayType(FloatType()),\n",
    "                           batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85344c22-4a4d-4cb0-8771-5836ae2794db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 ms, sys: 9.35 ms, total: 27.2 ms\n",
      "Wall time: 8.36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23bb885-6ab0-4471-943d-4c10414100fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 ms, sys: 1.13 ms, total: 18.8 ms\n",
      "Wall time: 3.25 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(\"lines\"))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93bc6da3-d853-4233-b805-cb4a46f4f9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.9 ms, sys: 0 ns, total: 16.9 ms\n",
      "Wall time: 2.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2073616f-7151-4760-92f2-441dd0bfe9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       lines|                                                    encoding|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happen...|[0.050629966, -0.19899231, 2.686046E-4, 0.13270327, -0.16...|\n",
      "|Hard up, No proper jobs going down at the pit, why not re...|[0.08634103, -0.002254839, 0.10213216, -0.03454912, -0.23...|\n",
      "|I watched this movie to see the direction one of the most...|[0.008758117, -0.0083419345, -0.119090386, 0.025434377, -...|\n",
      "|This movie makes you wish imdb would let you vote a zero....|[0.24080081, -0.14614257, 0.18119521, 0.118741795, 0.1022...|\n",
      "|I never want to see this movie again!<br /><br />Not only...|[0.32271573, -0.14145091, 0.09245593, 0.04562203, 0.07219...|\n",
      "|(As a note, I'd like to say that I saw this movie at my a...|[0.1308969, 0.14792246, -0.021109976, -0.16882573, -0.055...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gen...|[-0.19420472, 0.116419405, 0.01985946, -0.37481546, 0.052...|\n",
      "|Did you ever think, like after watching a horror movie wi...|[0.050077364, -0.34728476, -0.47222477, 0.09191189, -0.16...|\n",
      "|Awful, awful, awful...<br /><br />I loved the original fi...|[-0.23921771, -0.22389278, -0.0042956644, 0.058358684, 0....|\n",
      "|This movie seems a little clunky around the edges, like n...|[-0.12948105, -0.16344212, -0.28761974, -0.10628598, -0.0...|\n",
      "|I rented this movie hoping that it would provide some goo...|[-0.030982, -0.13821997, 0.14594209, -0.20565805, -0.0225...|\n",
      "|Well, where to start describing this celluloid debacle? Y...|[-0.29094818, 0.026240889, -0.21248402, 0.028826537, -0.1...|\n",
      "|I hoped for this show to be somewhat realistic. It stroke...|[0.14481407, -0.13123356, -0.47293735, -0.21168816, 0.001...|\n",
      "|All I have to say is one word...SUCKS!!!!. The only reaso...|[0.018178312, 0.11847291, -0.33938172, -0.15572134, 0.051...|\n",
      "|Honestly awful film, bad editing, awful lighting, dire di...|[-0.10033801, -0.28231186, 0.18979141, 0.042497832, 0.125...|\n",
      "|This critique tells the story of 4 little friends who wen...|[0.1318425, -0.1671868, -0.013854267, 0.14505053, -0.2534...|\n",
      "|This review contains a partial spoiler.<br /><br />Shallo...|[-0.08296674, -0.08548329, -0.13219479, -0.20946309, 0.01...|\n",
      "|I'm rather surprised that anybody found this film touchin...|[-0.21176083, -0.12755248, -0.28217235, 0.02004116, 0.074...|\n",
      "|If you like bad movies (and you must to watch this one) h...|[-0.38088003, -0.1916466, 0.16510564, -0.11013024, -0.233...|\n",
      "|This is really bad, the characters were bland, the story ...|[0.09919267, 0.042636175, -0.17805319, -0.1818586, -0.123...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b730f5a3-f7eb-42aa-8869-881ecd0f5542",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8211920-234e-480f-bf87-6d719090e292",
   "metadata": {},
   "source": [
    "This notebook uses the [Python backend with a custom execution environment](https://github.com/triton-inference-server/python_backend#creating-custom-execution-environments), using a conda-pack environment created as follows:\n",
    "```\n",
    "conda create -n huggingface -c conda-forge python=3.8\n",
    "conda activate huggingface\n",
    "\n",
    "export PYTHONUSERSITE=True\n",
    "pip install conda-pack sentencepiece sentence_transformers transformers\n",
    "\n",
    "conda-pack  # huggingface.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772e337e-1098-4c7b-ba81-8cb221a518e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d0c93a-bb0b-46c5-9d28-7b08a2e70964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# copy custom model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models\n",
    "cp -r models_config/hf_transformer models\n",
    "\n",
    "# add custom execution environment\n",
    "cp huggingface.tar.gz models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d7d4b-1a0b-4c5f-bc93-be2a039b6ea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1654cdc1-4f9a-4fd5-b7ac-6ca4215bde5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "huggingface_cache_dir = \"{}/.cache/huggingface\".format(os.path.expanduser('~'))\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:23.04-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={\n",
    "                triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                huggingface_cache_dir: {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34de5f-89f8-455e-b45e-a557a4ab0f05",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2969d502-e97b-49d6-bf80-7d177ae867cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8f1e6d6-6519-49e7-8465-4419547633b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/19 19:15:37 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29b0cc0d-c480-4e4a-bd41-207dc314cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c712b8f-6eb4-4fb8-9f0a-04feef847fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"hf_transformer\"),\n",
    "                           return_type=ArrayType(FloatType()),\n",
    "                           input_tensor_shapes=[[1]],\n",
    "                           batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "934c1a1f-b126-45b0-9c15-265236820ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 ms, sys: 3.95 ms, total: 23.6 ms\n",
      "Wall time: 2.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "embeddings = df.withColumn(\"encoding\", encode(struct(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f84cd3f6-b6a8-4142-859a-91f3c183457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.66 ms, sys: 3.04 ms, total: 10.7 ms\n",
      "Wall time: 265 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(\"lines\"))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "921a4c01-e296-4406-be90-86f20c8c582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 ms, sys: 570 Âµs, total: 13.2 ms\n",
      "Wall time: 261 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = df.withColumn(\"encoding\", encode(col(\"lines\")))\n",
    "results = embeddings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f67584e-9c4e-474f-b6ea-7811b14d116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       lines|                                                    encoding|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|...But not this one! I always wanted to know \"what happen...|[0.050629944, -0.19899224, 2.68735E-4, 0.13270333, -0.160...|\n",
      "|Hard up, No proper jobs going down at the pit, why not re...|[0.08634147, -0.002254737, 0.10213226, -0.034549147, -0.2...|\n",
      "|I watched this movie to see the direction one of the most...|[0.008757966, -0.008341991, -0.11909033, 0.02543464, -0.2...|\n",
      "|This movie makes you wish imdb would let you vote a zero....|[0.24080098, -0.14614293, 0.1811954, 0.11874188, 0.102292...|\n",
      "|I never want to see this movie again!<br /><br />Not only...|[0.3227157, -0.14145078, 0.0924558, 0.045622032, 0.072197...|\n",
      "|(As a note, I'd like to say that I saw this movie at my a...|[0.13089702, 0.1479226, -0.021110116, -0.16882578, -0.055...|\n",
      "|Don't get me wrong, I love the TV series of League Of Gen...|[-0.19420475, 0.11641937, 0.019859463, -0.37481567, 0.052...|\n",
      "|Did you ever think, like after watching a horror movie wi...|[0.050077528, -0.34728497, -0.4722248, 0.091912046, -0.16...|\n",
      "|Awful, awful, awful...<br /><br />I loved the original fi...|[-0.2392176, -0.22389287, -0.004295718, 0.05835876, 0.082...|\n",
      "|This movie seems a little clunky around the edges, like n...|[-0.12948103, -0.16344213, -0.2876199, -0.106286034, -0.0...|\n",
      "|I rented this movie hoping that it would provide some goo...|[-0.03098194, -0.13821997, 0.1459418, -0.20565815, -0.022...|\n",
      "|Well, where to start describing this celluloid debacle? Y...|[-0.29094803, 0.026240645, -0.21248397, 0.028826557, -0.1...|\n",
      "|I hoped for this show to be somewhat realistic. It stroke...|[0.14481404, -0.13123384, -0.47293738, -0.21168788, 0.001...|\n",
      "|All I have to say is one word...SUCKS!!!!. The only reaso...|[0.018178271, 0.11847262, -0.3393819, -0.15572123, 0.0515...|\n",
      "|Honestly awful film, bad editing, awful lighting, dire di...|[-0.10033788, -0.28231215, 0.18979158, 0.042498272, 0.125...|\n",
      "|This critique tells the story of 4 little friends who wen...|[0.13184246, -0.16718695, -0.013854082, 0.14505032, -0.25...|\n",
      "|This review contains a partial spoiler.<br /><br />Shallo...|[-0.08296674, -0.08548302, -0.1321949, -0.20946284, 0.010...|\n",
      "|I'm rather surprised that anybody found this film touchin...|[-0.21176091, -0.1275524, -0.28217238, 0.020041106, 0.074...|\n",
      "|If you like bad movies (and you must to watch this one) h...|[-0.38088012, -0.19164667, 0.16510546, -0.11012972, -0.23...|\n",
      "|This is really bad, the characters were bland, the story ...|[0.099192545, 0.04263605, -0.17805345, -0.18185869, -0.12...|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0077c-785f-41af-9fa9-812e7fb63810",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e5466b-b5dc-4fe1-9012-0c87cdd72962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e82b9518-da7b-4ebc-8990-c8ab909bec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a60f2d-295a-4270-a2fd-16559962edda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
