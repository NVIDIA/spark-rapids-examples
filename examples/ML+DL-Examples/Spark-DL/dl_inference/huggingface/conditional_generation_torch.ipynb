{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777fc40d",
   "metadata": {},
   "source": [
    "# PySpark Huggingface Inferencing\n",
    "## Conditional generation with PyTorch\n",
    "\n",
    "From: https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0eed0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "task_prefix = \"translate English to German: \"\n",
    "\n",
    "lines = [\n",
    "    \"The house is wonderful\",\n",
    "    \"Welcome to NYC\",\n",
    "    \"HuggingFace is a company\"\n",
    "]\n",
    "\n",
    "input_sequences = [task_prefix + l for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73655aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_sequences, \n",
    "                      padding=\"longest\", \n",
    "                      max_length=max_source_length,\n",
    "                      truncation=True,\n",
    "                      return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e54262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Das Haus ist wunderbar',\n",
       " 'Willkommen in NYC',\n",
       " 'HuggingFace ist ein Unternehmen']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(o, skip_special_tokens=True) for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b11c89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eabe0",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6db1f0-7d68-4af7-8bd6-c9fa45906c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68121304-f1df-466e-9347-c9d2b36a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6279a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 16:39:14 WARN Utils: Your hostname, dgx2h0194.spark.sjc4.nvmetal.net resolves to a loopback address: 127.0.1.1; using 10.150.30.2 instead (on interface enp134s0f0np0)\n",
      "24/09/25 16:39:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 16:39:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "num_threads = 6\n",
    "\n",
    "# Creating a local Spark session for demonstration, in case it hasn't already been created.\n",
    "\n",
    "_config = {\n",
    "    \"spark.master\": f\"local[{num_threads}]\",\n",
    "    \"spark.driver.host\": \"127.0.0.1\",\n",
    "    \"spark.task.maxFailures\": \"1\",\n",
    "    \"spark.driver.memory\": \"8g\",\n",
    "    \"spark.executor.memory\": \"8g\",\n",
    "    \"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\": \"false\",\n",
    "    \"spark.sql.pyspark.jvmStacktrace.enabled\": \"true\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "    \"spark.python.worker.reuse\": \"true\",\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"spark-dl-example\")\n",
    "for key, value in _config.items():\n",
    "    spark = spark.config(key, value)\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8453111-d068-49bb-ab91-8ae3d8bcdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IMDB reviews (test) dataset\n",
    "data = load_dataset(\"imdb\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ad01d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "for example in data:\n",
    "    lines.append([example[\"text\"].split(\".\")[0]])\n",
    "\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5b472-47e8-4804-9907-772793fedb2b",
   "metadata": {},
   "source": [
    "### Create PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d24d9404-0269-476e-a9dd-1842667c915a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('lines', StringType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(lines, ['lines']).repartition(10)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4384c762-1f79-4f60-876c-94b1f552e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(lines=\"i do not understand at all why this movie received such good grades from critics - - i've seen tens of documentaries (on TV) about the wine world which were much much better when (if) you watch it, please think of two very annoying aspects of mondovino : first, the filming is just awful and terrible and upsetting : to me, it looked like the guy behind the camera just received the material and was playing with it : plenty of zooms (for no purpose other than pushing the button in/out) for instance - - i almost stopped to watch it because of that ! secondly, the interviewer (the director i think) is not really relevant : he looks like and ask questions like a boy scout, not like a journalist, even if the general idea and themes would have been interesting, too bad conclusion: overrated documentary, maybe only for guys who do not know nothing about wine => not recommended at all (2/10)\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba3513-82dd-47e7-8193-eb4389458757",
   "metadata": {},
   "source": [
    "### Save the test dataset as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7eec8ec-4126-4890-b957-025809fad67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"imdb_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e1fc8-42a3-47dd-b3c0-47efd5be1040",
   "metadata": {},
   "source": [
    "### Check arrow memory configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20554ea5-01be-4a30-8607-db5d87786fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"512\")\n",
    "# This line will fail if the vectorized reader runs out of memory\n",
    "assert len(df.head()) > 0, \"`df` should not be empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4ecab-c9d9-466f-ba49-902ad1fd5488",
   "metadata": {},
   "source": [
    "## Inference using Spark DL API (PyTorch)\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a00479-1347-4de8-8431-faa77f8cdf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, pandas_udf, struct\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a0889a-35b4-493a-8197-1146fc7efd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c483e4d4-9ab1-416f-a766-694e17490fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   lines|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story that is completely ununderst...|\n",
      "|                                                        Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                                                 I tried|\n",
      "|                                             This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|After I saw this I concluded that it was most likely a chick flick; afterward I found out that Keira's mother wrote t...|\n",
      "|Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-actors (lower than Don \"The Drag...|\n",
      "|I haven't seen this movie in years, the last time i did i was really drunk after 5 pints of tenant's at my local With...|\n",
      "|                                                                                Now don't get me wrong I love bad movies|\n",
      "|There I am sitting at home in the morning, suddenly my brother flips on what appears to be the stupidest looking movi...|\n",
      "|Yes, it was an awful movie, but there was a song near the beginning of the movie, I think, called \"I got a Woody\" or ...|\n",
      "|                                                        This was the most uninteresting horror flick I have seen to date|\n",
      "|Another in the long line of Conan wannabes that tired to cash in on that movie's success, this Italian monstrosity is...|\n",
      "|Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cranked-up Cuckoo theme (with er...|\n",
      "|Julie Andrews satirically prods her own goody-two-shoes image in this overproduced musical comedy-drama, but if she a...|\n",
      "|                                                                                            'Leatherheads' tries so hard|\n",
      "|                                   If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery Combs given the lead? Henrik...|\n",
      "|                                                                                                   Woa, talk about awful|\n",
      "|                                                                                      The guy mentioned to sue for the 1|\n",
      "|                                                                                           (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100)\n",
    "df.show(truncate=120)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "831bc52c-a5c6-4c29-a6da-0566b5167773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46dac59c-5a54-4576-91e0-279c8b375b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fef1d846-5852-4762-8527-602f32c0d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to German: A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story...|\n",
      "|                           Translate English to German: Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                    Translate English to German: I tried|\n",
      "|                Translate English to German: This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|Translate English to German: After I saw this I concluded that it was most likely a chick flick; afterward I found ou...|\n",
      "|Translate English to German: Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-act...|\n",
      "|Translate English to German: I haven't seen this movie in years, the last time i did i was really drunk after 5 pints...|\n",
      "|                                                   Translate English to German: Now don't get me wrong I love bad movies|\n",
      "|Translate English to German: There I am sitting at home in the morning, suddenly my brother flips on what appears to ...|\n",
      "|Translate English to German: Yes, it was an awful movie, but there was a song near the beginning of the movie, I thin...|\n",
      "|                           Translate English to German: This was the most uninteresting horror flick I have seen to date|\n",
      "|Translate English to German: Another in the long line of Conan wannabes that tired to cash in on that movie's success...|\n",
      "|Translate English to German: Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cra...|\n",
      "|Translate English to German: Julie Andrews satirically prods her own goody-two-shoes image in this overproduced music...|\n",
      "|                                                               Translate English to German: 'Leatherheads' tries so hard|\n",
      "|      Translate English to German: If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|Translate English to German: With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery...|\n",
      "|                                                                      Translate English to German: Woa, talk about awful|\n",
      "|                                                         Translate English to German: The guy mentioned to sue for the 1|\n",
      "|                                                              Translate English to German: (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7ae69d3-70c2-4765-928f-c96a7ba59829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import numpy as np\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "    def predict(inputs):\n",
    "        flattened = np.squeeze(inputs).tolist()   # convert 2d numpy array of string into flattened python list\n",
    "        input_ids = tokenizer(flattened, \n",
    "                              padding=\"longest\", \n",
    "                              max_length=128,\n",
    "                              return_tensors=\"pt\").input_ids\n",
    "        output_ids = model.generate(input_ids)\n",
    "        string_outputs = np.array([tokenizer.decode(o, skip_special_tokens=True) for o in output_ids])\n",
    "        print(\"predict: {}\".format(len(flattened)))\n",
    "        return string_outputs\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36684f59-d947-43f8-a2e8-c7a423764e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=StringType(),\n",
    "                             batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a01c855-8fa1-4765-a3a5-2c9dd872df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 ms, sys: 0 ns, total: 19.1 ms\n",
      "Wall time: 22.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d912d4b0-cd0b-44ea-859a-b23455cc2700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.77 ms, sys: 8.69 ms, total: 16.5 ms\n",
      "Wall time: 18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fe3d88b-30f7-468f-8db8-1f4118d0f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 ms, sys: 2.94 ms, total: 13.8 ms\n",
      "Wall time: 17.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ad9b365-4b9a-438e-8fdf-47da55cb1cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to German: A ridiculous movie, a terrib...|Ein lächerlicher Film, eine schreckliche Bearbeitung, sch...|\n",
      "|Translate English to German: Most of this film was okay, ...|Der größte Teil dieses Films war okay, für eine Fortsetzu...|\n",
      "|                        Translate English to German: I tried|                   Ich habe versucht, Englisch zu übersetzen|\n",
      "|Translate English to German: This movie attempted to make...|Dieser Film versuchte, das Leben von Stu Ungar interessan...|\n",
      "|Translate English to German: After I saw this I concluded...|Nach meiner Anzeige kam ich zu dem Schluss, dass es höchs...|\n",
      "|Translate English to German: Jeff Speakman never really m...|Jeff Speakman hat es nie wirklich über die niedrigsten Kl...|\n",
      "|Translate English to German: I haven't seen this movie in...|Ich habe diesen Film nicht in Jahren gesehen, das letzte ...|\n",
      "|Translate English to German: Now don't get me wrong I lov...|  Jetzt mache ich mir nicht recht, ich liebe schlechte Filme|\n",
      "|Translate English to German: There I am sitting at home i...|   Dort sitze ich morgens zu Hause, plötzlich dreht mein Bru|\n",
      "|Translate English to German: Yes, it was an awful movie, ...|              Ja, es war ein schrecklicher Film, aber es gab|\n",
      "|Translate English to German: This was the most uninterest...|Dies war der größte Horrorfilm, den ich bisher gesehen habe.|\n",
      "|Translate English to German: Another in the long line of ...|      Ein weiterer in der langen Linie von Conan-Wünstlingen|\n",
      "|Translate English to German: Oh, why did it have to end l...|        Laurel und Hardy's letzter Film, von dem grotesken C|\n",
      "|Translate English to German: Julie Andrews satirically pr...|  Julie Andrews sah in diesem überproduzierten musikalischen|\n",
      "|   Translate English to German: 'Leatherheads' tries so hard|                                'Leatherheads' tries so hard|\n",
      "|Translate English to German: If I wouldn't have had any e...|Wenn ich keine Erwartungen an diesen Film hätte, hätte er...|\n",
      "|Translate English to German: With several name actors (La...|        Warum hat Jeffery Combs mit mehreren Namenssachen (L|\n",
      "|          Translate English to German: Woa, talk about awful|                         Woa, sprechen Sie über schreckliche|\n",
      "|Translate English to German: The guy mentioned to sue for...|                    Der Name hat es gesagt, daß er für die 1|\n",
      "|  Translate English to German: (Warning: Some spoilers ahead|              (Warning: Einige Vorschläge für die Übersetzer|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 121\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eb0c83b-d91b-4f8c-a5e7-c35f55c88108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "054f94fd-fe79-41e7-b1c7-6124083acc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to French: A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story...|\n",
      "|                           Translate English to French: Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                    Translate English to French: I tried|\n",
      "|                Translate English to French: This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|Translate English to French: After I saw this I concluded that it was most likely a chick flick; afterward I found ou...|\n",
      "|Translate English to French: Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-act...|\n",
      "|Translate English to French: I haven't seen this movie in years, the last time i did i was really drunk after 5 pints...|\n",
      "|                                                   Translate English to French: Now don't get me wrong I love bad movies|\n",
      "|Translate English to French: There I am sitting at home in the morning, suddenly my brother flips on what appears to ...|\n",
      "|Translate English to French: Yes, it was an awful movie, but there was a song near the beginning of the movie, I thin...|\n",
      "|                           Translate English to French: This was the most uninteresting horror flick I have seen to date|\n",
      "|Translate English to French: Another in the long line of Conan wannabes that tired to cash in on that movie's success...|\n",
      "|Translate English to French: Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cra...|\n",
      "|Translate English to French: Julie Andrews satirically prods her own goody-two-shoes image in this overproduced music...|\n",
      "|                                                               Translate English to French: 'Leatherheads' tries so hard|\n",
      "|      Translate English to French: If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|Translate English to French: With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery...|\n",
      "|                                                                      Translate English to French: Woa, talk about awful|\n",
      "|                                                         Translate English to French: The guy mentioned to sue for the 1|\n",
      "|                                                              Translate English to French: (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f6b70f9-188a-402b-9143-78a5788140e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/rishic/anaconda3/envs/spark-dl-torch/lib/python3.11/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 ms, sys: 775 μs, total: 17.1 ms\n",
      "Wall time: 22.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "031a6a5e-7999-4653-b394-19ed478d8c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 ms, sys: 1.09 ms, total: 14.4 ms\n",
      "Wall time: 18.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(\"input\"))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "229b6515-82f6-4e9c-90f0-a9c3cfb26301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 ms, sys: 0 ns, total: 15.8 ms\n",
      "Wall time: 18.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "result = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8be750ac-fa39-452e-bb4c-c2270bc2f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 10                                                         (0 + 1) / 1]\n",
      "predict: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to French: A ridiculous movie, a terrib...|Un film ridicule, un terrible travail de rédaction, le pi...|\n",
      "|Translate English to French: Most of this film was okay, ...|La plupart de ce film était en bonne et due forme, pour u...|\n",
      "|                        Translate English to French: I tried|                                                 J'ai essayé|\n",
      "|Translate English to French: This movie attempted to make...|Ce film tentait de rendre la vie de Stu Ungar intéressant...|\n",
      "|Translate English to French: After I saw this I concluded...|Après avoir vu ce film, j'ai conclu qu'il était très prob...|\n",
      "|Translate English to French: Jeff Speakman never really m...|Jeff Speakman n'a jamais vraiment franchi les rangs les p...|\n",
      "|Translate English to French: I haven't seen this movie in...|Je n'ai pas vu ce film depuis des années, la dernière foi...|\n",
      "|Translate English to French: Now don't get me wrong I lov...|     Maintenant, ne pas me grecher Je aime les mauvais films|\n",
      "|Translate English to French: There I am sitting at home i...|       l'intérieur, je me trouve à la maison le matin, sous-|\n",
      "|Translate English to French: Yes, it was an awful movie, ...|  Oui, c'était un film terrible, mais il y avait une chanson|\n",
      "|Translate English to French: This was the most uninterest...|         Ce fut le plus inquiétant et le plus inquiétant d'h|\n",
      "|Translate English to French: Another in the long line of ...|   Une autre en longue ligne de conan qui a eu la fatigue de|\n",
      "|Translate English to French: Oh, why did it have to end l...|            Laurel et Hardy s'en sont rendus dans le dernier|\n",
      "|Translate English to French: Julie Andrews satirically pr...|Julie Andrews s'enrôle satiriquement dans cette comédie m...|\n",
      "|   Translate English to French: 'Leatherheads' tries so hard|                                'Leatherheads' essaie si dur|\n",
      "|Translate English to French: If I wouldn't have had any e...|                       Si je n'aurais pas eu d'attentes à ce|\n",
      "|Translate English to French: With several name actors (La...|Avec plusieurs acteurs de nom (Lance Henrikson, David War...|\n",
      "|          Translate English to French: Woa, talk about awful|                                                            |\n",
      "|Translate English to French: The guy mentioned to sue for...|Le châssis mentionné pour intenter une action en justice ...|\n",
      "|  Translate English to French: (Warning: Some spoilers ahead|               (Avertissement : Quelques spoilers à l'avenir|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 121\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabb2a8-3880-46ec-8e01-5a10f71fe83d",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98fa52-7665-49bf-865a-feec86effe23",
   "metadata": {},
   "source": [
    "This notebook uses the [Python backend with a custom execution environment](https://github.com/triton-inference-server/python_backend#creating-custom-execution-environments) with the compatible versions of Python/Numpy for Triton 24.08, using a conda-pack environment created as follows:\n",
    "```\n",
    "conda create -n huggingface -c conda-forge python=3.10.0\n",
    "conda activate huggingface\n",
    "\n",
    "export PYTHONNOUSERSITE=True\n",
    "pip install numpy<2 conda-pack sentencepiece sentence_transformers transformers\n",
    "\n",
    "conda-pack  # huggingface.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b858cf85-82e6-41ef-905b-d8c5d6fea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05ce7c77-d562-45e8-89bb-cd656aba5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy custom model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models\n",
    "cp -r models_config/hf_generation models\n",
    "\n",
    "# add custom execution environment\n",
    "cp huggingface.tar.gz models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552865c-5dad-4f25-8834-f41e253ac2f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afd00b7e-8150-4c95-a2e4-037e9c90f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> starting triton: eeba2c4778b2                                  (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "huggingface_cache_dir = \"{}/.cache/huggingface\".format(os.path.expanduser('~'))\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            environment=[\n",
    "                \"TRANSFORMERS_CACHE=/cache\"\n",
    "            ],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"1G\",\n",
    "            volumes={\n",
    "                triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"},\n",
    "                huggingface_cache_dir: {\"bind\": \"/cache\", \"mode\": \"rw\"}\n",
    "            }\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d2df6-49fc-4be7-a534-a087dfe31c84",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a997c33-5202-466d-8304-b8c30f32978f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, pandas_udf, struct\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dea1875-6b95-4fc0-926d-a625a441b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first N examples, since this is slow\n",
    "df = spark.read.parquet(\"imdb_test\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d6c54e7-534d-406f-b8e6-fd592efd0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first sentence and add prefix for conditional generation\n",
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc1bbbe3-4232-49e5-80f6-99976524b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df1 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to German: \")).select(\"input\").limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d10c61c-6102-4d19-8dd6-0c7b5b65343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to German: A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story...|\n",
      "|                           Translate English to German: Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                    Translate English to German: I tried|\n",
      "|                Translate English to German: This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|Translate English to German: After I saw this I concluded that it was most likely a chick flick; afterward I found ou...|\n",
      "|Translate English to German: Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-act...|\n",
      "|Translate English to German: I haven't seen this movie in years, the last time i did i was really drunk after 5 pints...|\n",
      "|                                                   Translate English to German: Now don't get me wrong I love bad movies|\n",
      "|Translate English to German: There I am sitting at home in the morning, suddenly my brother flips on what appears to ...|\n",
      "|Translate English to German: Yes, it was an awful movie, but there was a song near the beginning of the movie, I thin...|\n",
      "|                           Translate English to German: This was the most uninteresting horror flick I have seen to date|\n",
      "|Translate English to German: Another in the long line of Conan wannabes that tired to cash in on that movie's success...|\n",
      "|Translate English to German: Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cra...|\n",
      "|Translate English to German: Julie Andrews satirically prods her own goody-two-shoes image in this overproduced music...|\n",
      "|                                                               Translate English to German: 'Leatherheads' tries so hard|\n",
      "|      Translate English to German: If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|Translate English to German: With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery...|\n",
      "|                                                                      Translate English to German: Woa, talk about awful|\n",
      "|                                                         Translate English to German: The guy mentioned to sue for the 1|\n",
      "|                                                              Translate English to German: (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e0907da-a5d9-4c3b-9db4-ce5e70ca9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool8),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9308bdd7-6f67-484d-8b51-dd1e1b2960ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"hf_generation\"),\n",
    "                             return_type=StringType(),\n",
    "                             input_tensor_shapes=[[1]],\n",
    "                             batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38484ffd-370d-492b-8ca4-9eff9f242a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1937910/3110230631.py:6: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.46 ms, sys: 1.34 ms, total: 8.8 ms\n",
      "Wall time: 8.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = df1.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebcb6699-3ac2-4529-ab0f-fab0a5e792da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 ms, sys: 0 ns, total: 6.27 ms\n",
      "Wall time: 7.82 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2ed18ad-d00b-472c-b2c3-047932f2105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.28 ms, sys: 0 ns, total: 6.28 ms\n",
      "Wall time: 8.01 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df1.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cd64a1c-beb8-47d5-ac6f-e8525bb61176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to German: A ridiculous movie, a terrib...|Ein lächerlicher Film, eine schreckliche Bearbeitung, sch...|\n",
      "|Translate English to German: Most of this film was okay, ...|Der größte Teil dieses Films war okay, für eine Fortsetzu...|\n",
      "|                        Translate English to German: I tried|                   Ich habe versucht, Englisch zu übersetzen|\n",
      "|Translate English to German: This movie attempted to make...|Dieser Film versuchte, das Leben von Stu Ungar interessan...|\n",
      "|Translate English to German: After I saw this I concluded...|Nach meiner Anzeige kam ich zu dem Schluss, dass es höchs...|\n",
      "|Translate English to German: Jeff Speakman never really m...|Jeff Speakman hat es nie wirklich über die niedrigsten Kl...|\n",
      "|Translate English to German: I haven't seen this movie in...|Ich habe diesen Film nicht in Jahren gesehen, das letzte ...|\n",
      "|Translate English to German: Now don't get me wrong I lov...|  Jetzt mache ich mir nicht recht, ich liebe schlechte Filme|\n",
      "|Translate English to German: There I am sitting at home i...|   Dort sitze ich morgens zu Hause, plötzlich dreht mein Bru|\n",
      "|Translate English to German: Yes, it was an awful movie, ...|              Ja, es war ein schrecklicher Film, aber es gab|\n",
      "|Translate English to German: This was the most uninterest...|Dies war der größte Horrorfilm, den ich bisher gesehen habe.|\n",
      "|Translate English to German: Another in the long line of ...|      Ein weiterer in der langen Linie von Conan-Wünstlingen|\n",
      "|Translate English to German: Oh, why did it have to end l...|        Laurel und Hardy's letzter Film, von dem grotesken C|\n",
      "|Translate English to German: Julie Andrews satirically pr...|  Julie Andrews sah in diesem überproduzierten musikalischen|\n",
      "|   Translate English to German: 'Leatherheads' tries so hard|                                'Leatherheads' tries so hard|\n",
      "|Translate English to German: If I wouldn't have had any e...|Wenn ich keine Erwartungen an diesen Film hätte, hätte er...|\n",
      "|Translate English to German: With several name actors (La...|        Warum hat Jeffery Combs mit mehreren Namenssachen (L|\n",
      "|          Translate English to German: Woa, talk about awful|                         Woa, sprechen Sie über schreckliche|\n",
      "|Translate English to German: The guy mentioned to sue for...|                    Der Name hat es gesagt, daß er für die 1|\n",
      "|  Translate English to German: (Warning: Some spoilers ahead|              (Warning: Einige Vorschläge für die Übersetzer|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af70fed8-0f2b-4ea7-841c-476afdf9b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 16:44:23 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# only use first 100 rows, since generation takes a while\n",
    "df2 = df.withColumn(\"input\", preprocess(col(\"lines\"), \"Translate English to French: \")).select(\"input\").limit(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef075e10-e22c-4236-9e0b-cb47cf2d3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                   input|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|Translate English to French: A ridiculous movie, a terrible editing job, worst screenplay, ridiculous acting, a story...|\n",
      "|                           Translate English to French: Most of this film was okay, for a sequel of a sequel of a sequel|\n",
      "|                                                                                    Translate English to French: I tried|\n",
      "|                Translate English to French: This movie attempted to make Stu Ungar's life interesting by being creative|\n",
      "|Translate English to French: After I saw this I concluded that it was most likely a chick flick; afterward I found ou...|\n",
      "|Translate English to French: Jeff Speakman never really made it beyond the lowest ranks of martial-artists-turned-act...|\n",
      "|Translate English to French: I haven't seen this movie in years, the last time i did i was really drunk after 5 pints...|\n",
      "|                                                   Translate English to French: Now don't get me wrong I love bad movies|\n",
      "|Translate English to French: There I am sitting at home in the morning, suddenly my brother flips on what appears to ...|\n",
      "|Translate English to French: Yes, it was an awful movie, but there was a song near the beginning of the movie, I thin...|\n",
      "|                           Translate English to French: This was the most uninteresting horror flick I have seen to date|\n",
      "|Translate English to French: Another in the long line of Conan wannabes that tired to cash in on that movie's success...|\n",
      "|Translate English to French: Oh, why did it have to end like this? Laurel and Hardy's last film, from the crudely cra...|\n",
      "|Translate English to French: Julie Andrews satirically prods her own goody-two-shoes image in this overproduced music...|\n",
      "|                                                               Translate English to French: 'Leatherheads' tries so hard|\n",
      "|      Translate English to French: If I wouldn't have had any expectations of this film, it might have received a 5 or 6|\n",
      "|Translate English to French: With several name actors (Lance Henrikson, David Warner, Joe Don Baker), why was Jeffery...|\n",
      "|                                                                      Translate English to French: Woa, talk about awful|\n",
      "|                                                         Translate English to French: The guy mentioned to sue for the 1|\n",
      "|                                                              Translate English to French: (Warning: Some spoilers ahead|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e7e4af8-b815-4375-b851-8368309ee8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1937910/3110230631.py:6: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.26 ms, sys: 582 μs, total: 7.84 ms\n",
      "Wall time: 7.58 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b0aefb0-a96b-4791-a23c-1ce9b24eb20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 ms, sys: 5.48 ms, total: 7.3 ms\n",
      "Wall time: 6.82 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1214b75b-a373-4579-b4c6-0cb8627da776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.6 ms, sys: 162 μs, total: 8.76 ms\n",
      "Wall time: 20.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = df2.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9dbd21f-9e37-4221-b765-80ba8c80b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|                                                       input|                                                       preds|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "|Translate English to French: A ridiculous movie, a terrib...|Un film ridicule, un terrible travail de rédaction, le pi...|\n",
      "|Translate English to French: Most of this film was okay, ...|La plupart de ce film était en bonne et due forme, pour u...|\n",
      "|                        Translate English to French: I tried|                                                 J'ai essayé|\n",
      "|Translate English to French: This movie attempted to make...|Ce film tentait de rendre la vie de Stu Ungar intéressant...|\n",
      "|Translate English to French: After I saw this I concluded...|Après avoir vu ce film, j'ai conclu qu'il était très prob...|\n",
      "|Translate English to French: Jeff Speakman never really m...|Jeff Speakman n'a jamais vraiment franchi les rangs les p...|\n",
      "|Translate English to French: I haven't seen this movie in...|Je n'ai pas vu ce film depuis des années, la dernière foi...|\n",
      "|Translate English to French: Now don't get me wrong I lov...|     Maintenant, ne pas me grecher Je aime les mauvais films|\n",
      "|Translate English to French: There I am sitting at home i...|       l'intérieur, je me trouve à la maison le matin, sous-|\n",
      "|Translate English to French: Yes, it was an awful movie, ...|  Oui, c'était un film terrible, mais il y avait une chanson|\n",
      "|Translate English to French: This was the most uninterest...|         Ce fut le plus inquiétant et le plus inquiétant d'h|\n",
      "|Translate English to French: Another in the long line of ...|   Une autre en longue ligne de conan qui a eu la fatigue de|\n",
      "|Translate English to French: Oh, why did it have to end l...|            Laurel et Hardy s'en sont rendus dans le dernier|\n",
      "|Translate English to French: Julie Andrews satirically pr...|Julie Andrews s'enrôle satiriquement dans cette comédie m...|\n",
      "|   Translate English to French: 'Leatherheads' tries so hard|                                'Leatherheads' essaie si dur|\n",
      "|Translate English to French: If I wouldn't have had any e...|                       Si je n'aurais pas eu d'attentes à ce|\n",
      "|Translate English to French: With several name actors (La...|Avec plusieurs acteurs de nom (Lance Henrikson, David War...|\n",
      "|          Translate English to French: Woa, talk about awful|                                                            |\n",
      "|Translate English to French: The guy mentioned to sue for...|Le châssis mentionné pour intenter une action en justice ...|\n",
      "|  Translate English to French: (Warning: Some spoilers ahead|               (Avertissement : Quelques spoilers à l'avenir|\n",
      "+------------------------------------------------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e3113-64dd-482a-9233-6607b3f63c1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "425d3b28-7705-45ba-8a18-ad34fc895219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> stopping containers: ['eeba2c4778b2']\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2dec80ca-7a7c-46a9-97c0-7afb1572f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43118ab-fc0a-4f64-a126-4302e615654a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
