{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f6659b4-88da-4207-8d32-2674da5383a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks: PySpark DL Inference\n",
    "### Conditional generation with Huggingface\n",
    "\n",
    "In this notebook, we demonstrate distributed inference with the T5 transformer to perform sentence translation.  \n",
    "From: https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b8dae4a-3bfc-4430-b28a-7350db5efed4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf, col, struct\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a93a1424-e483-4d37-a719-32fabee3f285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "datasets.utils.logging.disable_progress_bar()\n",
    "datasets.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c1f9322-43e4-43a2-a286-ce96da9c6fac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n(Optional): For large datasets, we can specify the Huggingface dataset cache directory to the cluster's local disk or DBFS, rather than the default '/' (ephemeral file system at instance root). The code below specifies local disk, which enables autoscaling up to 5TB.\\n\\nFor more info on the tradeoffs, see https://docs.databricks.com/en/_extras/notebooks/source/deep-learning/hugging-face-dataset-download.html.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "(Optional): For large datasets, we can specify the Huggingface dataset cache directory to the cluster's local disk (or DBFS to persist after cluster termination), rather than the default '/' (ephemeral file system at instance root). The code below specifies local disk, which enables autoscaling up to 5TB.\n",
    "\n",
    "For more info on the tradeoffs, see https://docs.databricks.com/en/_extras/notebooks/source/deep-learning/hugging-face-dataset-download.html.\n",
    "\"\"\"\n",
    "\n",
    "# LOCAL_DISK_MOUNT = '/local_disk0'\n",
    "# dbutils.fs.mkdirs(f\"file://{LOCAL_DISK_MOUNT}/hf_cache\")\n",
    "# LOCAL_DISK_CACHE_DIR = f'{LOCAL_DISK_MOUNT}/hf_cache/'\n",
    "# dataset = load_dataset(\"imdb, split=\"test\", cache_dir=LOCAL_DISK_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB movie reviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0ec30c9-365a-43c5-9c53-3497400ee548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\", split=\"test\")\n",
    "dataset = dataset.to_pandas().drop(columns=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e4269da-d2b3-46a5-9309-38a1ba825a47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30dab34d-8e4b-4f30-b7c2-3dff49da018b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('text', StringType(), True)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(dataset).repartition(64)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55c33cc0-5dfb-449c-ae79-80972fb04405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efd6d6d9-1c2c-4131-8df4-a3ef75c3fc57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text=\"Frankly, after Cotton club and Unfaithful, it was kind of embarrassing to watch Lane and Gere in this film, because it is BAD. The acting was bad, the dialogs were extremely shallow and insincere. It was well shot, but, then again, it is a big budget movie. It was too predictable, even for a chick flick. I even knew from the beginning that he was going to die in the end, the only thing I didn't know was how. Too politically correct. Very disappointing. The only thing really worth watching was the scenery and the house, because it is beautiful. But, if you want that, watch National geographic. I love Lane, but I've never seen her in a movie this lousy. As far as Gere goes, he's a good actor, but he had movies like this, so I'm not surprised. An hour and a half I wish I could bring back.\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65a5b258-1634-441e-8b36-29777e54592d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/FileStore/rishic/datasets/imdb_test\"\n",
    "df.write.mode(\"overwrite\").parquet(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89b909f4-5732-428b-ad61-9a6c5cf94df2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Load and preprocess DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb7e53d6-bbd0-48d2-a3be-36847275e2a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text]) # Take first sentence.\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97eee1a4-9dc4-43b0-9578-6d7f8ff338bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                text|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|I stumbled across this movie late at night on TV. My brother and I could not stop laughing at how...|\n",
      "|Was a college acting class exercise filmed and released as a movie? The formulaic posturing and s...|\n",
      "|This is a better-than-average entry in the Saint series - It holds your interest and, as mysterie...|\n",
      "|There was a lot about Little Vera that was strange to me. All in all I did enjoy this movie, but ...|\n",
      "|I never dreamed when I started watching this DVD that I would be totally mesmerized by it within ...|\n",
      "|I'm a Boorman fan, but this is arguably his least successful film. Comedy has never been his stro...|\n",
      "|I wasn't sure about getting this movie on DVD because I really do have something against people m...|\n",
      "|I endured this film just to satisfy my curiosity. It has to be one of the worst films I have ever...|\n",
      "|I never saw any of John Leguizamo's stand-up before I watched Freak, and after seeing it again on...|\n",
      "|I have not watched every jackass episode. It was mildly entertaining if nothing else was going. B...|\n",
      "|It is impossible to avoid comparing Zhang Yimou's `Hero' to Ang Lee's `Crouching Tiger, Hidden Dr...|\n",
      "|The music is by Stravinsky (and not by stupid incompetent Philip Glass) and was written ten years...|\n",
      "|One of the last surviving horror screen greats - Conrad Radzoff - dies and has his body placed in...|\n",
      "|- Contains 1 spoiler, market with: ***** -<br /><br />Not presenting itself as yet another remake...|\n",
      "|Sadly, this movie is relegated to 'curio' status it seems. Many people that I've asked \"Did you k...|\n",
      "|So, I'm wondering while watching this film, did the producers of this movie get to save money on ...|\n",
      "|Loved this movie! Kicking it old school! Love the idea. Love the script. Love the characters. I r...|\n",
      "|The English Patient is one of those films that mostly deserve all the highest praise. I say, most...|\n",
      "|First off, Mexican Werewolf in Texas' title is misleading as many others have pointed out. It is ...|\n",
      "|This movie was a waste of 3 hours of my precious time..in the first 10 minutes i was already anno...|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(data_path).limit(2046).repartition(64)\n",
    "df.show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa14304d-b409-4d07-99ef-9da7c7c76158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                               input|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|translate English to French: I loved the first \"American Graffiti\" with all my heart and soul tha...|\n",
      "|translate English to French: Firstly this has nothing to do with the much better 18 weapons of Ku...|\n",
      "|translate English to French: But perhaps you have to have grown up in the 80's to truly appreciat...|\n",
      "|translate English to French: Take a subject I didn't know much about and make it exciting, why do...|\n",
      "|      translate English to French: This is the worst film I have ever seen, so bad it is astonishing|\n",
      "|translate English to French: Margaret Mitchell spins in her grave every time somebody watches thi...|\n",
      "|                                     translate English to French: I have seen this movie three times|\n",
      "|                                   translate English to French: I'd give this film a zero if I could|\n",
      "|                                 translate English to French: I had a hard time sitting through this|\n",
      "|translate English to French: Most likely \"Cleopatra 2525\" will be of little interest if you did n...|\n",
      "|translate English to French: i watch this film with horror in my heart because my mother also was...|\n",
      "|translate English to French: Maybe here in Sydney we are all poop side down and as a result we ge...|\n",
      "|  translate English to French: Gray can make the English language jump through hoops like none other|\n",
      "|                                 translate English to French: I agree that this film was spectacular|\n",
      "|translate English to French: Besides the comments on the technical merits of the production, or l...|\n",
      "|translate English to French: Having dabbled in the modeling industry (as a model), I watch this s...|\n",
      "|translate English to French: Before I'd seen this movie I've heard a lot of praise about it and q...|\n",
      "|translate English to French: Let me just give you guys some advice, if your going to watch this m...|\n",
      "|translate English to French: my girlfriend, as we walk in the cold London evening in leicester sq...|\n",
      "|translate English to French: The sad thing about Frontline is that once you watch three or four e...|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df = df.select(preprocess(col(\"text\"), \"translate English to French: \").alias(\"input\")).cache()\n",
    "input_df.show(truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc9cbdd2-1ca6-48e4-a549-792b3726525b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inference using Spark DL API\n",
    "\n",
    "Distributed inference using the PySpark [predict_batch_udf](https://spark.apache.org/docs/3.4.0/api/python/reference/api/pyspark.ml.functions.predict_batch_udf.html#pyspark.ml.functions.predict_batch_udf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adb81177-442d-42ab-b86d-d8792201b4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    from pyspark import TaskContext\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Initializing model on worker {TaskContext.get().partitionId()}.\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using {device} device.\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "    def predict(inputs):\n",
    "        flattened = np.squeeze(inputs).tolist()\n",
    "        inputs = tokenizer(flattened, \n",
    "                           padding=True,\n",
    "                           return_tensors=\"pt\").to(device)\n",
    "        outputs = model.generate(input_ids=inputs[\"input_ids\"],\n",
    "                                 attention_mask=inputs[\"attention_mask\"],\n",
    "                                 max_length=128)\n",
    "        string_outputs = np.array([tokenizer.decode(o, skip_special_tokens=True) for o in outputs])\n",
    "        print(\"predict: {}\".format(len(flattened)))\n",
    "        return string_outputs\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20aab3a1-2284-4c07-9ce1-a20cf54d88f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(predict_batch_fn,\n",
    "                             return_type=StringType(),\n",
    "                             batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8d6f48e-09e7-4fc7-9d2f-1b68bc2976a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.08012843132019 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# first pass caches model/fn\n",
    "preds = input_df.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()\n",
    "print(f\"{time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abe2271d-0077-48f6-98b1-93524dd86447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.499233961105347 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "preds = input_df.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()\n",
    "print(f\"{time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77623711-a742-4262-8839-16fc3ddd1af7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.471662521362305 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "preds = input_df.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()\n",
    "print(f\"{time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f339c654-52fd-4992-b054-188dfb260e5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                               input|                                                                                               preds|\n",
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|translate English to French: I loved the first \"American Graffiti\" with all my heart and soul tha...|J'ai aimé le premier \"American Graffiti\" avec tout mon cur et tout mon âme que j'ai considéré com...|\n",
      "|translate English to French: Firstly this has nothing to do with the much better 18 weapons of Ku...|Premièrement, cela n'a rien à voir avec les 18 armes bien meilleurs de Kung Fu en mettant en scèn...|\n",
      "|translate English to French: But perhaps you have to have grown up in the 80's to truly appreciat...|         Mais peut-être avez-vous dû avoir grandi dans les années 80 pour vraiment apprécier ce film|\n",
      "|translate English to French: Take a subject I didn't know much about and make it exciting, why do...|l'époque, il y avait eu un épisode de l'épisode de l'épisode de l'épisode de l'épisode de l'épiso...|\n",
      "|      translate English to French: This is the worst film I have ever seen, so bad it is astonishing|                                 C'est le pire film que je n'ai jamais vu, si mauvais c'est étonnant|\n",
      "|translate English to French: Margaret Mitchell spins in her grave every time somebody watches thi...|                Margaret Mitchell s'enfonce dans sa tombe chaque fois que quelqu'un regarde ce mess!|\n",
      "|                                     translate English to French: I have seen this movie three times|                                                                          J'ai vu ce film trois fois|\n",
      "|                                   translate English to French: I'd give this film a zero if I could|                                                          Je donnerais ce film un zéro si je pouvais|\n",
      "|                                 translate English to French: I had a hard time sitting through this|                                                      J’ai eu du mal à se tenir dans cette enceinte.|\n",
      "|translate English to French: Most likely \"Cleopatra 2525\" will be of little interest if you did n...|Il est très probable que le « Cleopatra 2525 » ne sera pas d'intérêt si vous n'avez pas regardé l...|\n",
      "|translate English to French: i watch this film with horror in my heart because my mother also was...|j'ai regardé ce film avec horreur dans mon coeur parce que ma mère était aussi une tête fente com...|\n",
      "|translate English to French: Maybe here in Sydney we are all poop side down and as a result we ge...|Peut-être ici à Sydney, nous sommes tous poop à côté et, par conséquent, nous avons l'occasion de...|\n",
      "|  translate English to French: Gray can make the English language jump through hoops like none other| Gray peut faire en sorte que la langue anglaise s’éleve à l’arrière-plan comme n’importe quel autre|\n",
      "|                                 translate English to French: I agree that this film was spectacular|                                          Je suis d'accord pour dire que ce film a été spectaculaire|\n",
      "|translate English to French: Besides the comments on the technical merits of the production, or l...|Outre les commentaires sur les mérites techniques de la production, ou l'absence de ces commentai...|\n",
      "|translate English to French: Having dabbled in the modeling industry (as a model), I watch this s...|Ayant dû s’efforcer de mettre en uvre des modèles (en tant que modèle), je regarde ce spectacle a...|\n",
      "|translate English to French: Before I'd seen this movie I've heard a lot of praise about it and q...|Avant de voir ce film, j'ai entendu beaucoup de louanges à ce sujet et beaucoup d'exclamations su...|\n",
      "|translate English to French: Let me just give you guys some advice, if your going to watch this m...|Je vous donne quelques conseils, si vous allez regarder ce film simplement pour voir un échantill...|\n",
      "|translate English to French: my girlfriend, as we walk in the cold London evening in leicester sq...|l'occasion de notre arrivée dans la soirée froide de Londres, à la place leicester, après le film...|\n",
      "|translate English to French: The sad thing about Frontline is that once you watch three or four e...|La triste chose de Frontline est qu'une fois que vous regardez trois ou quatre épisodes de cette ...|\n",
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a79a6f3a-cc34-46a4-aadd-16870423fffa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Using Triton Inference Server\n",
    "\n",
    "The Triton Inference Server is launched in a separate process on each node.   \n",
    "We use [PyTriton](https://github.com/triton-inference-server/pytriton), which provides a Python API to handle client/server communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e73757e-a451-4835-98e0-257ccf7a9025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71b1cb49-3d8f-4eeb-937a-c0c334bd2947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton Server PIDs:\n",
      " {0: 3151, 1: 3155, 2: 3149, 3: 3133, 4: 3134, 5: 3131, 6: 3129, 7: 3140}\n"
     ]
    }
   ],
   "source": [
    "def triton_server():\n",
    "    import signal\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "    from pytriton.decorators import batch\n",
    "    from pytriton.model_config import DynamicBatcher, ModelConfig, Tensor\n",
    "    from pytriton.triton import Triton\n",
    "    from pyspark import TaskContext\n",
    "\n",
    "    with Triton() as triton:\n",
    "        print(f\"Initializing Conditional Generation model on worker {TaskContext.get().partitionId()}.\")\n",
    "        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "        model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "        \n",
    "        DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using {DEVICE} device.\")\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "        @batch\n",
    "        def _infer_fn(**inputs):\n",
    "            sentences = np.squeeze(inputs[\"text\"]).tolist()\n",
    "            print(f\"Received batch of size {len(sentences)}\")\n",
    "            decoded_sentences = [s.decode(\"utf-8\") for s in sentences]\n",
    "            inputs = tokenizer(decoded_sentences,\n",
    "                            padding=True,\n",
    "                            return_tensors=\"pt\").to(DEVICE)\n",
    "            output_ids = model.generate(input_ids=inputs[\"input_ids\"],\n",
    "                                        attention_mask=inputs[\"attention_mask\"],\n",
    "                                        max_length=128)\n",
    "            outputs = np.array([[tokenizer.decode(o, skip_special_tokens=True)] for o in output_ids])\n",
    "            return {\n",
    "                \"translations\": outputs,\n",
    "            }\n",
    "\n",
    "        triton.bind(\n",
    "            model_name=\"ConditionalGeneration\",\n",
    "            infer_func=_infer_fn,\n",
    "            inputs=[\n",
    "                Tensor(name=\"text\", dtype=object, shape=(-1,)),\n",
    "            ],\n",
    "            outputs=[\n",
    "                Tensor(name=\"translations\", dtype=object, shape=(-1,)),\n",
    "            ],\n",
    "            config=ModelConfig(\n",
    "                max_batch_size=256,\n",
    "                batcher=DynamicBatcher(max_queue_delay_microseconds=5000),  # 5ms\n",
    "            ),\n",
    "            strict=True,\n",
    "        )\n",
    "\n",
    "        def stop_triton(signum, frame):\n",
    "            print(\"Received SIGTERM. Stopping Triton server.\")\n",
    "            triton.stop()\n",
    "\n",
    "        signal.signal(signal.SIGTERM, stop_triton)\n",
    "\n",
    "        print(\"Serving inference\")\n",
    "        triton.serve()\n",
    "\n",
    "def start_triton(idx, url, model_name):\n",
    "    from multiprocessing import Process\n",
    "    from pytriton.client import ModelClient\n",
    "\n",
    "    process = Process(target=triton_server)\n",
    "    process.start()\n",
    "\n",
    "    client = ModelClient(url, model_name)\n",
    "    ready = False\n",
    "    while not ready:\n",
    "        try:\n",
    "            client.wait_for_server(5)\n",
    "            ready = True\n",
    "        except Exception as e:\n",
    "            print(f\"Waiting for server to be ready: {e}\")\n",
    "    \n",
    "    return [(idx, process.pid)]\n",
    "\n",
    "# Start servers\n",
    "num_nodes = 8\n",
    "url = \"localhost\"\n",
    "model_name = \"ConditionalGeneration\"\n",
    "\n",
    "sc = spark.sparkContext\n",
    "nodeRDD = sc.parallelize(list(range(num_nodes)), num_nodes)\n",
    "pids = nodeRDD.barrier().mapPartitionsWithIndex(lambda idx, _: start_triton(idx, url, model_name)).collectAsMap()\n",
    "print(\"Triton Server PIDs:\\n\", pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e203eb19-166d-4177-aa87-fd31b7e3c90e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def triton_fn(url, model_name, init_timeout_s):\n",
    "    import numpy as np\n",
    "    from pytriton.client import ModelClient\n",
    "\n",
    "    print(f\"Connecting to model {model_name} at {url}.\")\n",
    "\n",
    "    def infer_batch(inputs):\n",
    "        with ModelClient(url, model_name, init_timeout_s=init_timeout_s) as client:\n",
    "            flattened = np.squeeze(inputs).tolist() \n",
    "            # Encode batch\n",
    "            encoded_batch = [[text.encode(\"utf-8\")] for text in flattened]\n",
    "            encoded_batch_np = np.array(encoded_batch, dtype=np.bytes_)\n",
    "            # Run inference\n",
    "            result_data = client.infer_batch(encoded_batch_np)\n",
    "            result_data = np.squeeze(result_data[\"translations\"], -1)\n",
    "            return result_data\n",
    "        \n",
    "    return infer_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5e83230-5178-4fec-bba2-0e69be40e68c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text: pd.Series, prefix: str = \"\") -> pd.Series:\n",
    "    @pandas_udf(\"string\")\n",
    "    def _preprocess(text: pd.Series) -> pd.Series:\n",
    "        return pd.Series([prefix + s.split(\".\")[0] for s in text])\n",
    "    return _preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aad299b0-34bb-4edb-b1e4-cd0c82bb7455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(data_path).limit(2046).repartition(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7934a6fc-57bc-4104-a52c-076351e77cbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_df = df.select(preprocess(col(\"text\"), \"translate English to French: \").alias(\"input\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be692f4a-cf86-4cf4-9530-7c62e479cacd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate = predict_batch_udf(partial(triton_fn, url=url, model_name=model_name, init_timeout_s=600),\n",
    "                             return_type=StringType(),\n",
    "                             input_tensor_shapes=[[1]],\n",
    "                             batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f6229ef-01c8-43c9-a259-c5df6a18d689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 ms, sys: 14.3 ms, total: 26.7 ms\n",
      "Wall time: 9.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "preds = input_df.withColumn(\"preds\", generate(struct(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a543b4c-8b29-4f61-9773-2639bbc7f728",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.7 ms, sys: 13.3 ms, total: 20 ms\n",
      "Wall time: 6.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = input_df.withColumn(\"preds\", generate(\"input\"))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c0cfc4e-ef0a-435e-9fdf-72b72b6def93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 ms, sys: 2.28 ms, total: 19.9 ms\n",
      "Wall time: 6.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = input_df.withColumn(\"preds\", generate(col(\"input\")))\n",
    "results = preds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d756e2e-8b60-43cb-b5f9-e27de11be24d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                               input|                                                                                               preds|\n",
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|translate English to French: This really is by far the worst movie I've ever seen in my whole lif...|         Cette vidéo est vraiment le pire que je n'ai jamais vu dans ma vie (je me rapproche de 47)!|\n",
      "|                               translate English to French: I thought i could see something good but|                                          Je pensais que je pouvais voir quelque chose de bien, mais|\n",
      "|translate English to French: Otto Preminger's \"The Man with the Golden Arm\" is a reference to her...|Le film d'Otto Preminger, « The Man with the Golden Arm », fait référence à la dépendance à l'hér...|\n",
      "|                                      translate English to French: I really wanted to love this film|                                                                   Je voulais vraiment aimer ce film|\n",
      "|translate English to French: Ettore Scola's masterful rendering of this epic of the heart deserve...|                         Ettore Scola a rendu cette épopée du coeur à un public beaucoup plus large.|\n",
      "|translate English to French: We brought this film as a joke for a friend, and could of been our w...|Nous avons livré ce film comme une plaisanterie pour un ami, et il aurait pu être notre pire plai...|\n",
      "|                                       translate English to French: This takes place in 1920s Harlem|                                                 Cette activité a lieu dans les années 1920 à Harlem|\n",
      "|translate English to French: This is a piece of Hollywood product that should have never left a f...|                     Il s'agit d'un produit hollywoodien qui n'aurait jamais dû quitter un film peut|\n",
      "|translate English to French: Let me preface by stating that I have lived in Louisville, Kentucky ...|          Permettez-moi de préfacer en affirmant que j'ai vécu à Louisville, Kentucky, toute ma vie.|\n",
      "|translate English to French: After slightly over 50 years of avid film watching, I've come up wit...|Après un peu plus de 50 ans de vidéos abondantes, j'ai établi quelques règles simples pour faire ...|\n",
      "|translate English to French: I only watched the first twenty minutes of this movie and personally...|Je n'ai regardé que les vingt premières minutes de ce film et personnellement je pense que c'est ...|\n",
      "|     translate English to French: L'Homme Blesse is not for an impatient, adventure-seeking audience|                      L'Homme Blesse n'est pas pour un public impatient et à la recherche d'aventure|\n",
      "|translate English to French: I had read online reviews praising this obscure outing as a combinat...|Je lis en ligne des critiques en lisant cette sortie obscure comme une combinaison de horror d'ho...|\n",
      "|translate English to French: <br /><br />In the process of boring you with the wordy, rambling st...|br />br />En l'ennuiant avec la racine verbale, rambling et l'absence totale de développement de ...|\n",
      "|       translate English to French: A kinda remake of PLANES TRAINS AND AUTOMOBILES in a lot of ways|                            Un genre de remake de PLANES TRAINS ET AUTOMOBILES de beaucoup de façons|\n",
      "|translate English to French: This is a very low budget film, set in one location in a valley shie...|Il s'agit d'un film très peu budgétaire, situé dans une vallée protégée par les effets des rayonn...|\n",
      "|translate English to French: **MAJOR SPOILERS** Watchable only for the action sequences not the s...|**SPOILERS DU MARCHÉ** Surveillable uniquement pour les séquences d'action non pas l'histoire ou ...|\n",
      "|translate English to French: Normally I wouldn't go to the trouble of commenting on a horror movi...|Normalement, je ne m'en ferais pas à commenter une suite de films d'horreur, parce qu'on suppose ...|\n",
      "|translate English to French: Having been interested in Akhenaton for many years I was surprised t...|Ayant eu l'intérêt d'Akhenaton depuis de nombreuses années, j'ai été surpris d'apprendre ce film ...|\n",
      "|               translate English to French: As many know, this is the feature film debut of Edward D|                                         Comme beaucoup le savent, c’est le long métrage d’Edward D.|\n",
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98fc8ea8-ca63-43b1-94eb-cf683d0706de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(idx, pids):\n",
    "    import os\n",
    "    import signal\n",
    "    import time \n",
    "\n",
    "    pid = pids[idx]\n",
    "\n",
    "    num_retries = 5\n",
    "    for _ in range(num_retries):\n",
    "        try:\n",
    "            os.kill(pid, signal.SIGTERM)\n",
    "        except ProcessLookupError:\n",
    "            return [True]\n",
    "        time.sleep(5)\n",
    "\n",
    "    return [False]\n",
    "\n",
    "nodeRDD.barrier().mapPartitionsWithIndex(lambda idx, _: stop_triton(idx, pids)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16fd4601-f6d5-4ddf-9b5e-d918ab0adf3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 421988607303514,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "spark-triton-db.ipynb",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "spark-dl-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
