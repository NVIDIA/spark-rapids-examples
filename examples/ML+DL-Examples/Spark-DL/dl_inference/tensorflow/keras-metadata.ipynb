{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6810cc-5982-4293-bfbd-c91ef0aca204",
   "metadata": {},
   "source": [
    "# Distributed model inference using TensorFlow Keras\n",
    "From: https://docs.databricks.com/_static/notebooks/deep-learning/keras-metadata.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf329ac8-0763-44bc-b0f6-b634b7dc480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 01:23:38.569048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:23:38.585924: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:23:38.591041: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:23:38.603766: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:23:39.300544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import uuid\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    " \n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d72768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/24 01:23:41 WARN Utils: Your hostname, dgx2h0194.spark.sjc4.nvmetal.net resolves to a loopback address: 127.0.1.1; using 10.150.30.2 instead (on interface enp134s0f0np0)\n",
      "24/09/24 01:23:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/24 01:23:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/24 01:23:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/09/24 01:23:42 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/09/24 01:23:42 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/09/24 01:23:42 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/09/24 01:23:42 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "num_threads = 6\n",
    "\n",
    "# Creating a local Spark session for demonstration, in case it hasn't already been created.\n",
    "\n",
    "_config = {\n",
    "    \"spark.master\": f\"local[{num_threads}]\",\n",
    "    \"spark.driver.host\": \"127.0.0.1\",\n",
    "    \"spark.task.maxFailures\": \"1\",\n",
    "    \"spark.driver.memory\": \"8g\",\n",
    "    \"spark.executor.memory\": \"8g\",\n",
    "    \"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\": \"false\",\n",
    "    \"spark.sql.pyspark.jvmStacktrace.enabled\": \"true\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "    \"spark.python.worker.reuse\": \"true\",\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"spark-dl-example\")\n",
    "for key, value in _config.items():\n",
    "    spark = spark.config(key, value)\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833e36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950b0470-a21e-4778-a80e-b8f6ef792dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"image_data.parquet\"\n",
    "output_file_path = \"predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d08a7-66b9-444f-b362-d8df692aef1c",
   "metadata": {},
   "source": [
    "### Prepare trained model and data for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da083168-137f-492c-8769-d8f1e2111756",
   "metadata": {},
   "source": [
    "Load the ResNet-50 Model and broadcast the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ddc715a-cdbc-4c49-93e9-58c9d88511da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 01:23:46.468094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 29659 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.469480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30823 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.470743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30823 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.471975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30823 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.473184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 30823 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.474382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30823 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.475587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30823 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.476779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 30823 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.478029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 30823 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.479304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 30823 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.480537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 30823 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.481685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 30823 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.482890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 30823 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.484111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 30823 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.485301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 30823 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:23:46.486492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 30823 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dddfa3-e8df-4e8e-8251-64457f1ebf80",
   "metadata": {},
   "source": [
    "Load the data and save the datasets to one Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0738bec-97d4-4946-8c49-5e6d07ff1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014644f4-2a45-4474-8afb-0daf90043253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54f470a-d308-4426-8ed0-33f95155bb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(data_dir) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "files = files[:2048]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd883dc0-4846-4411-a4d6-4f5f252ac707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rishic/.keras/datasets/flower_photos\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f94ee0-f1ea-47f6-a77e-be8da5d1b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "for file in files:\n",
    "    img = Image.open(file)\n",
    "    img = img.resize([224, 224])\n",
    "    data = np.asarray(img, dtype=\"float32\").reshape([224*224*3])\n",
    "\n",
    "    image_data.append({\"data\": data})\n",
    "\n",
    "pandas_df = pd.DataFrame(image_data, columns=['data'])\n",
    "pandas_df.to_parquet(file_name)\n",
    "# os.makedirs(dbfs_file_path)\n",
    "# shutil.copyfile(file_name, dbfs_file_path+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2414b0f-58f2-4e4a-9d09-8ea95b38d413",
   "metadata": {},
   "source": [
    "### Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670328e3-7274-4d78-b315-487750166a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\"rm -rf resnet50_model\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76fffe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet50_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet50_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'resnet50_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139905008456848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008458960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008458768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008458576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008457424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008458000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008461840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008462992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008463952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008463376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008464144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008462416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008463568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008466256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008466640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008465872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008464528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008466448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008465296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008467024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008457616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008459344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008452624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008459536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008459920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905008458384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402587344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402586768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402587536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402586960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402588304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402589456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402589840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402587920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402588688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402589648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402590608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402591760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402592144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402590224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402590992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402591952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402592912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402594064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402594448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402592528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402593296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402594256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402593680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402596560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402596944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402596176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402594832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402596752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402595216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402599056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402599440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402598672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402597328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402599248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402600208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402601360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402601744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402600976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402600592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402601552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402981712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402982864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402983248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402981328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402982096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402983056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402984016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402985168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402985552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402983632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402984400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402985360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402986320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402987472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402599824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402980560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402980944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402980176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402979408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402980752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402987856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402985936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402986704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402987664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402988624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402989776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402990160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402988240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402989008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402989968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402990928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402992080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402992464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402990544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402991312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402992272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402993232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402994384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402994768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402992848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402993616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402994576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911402994000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403340816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403339856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403340432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403341200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403341008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403341968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403343120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403343504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403341584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403342352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403343312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403344272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403345424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403345808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403343888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403344656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403345616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403346576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403347728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403348112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403346192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403346960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403347920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403348880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403350032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403350416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403348496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403349264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403350224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403351184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403352336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403352720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403350800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403351568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403352528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403355408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403354256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395737872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395738064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395738832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395738448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395739600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395740752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395741136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395739216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395739984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395740944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395741904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395743056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403353488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403354640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403355024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403353104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403353872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911403354832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395743440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395741520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395742288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395743248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395744208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395745360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395745744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395743824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395744592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395745552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395746512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395747664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395748048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395746128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395746896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395747856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395748816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395749968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395750352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395748432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395749200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395750160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395751120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395752272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395752656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395750736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395751504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395752464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395737680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911395753040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396130896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396131280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396131856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396131088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396132624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396133776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396134160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396132240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396133008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396133968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396134928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396136080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396136464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396134544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396135312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396136272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396137232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396138384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396138768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396136848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396137616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396138576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396139536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396140688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396141072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396139152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396139920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396140880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396141840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396142992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396143376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396141456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396142224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396143184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396144144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396145296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396145680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396143760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396144528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396145488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396144912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396146448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540866896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540866320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139911396146832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540866128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540867664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540868816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540869200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540867280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540868048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540869008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540869968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540871120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540871504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540869584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540870352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540871312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540872272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540873424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540873808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540871888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540872656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540873616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540876880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540878032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540878416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540876496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540877264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540878224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540879184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540880336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540880720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540878800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540879568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540880528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540881488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540881104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540874576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540875728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540876112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540874192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540874960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540875920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541227536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541227152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905540881872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541226960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541227920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541229072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541229456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541227344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541228304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541229264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541230224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541231376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541231760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541229840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541230608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541231568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541232528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541233680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541234064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541232144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541232912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541233872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541234832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541235984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541236368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541234448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541235216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541236176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541237136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541238288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541238672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541236752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541237520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541238480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541239440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541240592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541240976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541239056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541239824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541240784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541241744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139905541241360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export(\"resnet50_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827ad56-1af0-41b7-be68-94bd203a2a70",
   "metadata": {},
   "source": [
    "### Load the data into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ddc22d0-b88a-4906-bd47-bf247e34feeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "df = spark.read.parquet(file_name)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7adf1d9-1fa7-4456-ae32-cf7d1d43bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97173c07-a96e-4262-b60f-82865b997e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert len(df.head()) > 0, \"`df` should not be empty\" # This line will fail if the vectorized reader runs out of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865929b0-b016-4de4-996d-7f16176cf49c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model inference via pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67b3128-13c1-44f1-a0c0-7cf7a836fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image_data):\n",
    "    image = tf.image.convert_image_dtype(\n",
    "        image_data, dtype=tf.float32) * (2. / 255) - 1\n",
    "    image = tf.reshape(image, [224, 224, 3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b33185f-6d1e-4ca9-9757-fdc3d736496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rishic/anaconda3/envs/spark-rapids-tf-andcuda/lib/python3.11/site-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(ArrayType(FloatType()), PandasUDFType.SCALAR_ITER)\n",
    "def predict_batch_udf(image_batch_iter):\n",
    "\n",
    "    # Enable GPU memory growth to avoid CUDA OOM\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    batch_size = 64\n",
    "    model = ResNet50(weights=None)\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    for image_batch in image_batch_iter:\n",
    "        images = np.vstack(image_batch)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "        dataset = dataset.map(parse_image, num_parallel_calls=8).prefetch(\n",
    "            5000).batch(batch_size)\n",
    "        preds = model.predict(dataset)\n",
    "        yield pd.Series(list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad8c05da-db38-45ef-81d0-1f862f575ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 01:25:01.047489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:25:01.063458: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:25:01.068152: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:25:01.080010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:25:01.757859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:25:07.837282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 29095 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.838722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30515 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.840022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30515 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.841292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30515 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.842552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 30515 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.843785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30515 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.845055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30515 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.846300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 30515 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.847536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 30515 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.848783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 30515 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.849990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 30515 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.851222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 30515 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.852479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 30515 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.853651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 30515 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.854860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 30515 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:07.856106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 30515 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:09.859859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:25:09.859866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:25:09.876643: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:25:09.876651: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:25:09.881680: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:25:09.881689: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:25:09.895007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:25:09.895008: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:25:10.580302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:25:10.580318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:25:13.619665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:25:13.635693: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:25:13.640551: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:25:13.652341: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:25:14.302601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:25:20.177164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 27915 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.181753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 29591 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.185637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 29591 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.188554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 29591 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.191594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 29591 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.195834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 29591 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.199027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 29591 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.201354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 29591 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.203922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 29887 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.206862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 29899 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.210750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 29899 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.213004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 29899 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.215329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 29899 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.217776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 29899 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.221629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 29899 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.225046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 29899 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.232064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 27915 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.235290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 29591 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.237912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 29591 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.240162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 29591 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.242927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 29591 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.245733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 29591 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.248032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 29591 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.250315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 29591 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.253042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 29887 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.256556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 29899 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.259937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 29899 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.262554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 29899 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.265816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 29899 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.269310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 29899 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.272745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 29899 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:20.276091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 29899 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.709602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 27403 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.711004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 29591 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.712260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 29591 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.713511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 29591 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.714745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 29591 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.715963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 29591 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.717187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 29591 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.718401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 29591 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.719621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 29591 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.720794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 29591 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.722006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 29591 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.723263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 29591 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.724431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 29591 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.725616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 29591 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.727026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 29591 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:25:22.728199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 29591 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "WARNING:tensorflow:AutoGraph could not transform <function parse_image at 0x7fc62fdd4fe0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node, got [<gast.gast.Import object at 0x7fc5c010cb80>, <gast.gast.Import object at 0x7fc5c010c190>, <gast.gast.Import object at 0x7fc5c010c0a0>, <gast.gast.Import object at 0x7fc5c010d750>, <gast.gast.Import object at 0x7fc5c010dae0>, <gast.gast.Import object at 0x7fc5c010db40>, <gast.gast.Import object at 0x7fc5c010dba0>, <gast.gast.Import object at 0x7fc5c010dc00>, <gast.gast.Import object at 0x7fc5c010dc60>, <gast.gast.ImportFrom object at 0x7fc5c010e2c0>, <gast.gast.ImportFrom object at 0x7fc5c010e320>, <gast.gast.ImportFrom object at 0x7fc5c010e380>, <gast.gast.ImportFrom object at 0x7fc5c010e3e0>, <gast.gast.ImportFrom object at 0x7fc5c010e470>, <gast.gast.FunctionDef object at 0x7fc5c010e560>]\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727141125.627026 3947310 service.cc:146] XLA service 0x7fbfe80d4fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727141125.627052 3947310 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627055 3947310 service.cc:154]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627057 3947310 service.cc:154]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627059 3947310 service.cc:154]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627061 3947310 service.cc:154]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627063 3947310 service.cc:154]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627065 3947310 service.cc:154]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627067 3947310 service.cc:154]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627069 3947310 service.cc:154]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627071 3947310 service.cc:154]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627073 3947310 service.cc:154]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627076 3947310 service.cc:154]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627077 3947310 service.cc:154]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627079 3947310 service.cc:154]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627081 3947310 service.cc:154]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141125.627083 3947310 service.cc:154]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-24 01:25:25.695627: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-24 01:25:26.173207: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-24 01:25:27.320163: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1727141127.658602 3947310 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[4.7788864E-5, 3.036927E-4, 7.026324E-5, 1.772748E-4, 4.5683286E-5, 1.9182988E-4, 9.988368E-6, 7.264478E-5, 1.4183694...|\n",
      "|[1.2047288E-5, 2.4665435E-4, 2.3863144E-4, 1.9301432E-4, 1.5375564E-4, 4.5055505E-5, 2.220773E-5, 3.791191E-4, 1.5702...|\n",
      "|[1.3302326E-4, 2.696228E-4, 5.517897E-5, 9.9901976E-5, 4.7618698E-5, 4.4045786E-4, 6.8055174E-6, 3.486012E-5, 1.26733...|\n",
      "|[1.5190376E-5, 2.9297185E-4, 1.17424854E-4, 8.6468535E-5, 7.027255E-5, 7.291867E-5, 1.1590379E-5, 2.905424E-4, 1.7357...|\n",
      "|[1.1257283E-4, 2.5857892E-4, 5.5297343E-5, 1.0446069E-4, 4.6776848E-5, 3.4146357E-4, 6.6849643E-6, 3.6820922E-5, 1.15...|\n",
      "|[9.95129E-5, 3.513081E-4, 9.309831E-5, 1.4611095E-4, 7.243498E-5, 2.7604023E-4, 1.3097427E-5, 1.0884549E-4, 2.2091297...|\n",
      "|[9.426697E-5, 3.7797264E-4, 1.889081E-4, 3.017484E-4, 1.1807096E-4, 2.825622E-4, 1.970623E-5, 1.1764238E-4, 1.8083643...|\n",
      "|[1.2302614E-4, 2.2465072E-4, 3.0343583E-5, 9.0339316E-5, 2.819704E-5, 4.4976934E-4, 3.189744E-6, 2.624859E-5, 9.48956...|\n",
      "|[1.1142831E-4, 2.504624E-4, 4.6369034E-5, 1.0202974E-4, 3.9002465E-5, 3.5218574E-4, 5.2744895E-6, 3.2696487E-5, 1.100...|\n",
      "|[5.0597966E-5, 2.834586E-4, 1.2132926E-4, 1.9169123E-4, 9.219973E-5, 2.0994889E-4, 1.0187929E-5, 1.3009128E-4, 1.7364...|\n",
      "|[8.3086015E-5, 2.8279284E-4, 1.3492702E-4, 2.208303E-4, 9.525056E-5, 2.375283E-4, 1.6205138E-5, 1.00991216E-4, 1.4331...|\n",
      "|[1.15561685E-4, 2.5343124E-4, 3.9419767E-5, 8.738221E-5, 3.43671E-5, 4.1973148E-4, 5.474829E-6, 2.7518814E-5, 1.27988...|\n",
      "|[7.8735575E-5, 2.843643E-4, 9.4464434E-5, 2.909338E-4, 1.0374696E-4, 2.0492346E-4, 7.027104E-6, 1.0258028E-4, 9.28546...|\n",
      "|[1.3040153E-4, 2.925545E-4, 7.7841185E-5, 1.5847E-4, 6.818609E-5, 3.9240666E-4, 1.3796494E-5, 4.6808407E-5, 1.8040277...|\n",
      "|[1.0765981E-4, 2.2286251E-4, 4.466443E-5, 8.856087E-5, 3.559462E-5, 3.5881315E-4, 3.6300344E-6, 3.8859125E-5, 8.36635...|\n",
      "|[6.4850945E-5, 2.836782E-4, 1.6979409E-4, 2.524894E-4, 1.1747874E-4, 3.016754E-4, 1.5257171E-5, 1.3339268E-4, 1.34892...|\n",
      "|[3.262807E-5, 3.9011642E-4, 5.610781E-5, 9.1521484E-5, 8.91793E-5, 1.8981296E-4, 1.6347147E-5, 1.3983177E-4, 1.212782...|\n",
      "|[1.11893285E-4, 2.7323118E-4, 4.9729966E-5, 9.237238E-5, 3.5741083E-5, 3.6771223E-4, 6.1541077E-6, 3.7560138E-5, 9.64...|\n",
      "|[1.15863666E-4, 9.872305E-4, 1.2683612E-4, 2.8349645E-4, 1.247385E-4, 3.3857307E-4, 7.44898E-5, 1.4036038E-4, 5.81837...|\n",
      "|[5.5262528E-5, 2.714447E-4, 2.1939904E-4, 3.41609E-4, 1.2830946E-4, 1.6681952E-4, 1.8766756E-5, 1.1253764E-4, 1.17077...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 129 ms, sys: 87.4 ms, total: 216 ms\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(col(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40799f8e-443e-40ca-919b-391f901cb3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 01:25:52.662786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:25:52.662786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:25:52.662789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:25:52.680249: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:25:52.680249: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:25:52.680249: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:25:52.685367: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:25:52.685368: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:25:52.685369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:25:52.698970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:25:52.698970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:25:52.698970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:25:53.442751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:25:53.442751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:25:53.442751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:26:09.008498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 26785 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.012439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 28975 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.016240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 28975 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.019851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 28975 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.023666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 28975 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.027437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 28975 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.031217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 28975 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.034949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 28975 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.038793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 28975 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.042680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 28975 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.046554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 28975 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.050435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 28975 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.061768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 26785 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.064853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 28975 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.067775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 28975 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.068274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 28975 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.071417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 28975 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.071877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 28975 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.075103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 28975 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.075564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 28975 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.078411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 26785 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.078860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 28975 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.079295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 28975 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.081546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 28975 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.081899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 28975 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.084386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 28975 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.084817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 28975 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.086596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 28975 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.087040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 28975 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.089229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 28975 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.089870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 28975 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.091898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 28975 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.092772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 28975 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.094503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 28975 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.095518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 28975 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.097098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 28975 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.098101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 28975 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.100199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 28975 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.101348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 28975 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.102944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 28975 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.104231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 28975 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.105740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 28975 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.107085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 28975 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.108891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 28975 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.113015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 28975 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.116967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 28975 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.120330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 28975 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:26:09.124349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 28975 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "WARNING:tensorflow:AutoGraph could not transform <function parse_image at 0x7fc62b7a02c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node, got [<gast.gast.Import object at 0x7fc62af01fc0>, <gast.gast.Import object at 0x7fc62af01480>, <gast.gast.Import object at 0x7fc62af01510>, <gast.gast.Import object at 0x7fc62af02bc0>, <gast.gast.Import object at 0x7fc62af02f50>, <gast.gast.Import object at 0x7fc62af02fb0>, <gast.gast.Import object at 0x7fc62af03010>, <gast.gast.Import object at 0x7fc62af03070>, <gast.gast.Import object at 0x7fc62af030d0>, <gast.gast.ImportFrom object at 0x7fc62af03730>, <gast.gast.ImportFrom object at 0x7fc62af03790>, <gast.gast.ImportFrom object at 0x7fc62af037f0>, <gast.gast.ImportFrom object at 0x7fc62af03850>, <gast.gast.ImportFrom object at 0x7fc62af038e0>, <gast.gast.FunctionDef object at 0x7fc62af039d0>]\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727141178.779761 3947098 service.cc:146] XLA service 0x7fbfe8254760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727141178.779794 3947098 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779799 3947098 service.cc:154]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779804 3947098 service.cc:154]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779808 3947098 service.cc:154]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779813 3947098 service.cc:154]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779816 3947098 service.cc:154]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779821 3947098 service.cc:154]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779826 3947098 service.cc:154]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779831 3947098 service.cc:154]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779835 3947098 service.cc:154]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779839 3947098 service.cc:154]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779843 3947098 service.cc:154]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779848 3947098 service.cc:154]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779852 3947098 service.cc:154]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779862 3947098 service.cc:154]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141178.779866 3947098 service.cc:154]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-24 01:26:18.850862: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-24 01:26:19.339057: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-24 01:26:20.978272: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1727141181.310793 3947098 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 104 ms, total: 240 ms\n",
      "Wall time: 32.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16726357-65d8-4d3d-aea1-6800101741cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model inference using Spark DL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6af27b2-ddc0-42ee-94cc-9ba5ffee6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dda88b46-6300-4bf7-bc10-7403f4fbbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "    # Enable GPU memory growth\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    model = ResNet50()\n",
    "    def predict(inputs):\n",
    "        inputs = inputs * (2. / 255) - 1\n",
    "        return model.predict(inputs)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cff0e851-563d-40b6-9d05-509c22b3b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             input_tensor_shapes=[[224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f733c38b-867d-48c1-b9a6-74a931561896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa7c156f-e2b3-4837-9427-ccf3a5720412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80bc50ad-eaf5-4fce-a354-5e17d65e2da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727141215.666478 3948946 service.cc:146] XLA service 0x7fbfe80d5110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727141215.666502 3948946 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666506 3948946 service.cc:154]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666511 3948946 service.cc:154]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666515 3948946 service.cc:154]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666520 3948946 service.cc:154]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666523 3948946 service.cc:154]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666528 3948946 service.cc:154]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666533 3948946 service.cc:154]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666538 3948946 service.cc:154]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666542 3948946 service.cc:154]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666545 3948946 service.cc:154]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666550 3948946 service.cc:154]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666555 3948946 service.cc:154]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666559 3948946 service.cc:154]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666564 3948946 service.cc:154]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141215.666573 3948946 service.cc:154]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-24 01:26:55.737201: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-24 01:26:56.216118: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-24 01:26:57.416505: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[4.7788864E-5, 3.036927E-4, 7.026324E-5, 1.772748E-4, 4.5683286E-5, 1.9182988E-4, 9.988368E-6, 7.264478E-5, 1.4183694...|\n",
      "|[1.2047288E-5, 2.4665435E-4, 2.3863144E-4, 1.9301432E-4, 1.5375564E-4, 4.5055505E-5, 2.220773E-5, 3.791191E-4, 1.5702...|\n",
      "|[1.3302326E-4, 2.696228E-4, 5.517897E-5, 9.9901976E-5, 4.7618698E-5, 4.4045786E-4, 6.8055174E-6, 3.486012E-5, 1.26733...|\n",
      "|[1.5190376E-5, 2.9297185E-4, 1.17424854E-4, 8.6468535E-5, 7.027255E-5, 7.291867E-5, 1.1590379E-5, 2.905424E-4, 1.7357...|\n",
      "|[1.1257283E-4, 2.5857892E-4, 5.5297343E-5, 1.0446069E-4, 4.6776848E-5, 3.4146357E-4, 6.6849643E-6, 3.6820922E-5, 1.15...|\n",
      "|[9.95129E-5, 3.513081E-4, 9.309831E-5, 1.4611095E-4, 7.243498E-5, 2.7604023E-4, 1.3097427E-5, 1.0884549E-4, 2.2091297...|\n",
      "|[9.426697E-5, 3.7797264E-4, 1.889081E-4, 3.017484E-4, 1.1807096E-4, 2.825622E-4, 1.970623E-5, 1.1764238E-4, 1.8083643...|\n",
      "|[1.2302614E-4, 2.2465072E-4, 3.0343583E-5, 9.0339316E-5, 2.819704E-5, 4.4976934E-4, 3.189744E-6, 2.624859E-5, 9.48956...|\n",
      "|[1.1142831E-4, 2.504624E-4, 4.6369034E-5, 1.0202974E-4, 3.9002465E-5, 3.5218574E-4, 5.2744895E-6, 3.2696487E-5, 1.100...|\n",
      "|[5.0597966E-5, 2.834586E-4, 1.2132926E-4, 1.9169123E-4, 9.219973E-5, 2.0994889E-4, 1.0187929E-5, 1.3009128E-4, 1.7364...|\n",
      "|[8.3086015E-5, 2.8279284E-4, 1.3492702E-4, 2.208303E-4, 9.525056E-5, 2.375283E-4, 1.6205138E-5, 1.00991216E-4, 1.4331...|\n",
      "|[1.15561685E-4, 2.5343124E-4, 3.9419767E-5, 8.738221E-5, 3.43671E-5, 4.1973148E-4, 5.474829E-6, 2.7518814E-5, 1.27988...|\n",
      "|[7.8735575E-5, 2.843643E-4, 9.4464434E-5, 2.909338E-4, 1.0374696E-4, 2.0492346E-4, 7.027104E-6, 1.0258028E-4, 9.28546...|\n",
      "|[1.3040153E-4, 2.925545E-4, 7.7841185E-5, 1.5847E-4, 6.818609E-5, 3.9240666E-4, 1.3796494E-5, 4.6808407E-5, 1.8040277...|\n",
      "|[1.0765981E-4, 2.2286251E-4, 4.466443E-5, 8.856087E-5, 3.559462E-5, 3.5881315E-4, 3.6300344E-6, 3.8859125E-5, 8.36635...|\n",
      "|[6.4850945E-5, 2.836782E-4, 1.6979409E-4, 2.524894E-4, 1.1747874E-4, 3.016754E-4, 1.5257171E-5, 1.3339268E-4, 1.34892...|\n",
      "|[3.262807E-5, 3.9011642E-4, 5.610781E-5, 9.1521484E-5, 8.91793E-5, 1.8981296E-4, 1.6347147E-5, 1.3983177E-4, 1.212782...|\n",
      "|[1.11893285E-4, 2.7323118E-4, 4.9729966E-5, 9.237238E-5, 3.5741083E-5, 3.6771223E-4, 6.1541077E-6, 3.7560138E-5, 9.64...|\n",
      "|[1.15863666E-4, 9.872305E-4, 1.2683612E-4, 2.8349645E-4, 1.247385E-4, 3.3857307E-4, 7.44898E-5, 1.4036038E-4, 5.81837...|\n",
      "|[5.5262528E-5, 2.714447E-4, 2.1939904E-4, 3.41609E-4, 1.2830946E-4, 1.6681952E-4, 1.8766756E-5, 1.1253764E-4, 1.17077...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 33.9 ms, sys: 60.2 ms, total: 94.1 ms\n",
      "Wall time: 11.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727141217.755256 3948946 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41cace80-7a4b-4929-8e63-9c83f9745e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727141235.787909 3948707 service.cc:146] XLA service 0x7fbfe00d63e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727141235.787940 3948707 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787945 3948707 service.cc:154]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787950 3948707 service.cc:154]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787953 3948707 service.cc:154]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787958 3948707 service.cc:154]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787962 3948707 service.cc:154]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787967 3948707 service.cc:154]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787972 3948707 service.cc:154]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787977 3948707 service.cc:154]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787980 3948707 service.cc:154]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787984 3948707 service.cc:154]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787989 3948707 service.cc:154]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787993 3948707 service.cc:154]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.787998 3948707 service.cc:154]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.788003 3948707 service.cc:154]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141235.788008 3948707 service.cc:154]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-24 01:27:15.859527: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-24 01:27:16.355851: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-24 01:27:17.524127: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[4.7788864E-5, 3.036927E-4, 7.026324E-5, 1.772748E-4, 4.5683286E-5, 1.9182988E-4, 9.988368E-6, 7.264478E-5, 1.4183694...|\n",
      "|[1.2047288E-5, 2.4665435E-4, 2.3863144E-4, 1.9301432E-4, 1.5375564E-4, 4.5055505E-5, 2.220773E-5, 3.791191E-4, 1.5702...|\n",
      "|[1.3302326E-4, 2.696228E-4, 5.517897E-5, 9.9901976E-5, 4.7618698E-5, 4.4045786E-4, 6.8055174E-6, 3.486012E-5, 1.26733...|\n",
      "|[1.5190376E-5, 2.9297185E-4, 1.17424854E-4, 8.6468535E-5, 7.027255E-5, 7.291867E-5, 1.1590379E-5, 2.905424E-4, 1.7357...|\n",
      "|[1.1257283E-4, 2.5857892E-4, 5.5297343E-5, 1.0446069E-4, 4.6776848E-5, 3.4146357E-4, 6.6849643E-6, 3.6820922E-5, 1.15...|\n",
      "|[9.95129E-5, 3.513081E-4, 9.309831E-5, 1.4611095E-4, 7.243498E-5, 2.7604023E-4, 1.3097427E-5, 1.0884549E-4, 2.2091297...|\n",
      "|[9.426697E-5, 3.7797264E-4, 1.889081E-4, 3.017484E-4, 1.1807096E-4, 2.825622E-4, 1.970623E-5, 1.1764238E-4, 1.8083643...|\n",
      "|[1.2302614E-4, 2.2465072E-4, 3.0343583E-5, 9.0339316E-5, 2.819704E-5, 4.4976934E-4, 3.189744E-6, 2.624859E-5, 9.48956...|\n",
      "|[1.1142831E-4, 2.504624E-4, 4.6369034E-5, 1.0202974E-4, 3.9002465E-5, 3.5218574E-4, 5.2744895E-6, 3.2696487E-5, 1.100...|\n",
      "|[5.0597966E-5, 2.834586E-4, 1.2132926E-4, 1.9169123E-4, 9.219973E-5, 2.0994889E-4, 1.0187929E-5, 1.3009128E-4, 1.7364...|\n",
      "|[8.3086015E-5, 2.8279284E-4, 1.3492702E-4, 2.208303E-4, 9.525056E-5, 2.375283E-4, 1.6205138E-5, 1.00991216E-4, 1.4331...|\n",
      "|[1.15561685E-4, 2.5343124E-4, 3.9419767E-5, 8.738221E-5, 3.43671E-5, 4.1973148E-4, 5.474829E-6, 2.7518814E-5, 1.27988...|\n",
      "|[7.8735575E-5, 2.843643E-4, 9.4464434E-5, 2.909338E-4, 1.0374696E-4, 2.0492346E-4, 7.027104E-6, 1.0258028E-4, 9.28546...|\n",
      "|[1.3040153E-4, 2.925545E-4, 7.7841185E-5, 1.5847E-4, 6.818609E-5, 3.9240666E-4, 1.3796494E-5, 4.6808407E-5, 1.8040277...|\n",
      "|[1.0765981E-4, 2.2286251E-4, 4.466443E-5, 8.856087E-5, 3.559462E-5, 3.5881315E-4, 3.6300344E-6, 3.8859125E-5, 8.36635...|\n",
      "|[6.4850945E-5, 2.836782E-4, 1.6979409E-4, 2.524894E-4, 1.1747874E-4, 3.016754E-4, 1.5257171E-5, 1.3339268E-4, 1.34892...|\n",
      "|[3.262807E-5, 3.9011642E-4, 5.610781E-5, 9.1521484E-5, 8.91793E-5, 1.8981296E-4, 1.6347147E-5, 1.3983177E-4, 1.212782...|\n",
      "|[1.11893285E-4, 2.7323118E-4, 4.9729966E-5, 9.237238E-5, 3.5741083E-5, 3.6771223E-4, 6.1541077E-6, 3.7560138E-5, 9.64...|\n",
      "|[1.15863666E-4, 9.872305E-4, 1.2683612E-4, 2.8349645E-4, 1.247385E-4, 3.3857307E-4, 7.44898E-5, 1.4036038E-4, 5.81837...|\n",
      "|[5.5262528E-5, 2.714447E-4, 2.1939904E-4, 3.41609E-4, 1.2830946E-4, 1.6681952E-4, 1.8766756E-5, 1.1253764E-4, 1.17077...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 45.9 ms, sys: 34.3 ms, total: 80.2 ms\n",
      "Wall time: 10.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727141237.865103 3948707 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(\"data\").alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a2ec8a-de09-4d7c-9666-1b3c76f10657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 01:27:34.143820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:27:34.161243: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:27:34.166472: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:27:34.178907: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:27:34.911873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:27:41.293232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22721 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.294646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 29281 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.295859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 29281 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.297112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 29281 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.298357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 29281 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.299597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 29281 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.300820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 29281 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.302094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 29281 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.303331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 29281 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.304542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 29281 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.305718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 29281 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.306927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 29281 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.308186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 29281 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.309366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 29281 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.310487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 29281 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:41.311746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 29281 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:48.211718: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 01:27:48.230075: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 01:27:48.235697: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 01:27:48.249448: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 01:27:48.982478: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-09-24 01:27:55.683585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22157 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.685109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 28973 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.686400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 28973 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.687619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 28973 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.688836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 28973 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.690058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 28973 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.691303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 28973 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.692502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 28973 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.693751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 28973 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.694938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 28973 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.696115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 28973 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.697236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 28973 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.698417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 28973 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.699570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 28973 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.700742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 28973 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2024-09-24 01:27:55.701930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 28973 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:e7:00.0, compute capability: 7.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727141280.157861 3951325 service.cc:146] XLA service 0x7fbfd81575d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727141280.157890 3951325 service.cc:154]   StreamExecutor device (0): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157894 3951325 service.cc:154]   StreamExecutor device (1): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157898 3951325 service.cc:154]   StreamExecutor device (2): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157903 3951325 service.cc:154]   StreamExecutor device (3): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157907 3951325 service.cc:154]   StreamExecutor device (4): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157912 3951325 service.cc:154]   StreamExecutor device (5): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157917 3951325 service.cc:154]   StreamExecutor device (6): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157922 3951325 service.cc:154]   StreamExecutor device (7): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157927 3951325 service.cc:154]   StreamExecutor device (8): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157932 3951325 service.cc:154]   StreamExecutor device (9): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157936 3951325 service.cc:154]   StreamExecutor device (10): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157940 3951325 service.cc:154]   StreamExecutor device (11): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157942 3951325 service.cc:154]   StreamExecutor device (12): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157945 3951325 service.cc:154]   StreamExecutor device (13): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157950 3951325 service.cc:154]   StreamExecutor device (14): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "I0000 00:00:1727141280.157953 3951325 service.cc:154]   StreamExecutor device (15): Tesla V100-SXM3-32GB-H, Compute Capability 7.0\n",
      "2024-09-24 01:28:00.229059: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-24 01:28:00.715355: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-24 01:28:01.964449: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1727141282.302091 3951325 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 178 ms, sys: 173 ms, total: 351 ms\n",
      "Wall time: 43.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(col(\"data\")).alias(\"prediction\"))\n",
    "predictions.write.mode(\"overwrite\").parquet(output_file_path + \"_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa48e9-2eda-4d57-8174-8850e5bca4af",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2605d134-ef75-4d94-9b16-2c6d85f29bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4666e618-8038-4dc5-9be7-793aedbf4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models/resnet50/1\n",
    "cp -r resnet50_model models/resnet50/1/model.savedmodel\n",
    "\n",
    "# add config.pbtxt\n",
    "cp models_config/resnet50/config.pbtxt models/resnet50/config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f1d6d-334e-4f85-9472-171dda09bae4",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c8c0744-0558-4dac-bbfe-8bdde4b2af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> starting triton: a13519cbf860                                  (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07365c-0a14-49b3-9bd8-cfb35f48b089",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcd46360-6851-4a9d-8590-c086e001242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool_),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            inputs = inputs * (2. / 255) - 1  # add normalization\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fabcaeb-5a44-42bb-8097-5dbc2d0cee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "classify = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"resnet50\"),\n",
    "                             input_tensor_shapes=[[224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b17f33c8-a0f0-4bce-91f8-5838ba9b12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e5b9e99-a1cf-43d3-a795-c7271a917057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e595473d-1a5d-46a6-a6ba-89d2ea903de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[4.7788824E-5, 3.0369216E-4, 7.026308E-5, 1.772744E-4, 4.5683184E-5, 1.9182982E-4, 9.988331E-6, 7.264462E-5, 1.418365...|\n",
      "|[1.2047234E-5, 2.466537E-4, 2.3863082E-4, 1.9301384E-4, 1.5375504E-4, 4.5055393E-5, 2.2207663E-5, 3.7911904E-4, 1.570...|\n",
      "|[1.3302344E-4, 2.6962307E-4, 5.5178945E-5, 9.990197E-5, 4.761874E-5, 4.4045786E-4, 6.8055238E-6, 3.486012E-5, 1.26733...|\n",
      "|[1.5190398E-5, 2.92972E-4, 1.17424854E-4, 8.6468666E-5, 7.0272654E-5, 7.291892E-5, 1.1590384E-5, 2.9054214E-4, 1.7357...|\n",
      "|[1.12572874E-4, 2.5857877E-4, 5.529736E-5, 1.04460785E-4, 4.6776888E-5, 3.4146404E-4, 6.684954E-6, 3.6820937E-5, 1.15...|\n",
      "|[9.9512836E-5, 3.5130794E-4, 9.309811E-5, 1.4611086E-4, 7.2434916E-5, 2.7604034E-4, 1.3097388E-5, 1.0884527E-4, 2.209...|\n",
      "|[9.426699E-5, 3.779725E-4, 1.8890815E-4, 3.01748E-4, 1.1807092E-4, 2.8256248E-4, 1.9706224E-5, 1.1764218E-4, 1.808362...|\n",
      "|[1.2302597E-4, 2.2465063E-4, 3.034353E-5, 9.033919E-5, 2.8197015E-5, 4.49769E-4, 3.1897443E-6, 2.6248545E-5, 9.489563...|\n",
      "|[1.1142843E-4, 2.504622E-4, 4.636911E-5, 1.020298E-4, 3.900249E-5, 3.5218577E-4, 5.274493E-6, 3.2696444E-5, 1.1008336...|\n",
      "|[5.0598002E-5, 2.834589E-4, 1.21329285E-4, 1.9169108E-4, 9.21997E-5, 2.0994882E-4, 1.01879305E-5, 1.3009131E-4, 1.736...|\n",
      "|[8.308601E-5, 2.8279284E-4, 1.3492708E-4, 2.2083039E-4, 9.525064E-5, 2.375285E-4, 1.6205127E-5, 1.0099106E-4, 1.43311...|\n",
      "|[1.1556177E-4, 2.5343124E-4, 3.941981E-5, 8.738222E-5, 3.436714E-5, 4.1973195E-4, 5.4748407E-6, 2.7518845E-5, 1.27988...|\n",
      "|[7.873544E-5, 2.8436392E-4, 9.446445E-5, 2.9093394E-4, 1.0374692E-4, 2.0492339E-4, 7.0270744E-6, 1.02580045E-4, 9.285...|\n",
      "|[1.3040159E-4, 2.9255447E-4, 7.784111E-5, 1.5846998E-4, 6.8186026E-5, 3.92407E-4, 1.3796482E-5, 4.6808313E-5, 1.80402...|\n",
      "|[1.076596E-4, 2.2286206E-4, 4.4664303E-5, 8.856074E-5, 3.5594552E-5, 3.5881266E-4, 3.6300135E-6, 3.8858976E-5, 8.3663...|\n",
      "|[6.485096E-5, 2.8367812E-4, 1.697941E-4, 2.5248944E-4, 1.17478696E-4, 3.016753E-4, 1.5257165E-5, 1.3339291E-4, 1.3489...|\n",
      "|[3.262806E-5, 3.9011682E-4, 5.6107754E-5, 9.152158E-5, 8.917932E-5, 1.898128E-4, 1.6347141E-5, 1.3983184E-4, 1.212782...|\n",
      "|[1.1189317E-4, 2.7323075E-4, 4.972989E-5, 9.2372145E-5, 3.574101E-5, 3.67712E-4, 6.1540945E-6, 3.756006E-5, 9.642578E...|\n",
      "|[1.1586359E-4, 9.872313E-4, 1.2683592E-4, 2.8349628E-4, 1.2473829E-4, 3.385727E-4, 7.448961E-5, 1.403603E-4, 5.818369...|\n",
      "|[5.5262408E-5, 2.7144453E-4, 2.1939877E-4, 3.416088E-4, 1.283092E-4, 1.6681956E-4, 1.876669E-5, 1.12537404E-4, 1.1707...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 21.7 ms, sys: 23.2 ms, total: 44.9 ms\n",
      "Wall time: 5.39 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f66d468-e0b1-4589-8606-b3848063a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[4.7788824E-5, 3.0369216E-4, 7.026308E-5, 1.772744E-4, 4.5683184E-5, 1.9182982E-4, 9.988331E-6, 7.264462E-5, 1.418365...|\n",
      "|[1.2047234E-5, 2.466537E-4, 2.3863082E-4, 1.9301384E-4, 1.5375504E-4, 4.5055393E-5, 2.2207663E-5, 3.7911904E-4, 1.570...|\n",
      "|[1.3302344E-4, 2.6962307E-4, 5.5178945E-5, 9.990197E-5, 4.761874E-5, 4.4045786E-4, 6.8055238E-6, 3.486012E-5, 1.26733...|\n",
      "|[1.5190398E-5, 2.92972E-4, 1.17424854E-4, 8.6468666E-5, 7.0272654E-5, 7.291892E-5, 1.1590384E-5, 2.9054214E-4, 1.7357...|\n",
      "|[1.12572874E-4, 2.5857877E-4, 5.529736E-5, 1.04460785E-4, 4.6776888E-5, 3.4146404E-4, 6.684954E-6, 3.6820937E-5, 1.15...|\n",
      "|[9.9512836E-5, 3.5130794E-4, 9.309811E-5, 1.4611086E-4, 7.2434916E-5, 2.7604034E-4, 1.3097388E-5, 1.0884527E-4, 2.209...|\n",
      "|[9.426699E-5, 3.779725E-4, 1.8890815E-4, 3.01748E-4, 1.1807092E-4, 2.8256248E-4, 1.9706224E-5, 1.1764218E-4, 1.808362...|\n",
      "|[1.2302597E-4, 2.2465063E-4, 3.034353E-5, 9.033919E-5, 2.8197015E-5, 4.49769E-4, 3.1897443E-6, 2.6248545E-5, 9.489563...|\n",
      "|[1.1142843E-4, 2.504622E-4, 4.636911E-5, 1.020298E-4, 3.900249E-5, 3.5218577E-4, 5.274493E-6, 3.2696444E-5, 1.1008336...|\n",
      "|[5.0598002E-5, 2.834589E-4, 1.21329285E-4, 1.9169108E-4, 9.21997E-5, 2.0994882E-4, 1.01879305E-5, 1.3009131E-4, 1.736...|\n",
      "|[8.308601E-5, 2.8279284E-4, 1.3492708E-4, 2.2083039E-4, 9.525064E-5, 2.375285E-4, 1.6205127E-5, 1.0099106E-4, 1.43311...|\n",
      "|[1.1556177E-4, 2.5343124E-4, 3.941981E-5, 8.738222E-5, 3.436714E-5, 4.1973195E-4, 5.4748407E-6, 2.7518845E-5, 1.27988...|\n",
      "|[7.873544E-5, 2.8436392E-4, 9.446445E-5, 2.9093394E-4, 1.0374692E-4, 2.0492339E-4, 7.0270744E-6, 1.02580045E-4, 9.285...|\n",
      "|[1.3040159E-4, 2.9255447E-4, 7.784111E-5, 1.5846998E-4, 6.8186026E-5, 3.92407E-4, 1.3796482E-5, 4.6808313E-5, 1.80402...|\n",
      "|[1.076596E-4, 2.2286206E-4, 4.4664303E-5, 8.856074E-5, 3.5594552E-5, 3.5881266E-4, 3.6300135E-6, 3.8858976E-5, 8.3663...|\n",
      "|[6.485096E-5, 2.8367812E-4, 1.697941E-4, 2.5248944E-4, 1.17478696E-4, 3.016753E-4, 1.5257165E-5, 1.3339291E-4, 1.3489...|\n",
      "|[3.262806E-5, 3.9011682E-4, 5.6107754E-5, 9.152158E-5, 8.917932E-5, 1.898128E-4, 1.6347141E-5, 1.3983184E-4, 1.212782...|\n",
      "|[1.1189317E-4, 2.7323075E-4, 4.972989E-5, 9.2372145E-5, 3.574101E-5, 3.67712E-4, 6.1540945E-6, 3.756006E-5, 9.642578E...|\n",
      "|[1.1586359E-4, 9.872313E-4, 1.2683592E-4, 2.8349628E-4, 1.2473829E-4, 3.385727E-4, 7.448961E-5, 1.403603E-4, 5.818369...|\n",
      "|[5.5262408E-5, 2.7144453E-4, 2.1939877E-4, 3.416088E-4, 1.283092E-4, 1.6681956E-4, 1.876669E-5, 1.12537404E-4, 1.1707...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 19 ms, sys: 18.1 ms, total: 37.1 ms\n",
      "Wall time: 4.25 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(\"data\").alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "632c4c3a-fa52-4c3d-b71e-7526286e353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 125 ms, sys: 84.5 ms, total: 209 ms\n",
      "Wall time: 29.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(col(\"data\")).alias(\"prediction\"))\n",
    "predictions.write.mode(\"overwrite\").parquet(output_file_path + \"_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc06b7e-f750-40b5-9208-a035db11d937",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbfcaa51-3b9f-43ff-a4a8-4b46766115b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> stopping containers: ['a13519cbf860']\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d88639b-d934-4eb4-ae2f-cc13b9b10456",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8cc28a-34d7-479c-be7e-9a380d39e25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
