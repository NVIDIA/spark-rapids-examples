{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6810cc-5982-4293-bfbd-c91ef0aca204",
   "metadata": {},
   "source": [
    "# Distributed model inference using TensorFlow Keras\n",
    "From: https://docs.databricks.com/_static/notebooks/deep-learning/keras-metadata.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e3a8d",
   "metadata": {},
   "source": [
    "### Using TensorFlow\n",
    "Note that cuFFT/cuDNN/cuBLAS registration errors are expected with `tf=2.17.0` and will not affect behavior, as noted in [this issue.](https://github.com/tensorflow/tensorflow/issues/62075)  \n",
    "This notebook does not demonstrate inference with TensorRT, as [TF-TRT](https://docs.nvidia.com/deeplearning/tensorrt/release-notes/index.html#tensorrt-10) does not yet support `tf=2.17.0`. See the `pytorch` notebooks for TensorRT demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf329ac8-0763-44bc-b0f6-b634b7dc480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 17:41:30.112764: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-03 17:41:30.119504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-03 17:41:30.126948: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-03 17:41:30.129111: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-03 17:41:30.134946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-03 17:41:30.497048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import uuid\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    " \n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d72768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "conda_env = os.environ.get(\"CONDA_PREFIX\")\n",
    "\n",
    "conf = SparkConf()\n",
    "if 'spark' not in globals():\n",
    "    # If Spark is not already started with Jupyter, attach to Spark Standalone\n",
    "    import socket\n",
    "    hostname = socket.gethostname()\n",
    "    conf.setMaster(f\"spark://{hostname}:7077\") # assuming Master is on default port 7077\n",
    "conf.set(\"spark.task.maxFailures\", \"1\")\n",
    "conf.set(\"spark.driver.memory\", \"8g\")\n",
    "conf.set(\"spark.executor.memory\", \"8g\")\n",
    "conf.set(\"spark.pyspark.python\", f\"{conda_env}/bin/python\")\n",
    "conf.set(\"spark.pyspark.driver.python\", f\"{conda_env}/bin/python\")\n",
    "conf.set(\"spark.sql.execution.pyspark.udf.simplifiedTraceback.enabled\", \"false\")\n",
    "conf.set(\"spark.sql.pyspark.jvmStacktrace.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "conf.set(\"spark.python.worker.reuse\", \"true\")\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"spark-dl-examples\").config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "833e36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950b0470-a21e-4778-a80e-b8f6ef792dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"image_data.parquet\"\n",
    "output_file_path = \"predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d08a7-66b9-444f-b362-d8df692aef1c",
   "metadata": {},
   "source": [
    "### Prepare trained model and data for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da083168-137f-492c-8769-d8f1e2111756",
   "metadata": {},
   "source": [
    "Load the ResNet-50 Model and broadcast the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddc715a-cdbc-4c49-93e9-58c9d88511da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 17:41:32.482802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45311 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50()\n",
    "bc_model_weights = sc.broadcast(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dddfa3-e8df-4e8e-8251-64457f1ebf80",
   "metadata": {},
   "source": [
    "Load the data and save the datasets to one Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0738bec-97d4-4946-8c49-5e6d07ff1afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "\u001b[1m228813984/228813984\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014644f4-2a45-4474-8afb-0daf90043253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54f470a-d308-4426-8ed0-33f95155bb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(data_dir) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "files = files[:2048]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd883dc0-4846-4411-a4d6-4f5f252ac707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rishic/.keras/datasets/flower_photos\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f94ee0-f1ea-47f6-a77e-be8da5d1b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "for file in files:\n",
    "    img = Image.open(file)\n",
    "    img = img.resize([224, 224])\n",
    "    data = np.asarray(img, dtype=\"float32\").reshape([224*224*3])\n",
    "\n",
    "    image_data.append({\"data\": data})\n",
    "\n",
    "pandas_df = pd.DataFrame(image_data, columns=['data'])\n",
    "pandas_df.to_parquet(file_name)\n",
    "# os.makedirs(dbfs_file_path)\n",
    "# shutil.copyfile(file_name, dbfs_file_path+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2414b0f-58f2-4e4a-9d09-8ea95b38d413",
   "metadata": {},
   "source": [
    "### Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670328e3-7274-4d78-b315-487750166a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\"rm -rf resnet50_model\".split())\n",
    "model.export(\"resnet50_model\", verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827ad56-1af0-41b7-be68-94bd203a2a70",
   "metadata": {},
   "source": [
    "### Load the data into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ddc22d0-b88a-4906-bd47-bf247e34feeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "df = spark.read.parquet(file_name)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7adf1d9-1fa7-4456-ae32-cf7d1d43bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97173c07-a96e-4262-b60f-82865b997e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert len(df.head()) > 0, \"`df` should not be empty\" # This line will fail if the vectorized reader runs out of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865929b0-b016-4de4-996d-7f16176cf49c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model inference via pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67b3128-13c1-44f1-a0c0-7cf7a836fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image_data):\n",
    "    image = tf.image.convert_image_dtype(\n",
    "        image_data, dtype=tf.float32) * (2. / 255) - 1\n",
    "    image = tf.reshape(image, [224, 224, 3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b33185f-6d1e-4ca9-9757-fdc3d736496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishic/anaconda3/envs/spark-dl-tf/lib/python3.11/site-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(ArrayType(FloatType()), PandasUDFType.SCALAR_ITER)\n",
    "def predict_batch_udf(image_batch_iter):\n",
    "\n",
    "    # Enable GPU memory growth to avoid CUDA OOM\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    batch_size = 64\n",
    "    model = ResNet50(weights=None)\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    for image_batch in image_batch_iter:\n",
    "        images = np.vstack(image_batch)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "        dataset = dataset.map(parse_image, num_parallel_calls=8).prefetch(\n",
    "            5000).batch(batch_size)\n",
    "        preds = model.predict(dataset)\n",
    "        yield pd.Series(list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad8c05da-db38-45ef-81d0-1f862f575ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.2938889E-4, 2.4666305E-4, 6.765791E-5, 1.2263245E-4, 5.7486624E-5, 3.9616702E-4, 7.0566134E-6, 4.1722178E-5, 1.225...|\n",
      "|[4.4501914E-5, 3.5403698E-4, 4.6702033E-5, 8.102543E-5, 3.1704556E-5, 1.9194305E-4, 7.905952E-6, 1.3744082E-4, 1.9563...|\n",
      "|[1.05672516E-4, 2.2686279E-4, 3.0055395E-5, 6.523785E-5, 2.352077E-5, 3.7122983E-4, 3.3315896E-6, 2.2584054E-5, 9.775...|\n",
      "|[2.0331638E-5, 2.2746396E-4, 7.828012E-5, 6.986782E-5, 4.705316E-5, 9.80732E-5, 5.561918E-6, 2.3519044E-4, 1.3803913E...|\n",
      "|[1.130241E-4, 2.3187004E-4, 5.296914E-5, 1.0871329E-4, 4.027478E-5, 3.7183522E-4, 5.5931855E-6, 3.4792112E-5, 1.14155...|\n",
      "|[9.094467E-5, 2.06384E-4, 4.514821E-5, 7.665891E-5, 3.2262324E-5, 3.3875552E-4, 3.831814E-6, 4.1848412E-5, 9.94389E-6...|\n",
      "|[1.07847634E-4, 3.7848807E-4, 7.660533E-5, 1.2446754E-4, 4.7595917E-5, 3.333814E-4, 1.0669675E-5, 9.133265E-5, 1.8015...|\n",
      "|[2.2261223E-5, 2.734666E-4, 3.8122747E-5, 6.2266954E-5, 1.7935155E-5, 1.7268128E-4, 6.034271E-6, 1.06450585E-4, 1.789...|\n",
      "|[1.1065645E-4, 2.900581E-4, 4.2585547E-5, 1.074203E-4, 3.052314E-5, 4.794604E-4, 6.4872897E-6, 3.646897E-5, 1.3717402...|\n",
      "|[9.673917E-5, 2.058331E-4, 7.4652424E-5, 1.1323769E-4, 4.6106186E-5, 2.8604185E-4, 5.62365E-6, 5.471466E-5, 9.664386E...|\n",
      "|[7.411196E-5, 3.291524E-4, 1.3454164E-4, 1.7738447E-4, 8.467504E-5, 2.2466244E-4, 1.3621126E-5, 1.1778668E-4, 1.83372...|\n",
      "|[8.721524E-5, 2.7338538E-4, 3.5964815E-5, 7.792533E-5, 2.3559302E-5, 3.6789547E-4, 3.5665628E-6, 3.648153E-5, 1.07589...|\n",
      "|[9.723709E-5, 2.7619812E-4, 5.7464153E-5, 1.10104906E-4, 3.8317143E-5, 3.490506E-4, 6.1553183E-6, 4.413095E-5, 1.1236...|\n",
      "|[6.940235E-5, 2.5377885E-4, 5.057188E-5, 1.1485363E-4, 3.0059196E-5, 2.7862669E-4, 5.024019E-6, 5.1511077E-5, 1.16149...|\n",
      "|[4.2095784E-5, 2.4891715E-4, 1.236292E-4, 1.4306813E-4, 7.3354306E-5, 1.6047148E-4, 7.958807E-6, 1.3556339E-4, 1.4698...|\n",
      "|[2.7327887E-5, 3.8553146E-4, 1.2939748E-4, 1.5762268E-4, 7.307493E-5, 8.5530424E-5, 1.2648808E-5, 1.9154618E-4, 2.307...|\n",
      "|[3.036101E-5, 3.5572305E-4, 1.600718E-4, 2.1437313E-4, 8.063033E-5, 1.02061334E-4, 1.3876456E-5, 1.561292E-4, 1.63637...|\n",
      "|[3.3109587E-5, 2.8182982E-4, 1.7998899E-4, 2.0246049E-4, 1.3720036E-4, 1.01000114E-4, 3.427488E-5, 3.887249E-4, 3.189...|\n",
      "|[4.549448E-5, 2.8782588E-4, 2.3703449E-4, 2.448979E-4, 1.20997625E-4, 1.3744453E-4, 1.62803E-5, 2.2094708E-4, 1.56962...|\n",
      "|[1.2242574E-4, 2.8095162E-4, 6.332559E-5, 1.0209269E-4, 4.335324E-5, 3.906304E-4, 8.205706E-6, 6.202823E-5, 1.5312888...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 10.8 ms, sys: 4.93 ms, total: 15.7 ms\n",
      "Wall time: 9.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_df = df.select(predict_batch_udf(col(\"data\")).alias(\"prediction\"))\n",
    "predictions_df.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40799f8e-443e-40ca-919b-391f901cb3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.96 ms, sys: 3.32 ms, total: 13.3 ms\n",
      "Wall time: 14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_df.write.mode(\"overwrite\").parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16726357-65d8-4d3d-aea1-6800101741cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model inference using Spark DL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6af27b2-ddc0-42ee-94cc-9ba5ffee6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import struct, col\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dda88b46-6300-4bf7-bc10-7403f4fbbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_fn():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "    # Enable GPU memory growth\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    model = ResNet50()\n",
    "    def predict(inputs):\n",
    "        inputs = inputs * (2. / 255) - 1\n",
    "        return model.predict(inputs)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cff0e851-563d-40b6-9d05-509c22b3b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = predict_batch_udf(predict_batch_fn,\n",
    "                             input_tensor_shapes=[[224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f733c38b-867d-48c1-b9a6-74a931561896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa7c156f-e2b3-4837-9427-ccf3a5720412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80bc50ad-eaf5-4fce-a354-5e17d65e2da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.296447E-4, 2.465122E-4, 6.7463385E-5, 1.2231144E-4, 5.731739E-5, 3.9644213E-4, 7.0297688E-6, 4.1668914E-5, 1.22212...|\n",
      "|[4.4481887E-5, 3.526653E-4, 4.683818E-5, 8.1168495E-5, 3.178377E-5, 1.9188467E-4, 7.885617E-6, 1.3758946E-4, 1.956621...|\n",
      "|[1.05946536E-4, 2.2744355E-4, 3.0219735E-5, 6.548672E-5, 2.3649674E-5, 3.7177472E-4, 3.353236E-6, 2.271976E-5, 9.8115...|\n",
      "|[2.0392703E-5, 2.2817637E-4, 7.840744E-5, 6.9875685E-5, 4.702542E-5, 9.8244425E-5, 5.5829764E-6, 2.3530141E-4, 1.3836...|\n",
      "|[1.1312391E-4, 2.31244E-4, 5.279228E-5, 1.0859927E-4, 4.0202678E-5, 3.721753E-4, 5.563934E-6, 3.4674114E-5, 1.1389492...|\n",
      "|[9.126345E-5, 2.0679034E-4, 4.5165678E-5, 7.679106E-5, 3.234611E-5, 3.3994843E-4, 3.84E-6, 4.1930372E-5, 9.949454E-6,...|\n",
      "|[1.07930486E-4, 3.7741542E-4, 7.613175E-5, 1.2414041E-4, 4.7409427E-5, 3.332554E-4, 1.05853915E-5, 9.1026224E-5, 1.79...|\n",
      "|[2.2216762E-5, 2.7354853E-4, 3.8192928E-5, 6.2340725E-5, 1.7952003E-5, 1.7253387E-4, 6.020507E-6, 1.0669143E-4, 1.786...|\n",
      "|[1.10480236E-4, 2.89734E-4, 4.239379E-5, 1.0727814E-4, 3.047985E-5, 4.7992737E-4, 6.4530495E-6, 3.6428817E-5, 1.36967...|\n",
      "|[9.6864875E-5, 2.0573521E-4, 7.4498465E-5, 1.1323085E-4, 4.6088306E-5, 2.8680824E-4, 5.604823E-6, 5.461046E-5, 9.6629...|\n",
      "|[7.4198484E-5, 3.2886668E-4, 1.3441108E-4, 1.7755068E-4, 8.469927E-5, 2.2534095E-4, 1.3617541E-5, 1.1781904E-4, 1.833...|\n",
      "|[8.7561886E-5, 2.7312653E-4, 3.5959012E-5, 7.7946424E-5, 2.3565723E-5, 3.6881721E-4, 3.5630535E-6, 3.642736E-5, 1.074...|\n",
      "|[9.743975E-5, 2.7615853E-4, 5.74148E-5, 1.10329434E-4, 3.83045E-5, 3.500394E-4, 6.167429E-6, 4.4207005E-5, 1.1250093E...|\n",
      "|[6.9320704E-5, 2.53287E-4, 5.0612853E-5, 1.14936556E-4, 3.0210098E-5, 2.7870742E-4, 5.031114E-6, 5.169024E-5, 1.16021...|\n",
      "|[4.2203726E-5, 2.4911022E-4, 1.2378568E-4, 1.4274308E-4, 7.32259E-5, 1.6058519E-4, 7.9425035E-6, 1.3519496E-4, 1.4662...|\n",
      "|[2.7190901E-5, 3.8381666E-4, 1.2918573E-4, 1.570463E-4, 7.310112E-5, 8.554618E-5, 1.2614603E-5, 1.9213595E-4, 2.30354...|\n",
      "|[3.0573912E-5, 3.5561546E-4, 1.5945674E-4, 2.1361349E-4, 8.046549E-5, 1.0269262E-4, 1.3862439E-5, 1.5622783E-4, 1.638...|\n",
      "|[3.3117096E-5, 2.8073433E-4, 1.7961214E-4, 2.020287E-4, 1.3662946E-4, 1.0117796E-4, 3.4090703E-5, 3.8897162E-4, 3.181...|\n",
      "|[4.5728237E-5, 2.8880237E-4, 2.3783019E-4, 2.4589908E-4, 1.2160292E-4, 1.3812551E-4, 1.6343482E-5, 2.2073709E-4, 1.57...|\n",
      "|[1.2280059E-4, 2.806991E-4, 6.3642765E-5, 1.02471764E-4, 4.351664E-5, 3.9150563E-4, 8.235125E-6, 6.211928E-5, 1.53269...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 8.12 ms, sys: 3.38 ms, total: 11.5 ms\n",
      "Wall time: 5.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41cace80-7a4b-4929-8e63-9c83f9745e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.293178E-4, 2.4644283E-4, 6.760039E-5, 1.2260793E-4, 5.7431564E-5, 3.9597694E-4, 7.0522524E-6, 4.1717416E-5, 1.2240...|\n",
      "|[4.4487308E-5, 3.5378174E-4, 4.6667028E-5, 8.102564E-5, 3.168566E-5, 1.9189132E-4, 7.903805E-6, 1.3741471E-4, 1.95482...|\n",
      "|[1.0566196E-4, 2.2684377E-4, 3.00564E-5, 6.5251304E-5, 2.3520754E-5, 3.7116173E-4, 3.331476E-6, 2.2584616E-5, 9.77515...|\n",
      "|[2.0337258E-5, 2.2749524E-4, 7.8351426E-5, 6.991163E-5, 4.7081656E-5, 9.8092445E-5, 5.564894E-6, 2.3517481E-4, 1.3805...|\n",
      "|[1.12979564E-4, 2.3172122E-4, 5.2946547E-5, 1.0876398E-4, 4.0259067E-5, 3.7143996E-4, 5.5940513E-6, 3.4814777E-5, 1.1...|\n",
      "|[9.093228E-5, 2.0639994E-4, 4.5151268E-5, 7.666316E-5, 3.2264295E-5, 3.387436E-4, 3.832487E-6, 4.185193E-5, 9.944773E...|\n",
      "|[1.0783461E-4, 3.7850672E-4, 7.660902E-5, 1.2446321E-4, 4.7591406E-5, 3.3328883E-4, 1.067249E-5, 9.131178E-5, 1.80121...|\n",
      "|[2.2258617E-5, 2.7345872E-4, 3.814439E-5, 6.229726E-5, 1.79387E-5, 1.7259057E-4, 6.0371217E-6, 1.0649798E-4, 1.789726...|\n",
      "|[1.1067773E-4, 2.8997674E-4, 4.2570035E-5, 1.0747747E-4, 3.0524247E-5, 4.7921995E-4, 6.489833E-6, 3.6502548E-5, 1.371...|\n",
      "|[9.676251E-5, 2.0588847E-4, 7.467098E-5, 1.1326933E-4, 4.6123736E-5, 2.8609246E-4, 5.627118E-6, 5.4726373E-5, 9.66839...|\n",
      "|[7.4104944E-5, 3.290917E-4, 1.3448784E-4, 1.7742367E-4, 8.463227E-5, 2.2462371E-4, 1.3614881E-5, 1.17794625E-4, 1.833...|\n",
      "|[8.7211796E-5, 2.7337394E-4, 3.5953894E-5, 7.7924225E-5, 2.3554327E-5, 3.67775E-4, 3.5652213E-6, 3.647724E-5, 1.07577...|\n",
      "|[9.7237185E-5, 2.762026E-4, 5.7450008E-5, 1.1019135E-4, 3.831896E-5, 3.4878452E-4, 6.1574788E-6, 4.415526E-5, 1.12374...|\n",
      "|[6.938849E-5, 2.5376282E-4, 5.0565883E-5, 1.14880335E-4, 3.0061366E-5, 2.7866007E-4, 5.024482E-6, 5.152425E-5, 1.1617...|\n",
      "|[4.2096388E-5, 2.4889092E-4, 1.2363133E-4, 1.4304162E-4, 7.337785E-5, 1.6042824E-4, 7.959722E-6, 1.3552785E-4, 1.4693...|\n",
      "|[2.730248E-5, 3.851789E-4, 1.293143E-4, 1.5753493E-4, 7.302161E-5, 8.547956E-5, 1.26348905E-5, 1.9148648E-4, 2.304900...|\n",
      "|[3.0354899E-5, 3.5562844E-4, 1.6008675E-4, 2.1440513E-4, 8.062159E-5, 1.02023136E-4, 1.3876455E-5, 1.5611007E-4, 1.63...|\n",
      "|[3.3083066E-5, 2.8158593E-4, 1.7979987E-4, 2.0232225E-4, 1.3704685E-4, 1.0091762E-4, 3.4243407E-5, 3.8870922E-4, 3.18...|\n",
      "|[4.5485373E-5, 2.878148E-4, 2.3707838E-4, 2.4493985E-4, 1.21028905E-4, 1.3738636E-4, 1.6280053E-5, 2.2104722E-4, 1.56...|\n",
      "|[1.22468E-4, 2.809503E-4, 6.3342835E-5, 1.021957E-4, 4.3373006E-5, 3.905496E-4, 8.212427E-6, 6.2081075E-5, 1.5323925E...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2.75 ms, sys: 3.03 ms, total: 5.78 ms\n",
      "Wall time: 4.79 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(\"data\").alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a2ec8a-de09-4d7c-9666-1b3c76f10657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 ms, sys: 4.25 ms, total: 14.9 ms\n",
      "Wall time: 16.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(col(\"data\")).alias(\"prediction\"))\n",
    "predictions.write.mode(\"overwrite\").parquet(output_file_path + \"_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa48e9-2eda-4d57-8174-8850e5bca4af",
   "metadata": {},
   "source": [
    "### Using Triton Inference Server\n",
    "\n",
    "Note: you can restart the kernel and run from this point to simulate running in a different node or environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2605d134-ef75-4d94-9b16-2c6d85f29bef",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4666e618-8038-4dc5-9be7-793aedbf4500",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# copy model to expected layout for Triton\n",
    "rm -rf models\n",
    "mkdir -p models/resnet50/1\n",
    "cp -r resnet50_model models/resnet50/1/model.savedmodel\n",
    "\n",
    "# add config.pbtxt\n",
    "cp models_config/resnet50/config.pbtxt models/resnet50/config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f1d6d-334e-4f85-9472-171dda09bae4",
   "metadata": {},
   "source": [
    "#### Start Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c8c0744-0558-4dac-bbfe-8bdde4b2af2d",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_executors = 1\n",
    "triton_models_dir = \"{}/models\".format(os.getcwd())\n",
    "nodeRDD = sc.parallelize(list(range(num_executors)), num_executors)\n",
    "\n",
    "def start_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    if containers:\n",
    "        print(\">>>> containers: {}\".format([c.short_id for c in containers]))\n",
    "    else:\n",
    "        container=client.containers.run(\n",
    "            \"nvcr.io/nvidia/tritonserver:24.08-py3\", \"tritonserver --model-repository=/models\",\n",
    "            detach=True,\n",
    "            device_requests=[docker.types.DeviceRequest(device_ids=[\"0\"], capabilities=[['gpu']])],\n",
    "            name=\"spark-triton\",\n",
    "            network_mode=\"host\",\n",
    "            remove=True,\n",
    "            shm_size=\"512M\",\n",
    "            volumes={triton_models_dir: {\"bind\": \"/models\", \"mode\": \"ro\"}}\n",
    "        )\n",
    "        print(\">>>> starting triton: {}\".format(container.short_id))\n",
    "\n",
    "        # wait for triton to be running\n",
    "        time.sleep(15)\n",
    "        client = grpcclient.InferenceServerClient(\"localhost:8001\")\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            try:\n",
    "                ready = client.is_server_ready()\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(start_triton).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07365c-0a14-49b3-9bd8-cfb35f48b089",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcd46360-6851-4a9d-8590-c086e001242a",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "def triton_fn(triton_uri, model_name):\n",
    "    import numpy as np\n",
    "    import tritonclient.grpc as grpcclient\n",
    "    \n",
    "    np_types = {\n",
    "      \"BOOL\": np.dtype(np.bool_),\n",
    "      \"INT8\": np.dtype(np.int8),\n",
    "      \"INT16\": np.dtype(np.int16),\n",
    "      \"INT32\": np.dtype(np.int32),\n",
    "      \"INT64\": np.dtype(np.int64),\n",
    "      \"FP16\": np.dtype(np.float16),\n",
    "      \"FP32\": np.dtype(np.float32),\n",
    "      \"FP64\": np.dtype(np.float64),\n",
    "      \"FP64\": np.dtype(np.double),\n",
    "      \"BYTES\": np.dtype(object)\n",
    "    }\n",
    "\n",
    "    client = grpcclient.InferenceServerClient(triton_uri)\n",
    "    model_meta = client.get_model_metadata(model_name)\n",
    "    \n",
    "    def predict(inputs):\n",
    "        if isinstance(inputs, np.ndarray):\n",
    "            # single ndarray input\n",
    "            inputs = inputs * (2. / 255) - 1  # add normalization\n",
    "            request = [grpcclient.InferInput(model_meta.inputs[0].name, inputs.shape, model_meta.inputs[0].datatype)]\n",
    "            request[0].set_data_from_numpy(inputs.astype(np_types[model_meta.inputs[0].datatype]))\n",
    "        else:\n",
    "            # dict of multiple ndarray inputs\n",
    "            request = [grpcclient.InferInput(i.name, inputs[i.name].shape, i.datatype) for i in model_meta.inputs]\n",
    "            for i in request:\n",
    "                i.set_data_from_numpy(inputs[i.name()].astype(np_types[i.datatype()]))\n",
    "        \n",
    "        response = client.infer(model_name, inputs=request)\n",
    "        \n",
    "        if len(model_meta.outputs) > 1:\n",
    "            # return dictionary of numpy arrays\n",
    "            return {o.name: response.as_numpy(o.name) for o in model_meta.outputs}\n",
    "        else:\n",
    "            # return single numpy array\n",
    "            return response.as_numpy(model_meta.outputs[0].name)\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fabcaeb-5a44-42bb-8097-5dbc2d0cee3e",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "classify = predict_batch_udf(partial(triton_fn, triton_uri=\"localhost:8001\", model_name=\"resnet50\"),\n",
    "                             input_tensor_shapes=[[224, 224, 3]],\n",
    "                             return_type=ArrayType(FloatType()),\n",
    "                             batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b17f33c8-a0f0-4bce-91f8-5838ba9b12a7",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "spark.conf.set(\"spark.sql.parquet.columnarReaderBatchSize\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e5b9e99-a1cf-43d3-a795-c7271a917057",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"image_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e595473d-1a5d-46a6-a6ba-89d2ea903de9",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.2838157E-4, 2.442499E-4, 6.756602E-5, 1.223822E-4, 5.718728E-5, 3.9370774E-4, 6.9826538E-6, 4.180329E-5, 1.21474E-...|\n",
      "|[4.3975022E-5, 3.5182733E-4, 4.6756446E-5, 8.051952E-5, 3.157192E-5, 1.8915786E-4, 7.8848925E-6, 1.3820908E-4, 1.9617...|\n",
      "|[1.0483801E-4, 2.2482511E-4, 2.9800098E-5, 6.471683E-5, 2.3306355E-5, 3.6853546E-4, 3.2802545E-6, 2.2436941E-5, 9.655...|\n",
      "|[2.0184121E-5, 2.2646098E-4, 7.754879E-5, 6.9126E-5, 4.6796213E-5, 9.757494E-5, 5.5280707E-6, 2.3486002E-4, 1.3758638...|\n",
      "|[1.1207414E-4, 2.3036542E-4, 5.2748997E-5, 1.0843094E-4, 3.9970357E-5, 3.692824E-4, 5.5317682E-6, 3.467135E-5, 1.1321...|\n",
      "|[9.028466E-5, 2.0533502E-4, 4.5085282E-5, 7.65107E-5, 3.217092E-5, 3.3741904E-4, 3.8024857E-6, 4.1927728E-5, 9.920564...|\n",
      "|[1.0625615E-4, 3.759827E-4, 7.6174496E-5, 1.2342798E-4, 4.7335903E-5, 3.3091815E-4, 1.0598523E-5, 9.161089E-5, 1.7926...|\n",
      "|[2.2157477E-5, 2.726377E-4, 3.831429E-5, 6.2276886E-5, 1.8050652E-5, 1.7177712E-4, 6.0331595E-6, 1.06755506E-4, 1.790...|\n",
      "|[1.0993216E-4, 2.8824335E-4, 4.2543048E-5, 1.06903855E-4, 3.039875E-5, 4.7743318E-4, 6.441006E-6, 3.6423717E-5, 1.361...|\n",
      "|[9.6276366E-5, 2.047977E-4, 7.4698546E-5, 1.128771E-4, 4.6044628E-5, 2.8445767E-4, 5.6014956E-6, 5.475251E-5, 9.63856...|\n",
      "|[7.3160336E-5, 3.2700456E-4, 1.3447899E-4, 1.7689951E-4, 8.4440886E-5, 2.2350134E-4, 1.3515168E-5, 1.1746432E-4, 1.81...|\n",
      "|[8.632592E-5, 2.7143923E-4, 3.583003E-5, 7.763873E-5, 2.3417528E-5, 3.6477615E-4, 3.527159E-6, 3.646688E-5, 1.0721673...|\n",
      "|[9.640316E-5, 2.7391897E-4, 5.7131063E-5, 1.09568326E-4, 3.8045353E-5, 3.472495E-4, 6.057242E-6, 4.3799748E-5, 1.1118...|\n",
      "|[6.912533E-5, 2.5222785E-4, 5.0288483E-5, 1.1415517E-4, 2.9881658E-5, 2.7816373E-4, 4.972507E-6, 5.121496E-5, 1.15293...|\n",
      "|[4.189945E-5, 2.4779947E-4, 1.2303083E-4, 1.4200866E-4, 7.2787174E-5, 1.600041E-4, 7.901948E-6, 1.3503798E-4, 1.46427...|\n",
      "|[2.7033573E-5, 3.8410365E-4, 1.2880778E-4, 1.5630701E-4, 7.2431474E-5, 8.455686E-5, 1.2551222E-5, 1.9146077E-4, 2.293...|\n",
      "|[2.9902518E-5, 3.521676E-4, 1.6034822E-4, 2.1348803E-4, 8.053424E-5, 1.00774814E-4, 1.3777179E-5, 1.5595586E-4, 1.615...|\n",
      "|[3.2834323E-5, 2.8044736E-4, 1.8003663E-4, 2.017913E-4, 1.3718085E-4, 1.0062256E-4, 3.4619785E-5, 3.8973117E-4, 3.187...|\n",
      "|[4.4552748E-5, 2.8623734E-4, 2.3419394E-4, 2.4108509E-4, 1.1926766E-4, 1.3529808E-4, 1.6018543E-5, 2.210266E-4, 1.558...|\n",
      "|[1.2160183E-4, 2.8021698E-4, 6.289166E-5, 1.0147789E-4, 4.3161614E-5, 3.8964444E-4, 8.174407E-6, 6.2043844E-5, 1.5228...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 4.79 ms, sys: 1.93 ms, total: 6.72 ms\n",
      "Wall time: 3.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first pass caches model/fn\n",
    "predictions = df.select(classify(struct(\"data\")).alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f66d468-e0b1-4589-8606-b3848063a823",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                              prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "|[1.2838157E-4, 2.442499E-4, 6.756602E-5, 1.223822E-4, 5.718728E-5, 3.9370774E-4, 6.9826538E-6, 4.180329E-5, 1.21474E-...|\n",
      "|[4.3975022E-5, 3.5182733E-4, 4.6756446E-5, 8.051952E-5, 3.157192E-5, 1.8915786E-4, 7.8848925E-6, 1.3820908E-4, 1.9617...|\n",
      "|[1.0483801E-4, 2.2482511E-4, 2.9800098E-5, 6.471683E-5, 2.3306355E-5, 3.6853546E-4, 3.2802545E-6, 2.2436941E-5, 9.655...|\n",
      "|[2.0184121E-5, 2.2646098E-4, 7.754879E-5, 6.9126E-5, 4.6796213E-5, 9.757494E-5, 5.5280707E-6, 2.3486002E-4, 1.3758638...|\n",
      "|[1.1207414E-4, 2.3036542E-4, 5.2748997E-5, 1.0843094E-4, 3.9970357E-5, 3.692824E-4, 5.5317682E-6, 3.467135E-5, 1.1321...|\n",
      "|[9.028466E-5, 2.0533502E-4, 4.5085282E-5, 7.65107E-5, 3.217092E-5, 3.3741904E-4, 3.8024857E-6, 4.1927728E-5, 9.920564...|\n",
      "|[1.0625615E-4, 3.759827E-4, 7.6174496E-5, 1.2342798E-4, 4.7335903E-5, 3.3091815E-4, 1.0598523E-5, 9.161089E-5, 1.7926...|\n",
      "|[2.2157477E-5, 2.726377E-4, 3.831429E-5, 6.2276886E-5, 1.8050652E-5, 1.7177712E-4, 6.0331595E-6, 1.06755506E-4, 1.790...|\n",
      "|[1.0993216E-4, 2.8824335E-4, 4.2543048E-5, 1.06903855E-4, 3.039875E-5, 4.7743318E-4, 6.441006E-6, 3.6423717E-5, 1.361...|\n",
      "|[9.6276366E-5, 2.047977E-4, 7.4698546E-5, 1.128771E-4, 4.6044628E-5, 2.8445767E-4, 5.6014956E-6, 5.475251E-5, 9.63856...|\n",
      "|[7.3160336E-5, 3.2700456E-4, 1.3447899E-4, 1.7689951E-4, 8.4440886E-5, 2.2350134E-4, 1.3515168E-5, 1.1746432E-4, 1.81...|\n",
      "|[8.632592E-5, 2.7143923E-4, 3.583003E-5, 7.763873E-5, 2.3417528E-5, 3.6477615E-4, 3.527159E-6, 3.646688E-5, 1.0721673...|\n",
      "|[9.640316E-5, 2.7391897E-4, 5.7131063E-5, 1.09568326E-4, 3.8045353E-5, 3.472495E-4, 6.057242E-6, 4.3799748E-5, 1.1118...|\n",
      "|[6.912533E-5, 2.5222785E-4, 5.0288483E-5, 1.1415517E-4, 2.9881658E-5, 2.7816373E-4, 4.972507E-6, 5.121496E-5, 1.15293...|\n",
      "|[4.189945E-5, 2.4779947E-4, 1.2303083E-4, 1.4200866E-4, 7.2787174E-5, 1.600041E-4, 7.901948E-6, 1.3503798E-4, 1.46427...|\n",
      "|[2.7033573E-5, 3.8410365E-4, 1.2880778E-4, 1.5630701E-4, 7.2431474E-5, 8.455686E-5, 1.2551222E-5, 1.9146077E-4, 2.293...|\n",
      "|[2.9902518E-5, 3.521676E-4, 1.6034822E-4, 2.1348803E-4, 8.053424E-5, 1.00774814E-4, 1.3777179E-5, 1.5595586E-4, 1.615...|\n",
      "|[3.2834323E-5, 2.8044736E-4, 1.8003663E-4, 2.017913E-4, 1.3718085E-4, 1.0062256E-4, 3.4619785E-5, 3.8973117E-4, 3.187...|\n",
      "|[4.4552748E-5, 2.8623734E-4, 2.3419394E-4, 2.4108509E-4, 1.1926766E-4, 1.3529808E-4, 1.6018543E-5, 2.210266E-4, 1.558...|\n",
      "|[1.2160183E-4, 2.8021698E-4, 6.289166E-5, 1.0147789E-4, 4.3161614E-5, 3.8964444E-4, 8.174407E-6, 6.2043844E-5, 1.5228...|\n",
      "+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 3.16 ms, sys: 3.36 ms, total: 6.52 ms\n",
      "Wall time: 2.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(\"data\").alias(\"prediction\"))\n",
    "predictions.show(truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "632c4c3a-fa52-4c3d-b71e-7526286e353a",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.57 ms, sys: 5.2 ms, total: 12.8 ms\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = df.select(classify(col(\"data\")).alias(\"prediction\"))\n",
    "predictions.write.mode(\"overwrite\").parquet(output_file_path + \"_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc06b7e-f750-40b5-9208-a035db11d937",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stop Triton Server on each executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbfcaa51-3b9f-43ff-a4a8-4b46766115b8",
   "metadata": {
    "tags": [
     "TRITON"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stop_triton(it):\n",
    "    import docker\n",
    "    import time\n",
    "    \n",
    "    client=docker.from_env()\n",
    "    containers=client.containers.list(filters={\"name\": \"spark-triton\"})\n",
    "    print(\">>>> stopping containers: {}\".format([c.short_id for c in containers]))\n",
    "    if containers:\n",
    "        container=containers[0]\n",
    "        container.stop(timeout=120)\n",
    "\n",
    "    return [True]\n",
    "\n",
    "nodeRDD.barrier().mapPartitions(stop_triton).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d88639b-d934-4eb4-ae2f-cc13b9b10456",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8cc28a-34d7-479c-be7e-9a380d39e25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-dl-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
